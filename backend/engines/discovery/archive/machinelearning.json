{
    "kind": "Listing",
    "data": {
        "modhash": "hypdzmub0oece42a91350773107a4bd54b122493cb54e07100",
        "dist": 5,
        "facets": {},
        "after": null,
        "geo_filter": "",
        "children": [
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Hey everyone!\n\nI built vLLM-MLX - a framework that uses Apple's MLX for native GPU acceleration.\n\n**What it does:**\n\n\\- OpenAI-compatible API (drop-in replacement for your existing code)\n\n\\- Multimodal support: Text, Images, Video, Audio - all in one server\n\n\\- Continuous batching for concurrent users (3.4x speedup)\n\n\\- TTS in 10+ languages (Kokoro, Chatterbox models)\n\n\\- MCP tool calling support\n\n**Performance on M4 Max:**\n\n\\- Llama-3.2-1B-4bit \u2192 464 tok/s\n\n\\- Qwen3-0.6B \u2192 402 tok/s\n\n\\- Whisper STT \u2192 197x real-time\n\nWorks with standard OpenAI Python SDK - just point it to localhost.\n\n**GitHub:**\u00a0[https://github.com/waybarrios/vllm-mlx](https://github.com/waybarrios/vllm-mlx)",
                    "author_fullname": "t2_57ierokx",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[P] vLLM-MLX: Native Apple Silicon LLM inference - 464 tok/s on M4 Max",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1qelny9",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.68,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 8,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Project",
                    "can_mod_post": false,
                    "score": 8,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1768583110.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;I built vLLM-MLX - a framework that uses Apple&amp;#39;s MLX for native GPU acceleration.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What it does:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- OpenAI-compatible API (drop-in replacement for your existing code)&lt;/p&gt;\n\n&lt;p&gt;- Multimodal support: Text, Images, Video, Audio - all in one server&lt;/p&gt;\n\n&lt;p&gt;- Continuous batching for concurrent users (3.4x speedup)&lt;/p&gt;\n\n&lt;p&gt;- TTS in 10+ languages (Kokoro, Chatterbox models)&lt;/p&gt;\n\n&lt;p&gt;- MCP tool calling support&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Performance on M4 Max:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- Llama-3.2-1B-4bit \u2192 464 tok/s&lt;/p&gt;\n\n&lt;p&gt;- Qwen3-0.6B \u2192 402 tok/s&lt;/p&gt;\n\n&lt;p&gt;- Whisper STT \u2192 197x real-time&lt;/p&gt;\n\n&lt;p&gt;Works with standard OpenAI Python SDK - just point it to localhost.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;GitHub:&lt;/strong&gt;\u00a0&lt;a href=\"https://github.com/waybarrios/vllm-mlx\"&gt;https://github.com/waybarrios/vllm-mlx&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/fBTqn5A_VMK5OvBsBnb5b0JpYvCkmnptt_UHJ212bNQ.png?auto=webp&amp;s=8a038454e6a2762a1a543f606fb53ae0422e549f",
                                    "width": 1200,
                                    "height": 600
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/fBTqn5A_VMK5OvBsBnb5b0JpYvCkmnptt_UHJ212bNQ.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=892966bdba333a956bfe2c383f77762610855143",
                                        "width": 108,
                                        "height": 54
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/fBTqn5A_VMK5OvBsBnb5b0JpYvCkmnptt_UHJ212bNQ.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=46a40ad70ba8bde07abdce77f8bf351e7ecb20d6",
                                        "width": 216,
                                        "height": 108
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/fBTqn5A_VMK5OvBsBnb5b0JpYvCkmnptt_UHJ212bNQ.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf1f1592fa93dbb1ad6e9f8cff0be4a5ced5d45c",
                                        "width": 320,
                                        "height": 160
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/fBTqn5A_VMK5OvBsBnb5b0JpYvCkmnptt_UHJ212bNQ.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0f8539fe5b27ab3b2c6f93564a02063fa844cda6",
                                        "width": 640,
                                        "height": 320
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/fBTqn5A_VMK5OvBsBnb5b0JpYvCkmnptt_UHJ212bNQ.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4d4a56221df1f2350c53d2e8b1ac5848eb2a5e8b",
                                        "width": 960,
                                        "height": 480
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/fBTqn5A_VMK5OvBsBnb5b0JpYvCkmnptt_UHJ212bNQ.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=836e2b9dd0d2699bec2d75e7abd0f288b9cea45b",
                                        "width": 1080,
                                        "height": 540
                                    }
                                ],
                                "variants": {},
                                "id": "fBTqn5A_VMK5OvBsBnb5b0JpYvCkmnptt_UHJ212bNQ"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "c6dea51c-19d3-11f0-81a2-deb9d8e21ccb",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#7d659a",
                    "id": "1qelny9",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "waybarrios",
                    "discussion_type": null,
                    "num_comments": 3,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/1qelny9/p_vllmmlx_native_apple_silicon_llm_inference_464/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/MachineLearning/comments/1qelny9/p_vllmmlx_native_apple_silicon_llm_inference_464/",
                    "subreddit_subscribers": 3015130,
                    "created_utc": 1768583110.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "While I was looking for a hybrid solution to precompute embeddings for documents offline and then use a hosted online service for embedding queries, I realized that I don\u2019t have that many options. In fact, the only open weight model I could find that has providers on OpenRouter was Qwen3-embeddings-4/8B (0.6B doesn\u2019t have any providers on OpenRouter).\n\nAm I missing something? Running a GPU full time is an overkill in my case.",
                    "author_fullname": "t2_wdwhyojsb",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[D] Hosted and Open Weight Embeddings",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1pt9w0w",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.76,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 8,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Discussion",
                    "can_mod_post": false,
                    "score": 8,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766434922.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While I was looking for a hybrid solution to precompute embeddings for documents offline and then use a hosted online service for embedding queries, I realized that I don\u2019t have that many options. In fact, the only open weight model I could find that has providers on OpenRouter was Qwen3-embeddings-4/8B (0.6B doesn\u2019t have any providers on OpenRouter).&lt;/p&gt;\n\n&lt;p&gt;Am I missing something? Running a GPU full time is an overkill in my case.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "15995904-19d4-11f0-b8c9-0eed6ea89bc1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#26c4d9",
                    "id": "1pt9w0w",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "stat-insig-005",
                    "discussion_type": null,
                    "num_comments": 6,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/1pt9w0w/d_hosted_and_open_weight_embeddings/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/MachineLearning/comments/1pt9w0w/d_hosted_and_open_weight_embeddings/",
                    "subreddit_subscribers": 3015130,
                    "created_utc": 1766434922.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "I am an open source contributor, working on load balancing for Bifrost (LLM gateway) and ran into some interesting challenges with Go implementation.\n\nStandard weighted round-robin works fine for static loads, but LLM providers behave weirdly. OpenAI might be fast at 9am, slow at 2pm. Azure rate limits kick in unexpectedly. One region degrades while others stay healthy.\n\nBuilt adaptive routing that adjusts weights based on live metrics - latency, error rates, throughput. Used EWMAs (exponentially weighted moving averages) to smooth out spikes without overreacting to noise.\n\nThe Go part that was tricky: tracking per-provider metrics without locks becoming a bottleneck at high RPS. Ended up using atomic operations for counters and a separate goroutine that periodically reads metrics and recalculates weights. Keeps the hot path lock-free.\n\nAlso had to handle provider health scoring. Not just \"up or down\" but scoring based on recent performance. A provider recovering from issues should gradually earn traffic back, not get slammed immediately.\n\nConnection pooling matters more than expected. Go's http.Transport reuses connections well, but tuning MaxIdleConnsPerHost made a noticeable difference under sustained load.\n\nRunning this at 5K RPS with sub-microsecond overhead now. The concurrency primitives in Go made this way easier than Python would've been.\n\nAnyone else built adaptive routing in Go? What patterns worked for you?",
                    "author_fullname": "t2_6fxogmyi",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[P] Adaptive load balancing in Go for LLM traffic - harder than expected",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1qdsd84",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.92,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 22,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Project",
                    "can_mod_post": false,
                    "score": 22,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1768503519.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am an open source contributor, working on load balancing for Bifrost (LLM gateway) and ran into some interesting challenges with Go implementation.&lt;/p&gt;\n\n&lt;p&gt;Standard weighted round-robin works fine for static loads, but LLM providers behave weirdly. OpenAI might be fast at 9am, slow at 2pm. Azure rate limits kick in unexpectedly. One region degrades while others stay healthy.&lt;/p&gt;\n\n&lt;p&gt;Built adaptive routing that adjusts weights based on live metrics - latency, error rates, throughput. Used EWMAs (exponentially weighted moving averages) to smooth out spikes without overreacting to noise.&lt;/p&gt;\n\n&lt;p&gt;The Go part that was tricky: tracking per-provider metrics without locks becoming a bottleneck at high RPS. Ended up using atomic operations for counters and a separate goroutine that periodically reads metrics and recalculates weights. Keeps the hot path lock-free.&lt;/p&gt;\n\n&lt;p&gt;Also had to handle provider health scoring. Not just &amp;quot;up or down&amp;quot; but scoring based on recent performance. A provider recovering from issues should gradually earn traffic back, not get slammed immediately.&lt;/p&gt;\n\n&lt;p&gt;Connection pooling matters more than expected. Go&amp;#39;s http.Transport reuses connections well, but tuning MaxIdleConnsPerHost made a noticeable difference under sustained load.&lt;/p&gt;\n\n&lt;p&gt;Running this at 5K RPS with sub-microsecond overhead now. The concurrency primitives in Go made this way easier than Python would&amp;#39;ve been.&lt;/p&gt;\n\n&lt;p&gt;Anyone else built adaptive routing in Go? What patterns worked for you?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "c6dea51c-19d3-11f0-81a2-deb9d8e21ccb",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#7d659a",
                    "id": "1qdsd84",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "dinkinflika0",
                    "discussion_type": null,
                    "num_comments": 1,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/1qdsd84/p_adaptive_load_balancing_in_go_for_llm_traffic/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/MachineLearning/comments/1qdsd84/p_adaptive_load_balancing_in_go_for_llm_traffic/",
                    "subreddit_subscribers": 3015130,
                    "created_utc": 1768503519.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Most current approaches to agent reliability involve mixing validation logic (regex checks, JSON parsing, retries) directly with application logic (prompts/tools). This usually results in decorators on every function or heavy `try/except` blocks inside the agent loop.\n\nI've been experimenting with an alternative architecture: an **Agent Service Mesh**.\n\nInstead of decorating individual functions, this approach involves monkeypatching the agent framework (e.g., PydanticAI or OpenAI SDK) at the entry point. The \"Mesh\" uses introspection to detect which tools or output types the agent is using, and automatically attaches deterministic validators (what I call \"Reality Locks\") to the lifecycle.\n\n**The Architecture Change:**\n\nInstead of tight coupling:\n```python\n@validate_json # &lt;--- Manual decoration required on every function\ndef run_agent(query):\n    ...\n```\n\nThe Service Mesh approach (using `sys.meta_path` or framework hooks):\n```python\n# Patches the framework globally.\n# Auto-detects usage of SQL tools or JSON schemas and attaches validators.\nmesh.init(patch=[\"pydantic_ai\"], policy=\"strict\")\n\n# Business logic remains pure\nagent.run(query) \n```\n\nI implemented this pattern in a library called **Steer**. It currently handles SQL verification (AST parsing), PII redaction, and JSON schema enforcement by hooking into the framework's tool-call events.\n\nI am curious if others are using this \"sidecar/mesh\" approach for local agents, or if middleware (like LangSmith) is the preferred abstraction layer?\n\n**Reference Implementation:** https://github.com/imtt-dev/steer",
                    "author_fullname": "t2_1x1lhyrq4l",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[P] Implementing an \"Agent Service Mesh\" pattern to decouple reliability logic from reasoning (Python)",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q5jyqp",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.38,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 0,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Project",
                    "can_mod_post": false,
                    "score": 0,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767709478.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most current approaches to agent reliability involve mixing validation logic (regex checks, JSON parsing, retries) directly with application logic (prompts/tools). This usually results in decorators on every function or heavy &lt;code&gt;try/except&lt;/code&gt; blocks inside the agent loop.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been experimenting with an alternative architecture: an &lt;strong&gt;Agent Service Mesh&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;Instead of decorating individual functions, this approach involves monkeypatching the agent framework (e.g., PydanticAI or OpenAI SDK) at the entry point. The &amp;quot;Mesh&amp;quot; uses introspection to detect which tools or output types the agent is using, and automatically attaches deterministic validators (what I call &amp;quot;Reality Locks&amp;quot;) to the lifecycle.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Architecture Change:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Instead of tight coupling:\n&lt;code&gt;python\n@validate_json # &amp;lt;--- Manual decoration required on every function\ndef run_agent(query):\n    ...\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;The Service Mesh approach (using &lt;code&gt;sys.meta_path&lt;/code&gt; or framework hooks):\n```python&lt;/p&gt;\n\n&lt;h1&gt;Patches the framework globally.&lt;/h1&gt;\n\n&lt;h1&gt;Auto-detects usage of SQL tools or JSON schemas and attaches validators.&lt;/h1&gt;\n\n&lt;p&gt;mesh.init(patch=[&amp;quot;pydantic_ai&amp;quot;], policy=&amp;quot;strict&amp;quot;)&lt;/p&gt;\n\n&lt;h1&gt;Business logic remains pure&lt;/h1&gt;\n\n&lt;p&gt;agent.run(query) \n```&lt;/p&gt;\n\n&lt;p&gt;I implemented this pattern in a library called &lt;strong&gt;Steer&lt;/strong&gt;. It currently handles SQL verification (AST parsing), PII redaction, and JSON schema enforcement by hooking into the framework&amp;#39;s tool-call events.&lt;/p&gt;\n\n&lt;p&gt;I am curious if others are using this &amp;quot;sidecar/mesh&amp;quot; approach for local agents, or if middleware (like LangSmith) is the preferred abstraction layer?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Reference Implementation:&lt;/strong&gt; &lt;a href=\"https://github.com/imtt-dev/steer\"&gt;https://github.com/imtt-dev/steer&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/aVPMmsLTUtRr0q4ZE9N5L4pVQQYd5d_o74kH51MezIM.png?auto=webp&amp;s=1089ccb8786efe179223277d3a8c2f928fec91af",
                                    "width": 1024,
                                    "height": 1024
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/aVPMmsLTUtRr0q4ZE9N5L4pVQQYd5d_o74kH51MezIM.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3e9add5a08bab7287cd6f6ffed6456555840fbfe",
                                        "width": 108,
                                        "height": 108
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/aVPMmsLTUtRr0q4ZE9N5L4pVQQYd5d_o74kH51MezIM.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=09edfd0bd6f60f3bce5678b20c69c61a743b39ae",
                                        "width": 216,
                                        "height": 216
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/aVPMmsLTUtRr0q4ZE9N5L4pVQQYd5d_o74kH51MezIM.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=14420050c4444b1c30f695bd21991c821fcf8fd9",
                                        "width": 320,
                                        "height": 320
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/aVPMmsLTUtRr0q4ZE9N5L4pVQQYd5d_o74kH51MezIM.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=14fb4b8e9a3c99150577873aa1caedec0d88151d",
                                        "width": 640,
                                        "height": 640
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/aVPMmsLTUtRr0q4ZE9N5L4pVQQYd5d_o74kH51MezIM.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=44a9f9d1ea0b0c517b82edfd9dfbcb86356d8ca9",
                                        "width": 960,
                                        "height": 960
                                    }
                                ],
                                "variants": {},
                                "id": "aVPMmsLTUtRr0q4ZE9N5L4pVQQYd5d_o74kH51MezIM"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "c6dea51c-19d3-11f0-81a2-deb9d8e21ccb",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#7d659a",
                    "id": "1q5jyqp",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Proud-Employ5627",
                    "discussion_type": null,
                    "num_comments": 3,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/1q5jyqp/p_implementing_an_agent_service_mesh_pattern_to/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/MachineLearning/comments/1q5jyqp/p_implementing_an_agent_service_mesh_pattern_to/",
                    "subreddit_subscribers": 3015130,
                    "created_utc": 1767709478.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "MachineLearning",
                    "selftext": "Hello all,\n\nI am a 3rd year research student and for the past few weeks, I am building a new approach to computer use agents.\n\nAround 5-6 months back, i had to implement openai-cua in one project when i first came to know how terrible it was. There\u2019s no reasoning, no reliability, it\u2019s like a black box.\n\nAnd i posted about it back then on reddit only and talked with so many peers facing the same problem.\n\nSo, a month back, a got a big personal setback and to cope up, i started building this new way to let agents access computer use.\n\nThere\u2019s first observation was that -\n\n1.\t\u2060It\u2019s the only workflow that\u2019s end-to-end. n8n, agentskit, memory, RPAs, etc. are distributed but computer use is based on single model.\n2.\t\u2060They are designed for smaller tasks. All of the models are demoed on smaller and simpler tasks, not complex ones. So, this is more of in the vanity metric state.\n3.\t\u2060A single model is reliable for all the work, i.e, architecturally flawed. The same model is reasoning, clicking, scrolling, etc. and don\u2019t \n\nSumming up.. all are focused on making it fast, not reliable.\n\nSo, i took the backward integration approach. I created this organisation -based architecture where rather than 1 model doing all computer use task, there are multiple models with credits, tools and designations to do very specific tasks.\n\nLike a ceo, manger, sales rep, hr, etc,\n\nEarly tests are going good.\n\nAgent ran yesterday night for 5+ hours and coz of a distributed tech, it was dirt cheap and most important, much much reliable.\n\nBonus for me, I programmed small models like Amazon nova 2 lite to do cua tasks without finetuning.\n\nNow, i really want to understand community\u2019s take on this - should i keep building? Should i open source it? Should i start sharing videos? What exactly ?\n\nAlso, i have right now no one to critique.. so, please help in that also.",
                    "author_fullname": "t2_bj2cd750",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "[R] I am building this alternate computer use architecture and need feedback",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/MachineLearning",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "three",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1prlx6u",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.33,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 0,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Research",
                    "can_mod_post": false,
                    "score": 0,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766257313.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.MachineLearning",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I am a 3rd year research student and for the past few weeks, I am building a new approach to computer use agents.&lt;/p&gt;\n\n&lt;p&gt;Around 5-6 months back, i had to implement openai-cua in one project when i first came to know how terrible it was. There\u2019s no reasoning, no reliability, it\u2019s like a black box.&lt;/p&gt;\n\n&lt;p&gt;And i posted about it back then on reddit only and talked with so many peers facing the same problem.&lt;/p&gt;\n\n&lt;p&gt;So, a month back, a got a big personal setback and to cope up, i started building this new way to let agents access computer use.&lt;/p&gt;\n\n&lt;p&gt;There\u2019s first observation was that -&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt; \u2060It\u2019s the only workflow that\u2019s end-to-end. n8n, agentskit, memory, RPAs, etc. are distributed but computer use is based on single model.&lt;/li&gt;\n&lt;li&gt; \u2060They are designed for smaller tasks. All of the models are demoed on smaller and simpler tasks, not complex ones. So, this is more of in the vanity metric state.&lt;/li&gt;\n&lt;li&gt; \u2060A single model is reliable for all the work, i.e, architecturally flawed. The same model is reasoning, clicking, scrolling, etc. and don\u2019t &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Summing up.. all are focused on making it fast, not reliable.&lt;/p&gt;\n\n&lt;p&gt;So, i took the backward integration approach. I created this organisation -based architecture where rather than 1 model doing all computer use task, there are multiple models with credits, tools and designations to do very specific tasks.&lt;/p&gt;\n\n&lt;p&gt;Like a ceo, manger, sales rep, hr, etc,&lt;/p&gt;\n\n&lt;p&gt;Early tests are going good.&lt;/p&gt;\n\n&lt;p&gt;Agent ran yesterday night for 5+ hours and coz of a distributed tech, it was dirt cheap and most important, much much reliable.&lt;/p&gt;\n\n&lt;p&gt;Bonus for me, I programmed small models like Amazon nova 2 lite to do cua tasks without finetuning.&lt;/p&gt;\n\n&lt;p&gt;Now, i really want to understand community\u2019s take on this - should i keep building? Should i open source it? Should i start sharing videos? What exactly ?&lt;/p&gt;\n\n&lt;p&gt;Also, i have right now no one to critique.. so, please help in that also.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "bb90e510-4e82-11e6-8635-0ee522e2349b",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2r3gv",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#f1f10e",
                    "id": "1prlx6u",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Uditakhourii",
                    "discussion_type": null,
                    "num_comments": 1,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/MachineLearning/comments/1prlx6u/r_i_am_building_this_alternate_computer_use/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/MachineLearning/comments/1prlx6u/r_i_am_building_this_alternate_computer_use/",
                    "subreddit_subscribers": 3015130,
                    "created_utc": 1766257313.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            }
        ],
        "before": null
    }
}