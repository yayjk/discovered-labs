{
    "kind": "Listing",
    "data": {
        "modhash": "du93s4s4hid7945b6dca96786615f963f84d0d99e1a0c91c21",
        "dist": 68,
        "facets": {},
        "after": null,
        "geo_filter": "",
        "children": [
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "https://preview.redd.it/to2hronir6dg1.jpg?width=1924&amp;format=pjpg&amp;auto=webp&amp;s=23dd307e59ab9b32195b2b16539234eded2515a5\n\nIntroducing Codex Manager. One place to manage all your OpenAI Codex coding agent setup.\n\nCodex Manager is a desktop configuration and asset manager for Codex. It manages the real files on disk and makes changes safe and reversible. It does not run Codex sessions and it does not execute arbitrary commands.\n\nWhat it manages\n\n* config.toml plus a public config library\n* skills plus a public skills library via ClawdHub\n* MCP servers\n* repo scoped skills\n* prompts and rules\n\nEvery change follows the same safety flow\n\n* preview diff\n* create a backup\n* atomic write\n* re validate and show status\n\nFeatures in v1.0.0\n\n* Config editor with Simple, Advanced, and raw TOML modes\n* Public Config Library and My Configs presets\n* MCP Servers management\n* Skills manager across user scope and repo scope\n* Public Skills browser backed by ClawdHub with install modes overlay, replace, sync\n* Diagnostics panel for parse errors and missing paths\n\nRelease v1.0.0  \n[https://github.com/siddhantparadox/codexmanager/releases/tag/v1.0.0](https://github.com/siddhantparadox/codexmanager/releases/tag/v1.0.0)\n\nI first built the idea during a Hackathon, then polished it into this public release.\n\nIf you use Codex daily, I would love feedback on what workflows are still annoying, config switching, skill installs, multi repo setups, anything.",
                    "author_fullname": "t2_4vdsgga6",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Codex Manager v1.0.0, desktop app to manage OpenAI Codex config, skills, MCP servers, and repo scoped setups",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 92,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "media_metadata": {
                        "to2hronir6dg1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/jpg",
                            "p": [
                                {
                                    "y": 71,
                                    "x": 108,
                                    "u": "https://preview.redd.it/to2hronir6dg1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3ef64986ea0dedbb11bbca751563e89d31c5fec3"
                                },
                                {
                                    "y": 143,
                                    "x": 216,
                                    "u": "https://preview.redd.it/to2hronir6dg1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=146f3acd3ec44fa7410e63af4d6c9ca79f604560"
                                },
                                {
                                    "y": 212,
                                    "x": 320,
                                    "u": "https://preview.redd.it/to2hronir6dg1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3d3c8a991002a72b45f0865293de9899ef22e1ef"
                                },
                                {
                                    "y": 424,
                                    "x": 640,
                                    "u": "https://preview.redd.it/to2hronir6dg1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8a8f5a5d84810f1f7f1855050a3c643df0e0fecc"
                                },
                                {
                                    "y": 636,
                                    "x": 960,
                                    "u": "https://preview.redd.it/to2hronir6dg1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=983e19f5e2402cb2de9b7ac5ca71b8e51ea1f7d4"
                                },
                                {
                                    "y": 716,
                                    "x": 1080,
                                    "u": "https://preview.redd.it/to2hronir6dg1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a61d70fdf9ebd034f2f088cdea204826c2582531"
                                }
                            ],
                            "s": {
                                "y": 1276,
                                "x": 1924,
                                "u": "https://preview.redd.it/to2hronir6dg1.jpg?width=1924&amp;format=pjpg&amp;auto=webp&amp;s=23dd307e59ab9b32195b2b16539234eded2515a5"
                            },
                            "id": "to2hronir6dg1"
                        }
                    },
                    "name": "t3_1qc3x5b",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.88,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 32,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Showcase",
                    "can_mod_post": false,
                    "score": 32,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/rlSEZP14_uHeBnUFwx8bTh24pePy3V0z-S9ItLQNrKg.jpg",
                    "edited": 1768340325.0,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1768339661.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/to2hronir6dg1.jpg?width=1924&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=23dd307e59ab9b32195b2b16539234eded2515a5\"&gt;https://preview.redd.it/to2hronir6dg1.jpg?width=1924&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=23dd307e59ab9b32195b2b16539234eded2515a5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Introducing Codex Manager. One place to manage all your OpenAI Codex coding agent setup.&lt;/p&gt;\n\n&lt;p&gt;Codex Manager is a desktop configuration and asset manager for Codex. It manages the real files on disk and makes changes safe and reversible. It does not run Codex sessions and it does not execute arbitrary commands.&lt;/p&gt;\n\n&lt;p&gt;What it manages&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;config.toml plus a public config library&lt;/li&gt;\n&lt;li&gt;skills plus a public skills library via ClawdHub&lt;/li&gt;\n&lt;li&gt;MCP servers&lt;/li&gt;\n&lt;li&gt;repo scoped skills&lt;/li&gt;\n&lt;li&gt;prompts and rules&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Every change follows the same safety flow&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;preview diff&lt;/li&gt;\n&lt;li&gt;create a backup&lt;/li&gt;\n&lt;li&gt;atomic write&lt;/li&gt;\n&lt;li&gt;re validate and show status&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Features in v1.0.0&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Config editor with Simple, Advanced, and raw TOML modes&lt;/li&gt;\n&lt;li&gt;Public Config Library and My Configs presets&lt;/li&gt;\n&lt;li&gt;MCP Servers management&lt;/li&gt;\n&lt;li&gt;Skills manager across user scope and repo scope&lt;/li&gt;\n&lt;li&gt;Public Skills browser backed by ClawdHub with install modes overlay, replace, sync&lt;/li&gt;\n&lt;li&gt;Diagnostics panel for parse errors and missing paths&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Release v1.0.0&lt;br/&gt;\n&lt;a href=\"https://github.com/siddhantparadox/codexmanager/releases/tag/v1.0.0\"&gt;https://github.com/siddhantparadox/codexmanager/releases/tag/v1.0.0&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I first built the idea during a Hackathon, then polished it into this public release.&lt;/p&gt;\n\n&lt;p&gt;If you use Codex daily, I would love feedback on what workflows are still annoying, config switching, skill installs, multi repo setups, anything.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "e350908e-b24e-11f0-b239-62e50da6d05a",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#00ff2a",
                    "id": "1qc3x5b",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "siddhantparadox",
                    "discussion_type": null,
                    "num_comments": 21,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1qc3x5b/codex_manager_v100_desktop_app_to_manage_openai/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1qc3x5b/codex_manager_v100_desktop_app_to_manage_openai/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1768339661.0,
                    "num_crossposts": 2,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "I've been using Codex for a few months now to dramatically speed up the development of a frontend app.\n\nOne thing I find myself doing manually a lot of is minor testing. Crossed my mind that it would be hugely helpful if codex could also do this, while also taking the chance to test out other things that may not have crossed my mind, and also spotting on its own if something goes wrong. \n\nIs there a way to essentially combine a codex session with a browser agent session?",
                    "author_fullname": "t2_k01zajj",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Integrating codex with a browser agent for automatic testing of frontend features - any way to use a tool like OpenAI's Atlas browser for this?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1psyje3",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.67,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 1,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Question",
                    "can_mod_post": false,
                    "score": 1,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766407012.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been using Codex for a few months now to dramatically speed up the development of a frontend app.&lt;/p&gt;\n\n&lt;p&gt;One thing I find myself doing manually a lot of is minor testing. Crossed my mind that it would be hugely helpful if codex could also do this, while also taking the chance to test out other things that may not have crossed my mind, and also spotting on its own if something goes wrong. &lt;/p&gt;\n\n&lt;p&gt;Is there a way to essentially combine a codex session with a browser agent session?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "302c6282-b24c-11f0-a6c9-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c13e80",
                    "id": "1psyje3",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Lostwhispers05",
                    "discussion_type": null,
                    "num_comments": 5,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1psyje3/integrating_codex_with_a_browser_agent_for/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1psyje3/integrating_codex_with_a_browser_agent_for/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766407012.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "I had recently posted about how Codex implements skills and how it's a game-changer. \n\nSince it got a lot of good feedback, I decided to open a PR with OpenAI's Skills repository for the first skills that I created and have tested work well. It's with Google's Agent Development Kit in TypeScript, and using this skill will make it much easier for users to create agentic applications. \n\n  \n[https://github.com/openai/skills/pull/24](https://github.com/openai/skills/pull/24)",
                    "author_fullname": "t2_147w1sjork",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "I opened my first PR with openai/skills",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1psib8x",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 7,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Other",
                    "can_mod_post": false,
                    "score": 7,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766354395.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had recently posted about how Codex implements skills and how it&amp;#39;s a game-changer. &lt;/p&gt;\n\n&lt;p&gt;Since it got a lot of good feedback, I decided to open a PR with OpenAI&amp;#39;s Skills repository for the first skills that I created and have tested work well. It&amp;#39;s with Google&amp;#39;s Agent Development Kit in TypeScript, and using this skill will make it much easier for users to create agentic applications. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/openai/skills/pull/24\"&gt;https://github.com/openai/skills/pull/24&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/O6qCcu6COnpsxgeQSOsC8oTSuehgx3lOSBBz0iE0mPM.png?auto=webp&amp;s=fb3e7790c51978b7348e46f41a3183a2e8f07450",
                                    "width": 1200,
                                    "height": 600
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/O6qCcu6COnpsxgeQSOsC8oTSuehgx3lOSBBz0iE0mPM.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0b150282f656abd037d3a91c98980920e80db9a1",
                                        "width": 108,
                                        "height": 54
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/O6qCcu6COnpsxgeQSOsC8oTSuehgx3lOSBBz0iE0mPM.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=296e46195f4ab1863680187ea513055c9853d17b",
                                        "width": 216,
                                        "height": 108
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/O6qCcu6COnpsxgeQSOsC8oTSuehgx3lOSBBz0iE0mPM.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c03557a26dd8f7f3506360b66af65bcb8098b3ce",
                                        "width": 320,
                                        "height": 160
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/O6qCcu6COnpsxgeQSOsC8oTSuehgx3lOSBBz0iE0mPM.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=50d6e21c2fdc34acfbab261e7831ba7a190342f2",
                                        "width": 640,
                                        "height": 320
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/O6qCcu6COnpsxgeQSOsC8oTSuehgx3lOSBBz0iE0mPM.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7b6a0722e2e6d5fc69975a7e0f3191c929284bd2",
                                        "width": 960,
                                        "height": 480
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/O6qCcu6COnpsxgeQSOsC8oTSuehgx3lOSBBz0iE0mPM.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b4ff8a0a72c8f893129919bd0d73f0fcdbcf2d66",
                                        "width": 1080,
                                        "height": 540
                                    }
                                ],
                                "variants": {},
                                "id": "O6qCcu6COnpsxgeQSOsC8oTSuehgx3lOSBBz0iE0mPM"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "00c10890-b24c-11f0-a5a8-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#dadada",
                    "id": "1psib8x",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Swimming_Driver4974",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1psib8x/i_opened_my_first_pr_with_openaiskills/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1psib8x/i_opened_my_first_pr_with_openaiskills/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766354395.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "The vibe coders are going to find out and migrate now and eat up all processing power and limits! \n\n/s ",
                    "author_fullname": "t2_8mabxgcf",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Its over",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 70,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1qdkyac",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.9,
                    "author_flair_background_color": null,
                    "ups": 278,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": true,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Showcase",
                    "can_mod_post": false,
                    "score": 278,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/6eZwNgKpFMoEdPhpfbwsqgT4gWKpuOK59yrcwTG5ySc.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "image",
                    "content_categories": null,
                    "is_self": false,
                    "subreddit_type": "public",
                    "created": 1768487244.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "i.redd.it",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The vibe coders are going to find out and migrate now and eat up all processing power and limits! &lt;/p&gt;\n\n&lt;p&gt;/s &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "url_overridden_by_dest": "https://i.redd.it/s4ek3dpdwidg1.png",
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://preview.redd.it/s4ek3dpdwidg1.png?auto=webp&amp;s=c237db9a792631fdfb5c56ae5af83a32d26c666a",
                                    "width": 1482,
                                    "height": 747
                                },
                                "resolutions": [
                                    {
                                        "url": "https://preview.redd.it/s4ek3dpdwidg1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=be5ebf69b22727a0f016f3c47c7741d0b30997ba",
                                        "width": 108,
                                        "height": 54
                                    },
                                    {
                                        "url": "https://preview.redd.it/s4ek3dpdwidg1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e952df8883c13e1f09a16f0f7326e385a0216fae",
                                        "width": 216,
                                        "height": 108
                                    },
                                    {
                                        "url": "https://preview.redd.it/s4ek3dpdwidg1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8b2b0bf4109f9042d887fcf45c554a7301e53349",
                                        "width": 320,
                                        "height": 161
                                    },
                                    {
                                        "url": "https://preview.redd.it/s4ek3dpdwidg1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ae5d0a60b374856be1bd1cd3d4e349232179bc3d",
                                        "width": 640,
                                        "height": 322
                                    },
                                    {
                                        "url": "https://preview.redd.it/s4ek3dpdwidg1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=753c3ac244414aabfb4d3f4853386babba43380d",
                                        "width": 960,
                                        "height": 483
                                    },
                                    {
                                        "url": "https://preview.redd.it/s4ek3dpdwidg1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=26781be15df03340be6fc08a8ddab2323f099f37",
                                        "width": 1080,
                                        "height": 544
                                    }
                                ],
                                "variants": {},
                                "id": "1vvmydqW6FFniG-nSq1aWmyGIckQF9ahA5Bi3qVPpHg"
                            }
                        ],
                        "enabled": true
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "e350908e-b24e-11f0-b239-62e50da6d05a",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "mod_note": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "num_reports": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#00ff2a",
                    "id": "1qdkyac",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "muchsamurai",
                    "discussion_type": null,
                    "num_comments": 135,
                    "send_replies": false,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1qdkyac/its_over/",
                    "stickied": true,
                    "url": "https://i.redd.it/s4ek3dpdwidg1.png",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1768487244.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Poor guy came at the wrong time with all the Openai bs. Truly a magical ai model when it comes to coding. It's a great model and it got no true love other then codex users because of Gemini 3 and Opus 4.5. I used both of these models and GPT-5.2 high/x-high is on another level when it comes to understanding and implementing working code. I build swiftui apps and Gemini and Opus always have build errors. Every single time. Where as gpt-5.2 its very rare. It understands your codebase and context king honestly. It truly feels like a capable Coding Ai model compared to others. Add Gpt-5.2-pro for review and planing and its a killer combination. \n\nSince its release building apps has been a breeze where as before it used to be constant issues. There was a time I had to rebuild a project because the models would constantly destroy it and it is no longer the case with 5.2. It is able to manage any request at this point. \n\nTruly appreciate this model and it has been so much fun to work with. I hope they don't nerf this. Openai Pls! \n\n",
                    "author_fullname": "t2_1z9kca91r9",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "I feel bad for GPT-5.2",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q59qme",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.95,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 251,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Praise",
                    "can_mod_post": false,
                    "score": 251,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767676455.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Poor guy came at the wrong time with all the Openai bs. Truly a magical ai model when it comes to coding. It&amp;#39;s a great model and it got no true love other then codex users because of Gemini 3 and Opus 4.5. I used both of these models and GPT-5.2 high/x-high is on another level when it comes to understanding and implementing working code. I build swiftui apps and Gemini and Opus always have build errors. Every single time. Where as gpt-5.2 its very rare. It understands your codebase and context king honestly. It truly feels like a capable Coding Ai model compared to others. Add Gpt-5.2-pro for review and planing and its a killer combination. &lt;/p&gt;\n\n&lt;p&gt;Since its release building apps has been a breeze where as before it used to be constant issues. There was a time I had to rebuild a project because the models would constantly destroy it and it is no longer the case with 5.2. It is able to manage any request at this point. &lt;/p&gt;\n\n&lt;p&gt;Truly appreciate this model and it has been so much fun to work with. I hope they don&amp;#39;t nerf this. Openai Pls! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "a1d1fcda-b24c-11f0-a8b0-4ea6c7db837e",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#eeff00",
                    "id": "1q59qme",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Affectionate_Fee232",
                    "discussion_type": null,
                    "num_comments": 118,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q59qme/i_feel_bad_for_gpt52/",
                    "stickied": true,
                    "url": "https://old.reddit.com/r/codex/comments/1q59qme/i_feel_bad_for_gpt52/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767676455.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "If anyone from openai is reading this. This is plea to not remove or change 5.2 high in anyway, it is the perfect balance and the most ideal agent!\n\nOver the last week or so I have tried high, xhigh and medium. Medium works a little faster, but makes mistakes, even though it fixes them, it takes a little bit of work. xhigh is very slow, and it does a little more than actually is required, its great for debugging really hard problem, but don't see a reason to use it all the time. high is the perfect balance of everything.\n\n5.2-codex models is not to my liking, makes mistakes, its coding style isn't great.\n\nPlease don't change 5.2 high, its awesome!",
                    "author_fullname": "t2_7wb6car6z",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "5.2 high",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q3hbgk",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.97,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 174,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Suggestion",
                    "can_mod_post": false,
                    "score": 174,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": 1767507376.0,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767503769.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If anyone from openai is reading this. This is plea to not remove or change 5.2 high in anyway, it is the perfect balance and the most ideal agent!&lt;/p&gt;\n\n&lt;p&gt;Over the last week or so I have tried high, xhigh and medium. Medium works a little faster, but makes mistakes, even though it fixes them, it takes a little bit of work. xhigh is very slow, and it does a little more than actually is required, its great for debugging really hard problem, but don&amp;#39;t see a reason to use it all the time. high is the perfect balance of everything.&lt;/p&gt;\n\n&lt;p&gt;5.2-codex models is not to my liking, makes mistakes, its coding style isn&amp;#39;t great.&lt;/p&gt;\n\n&lt;p&gt;Please don&amp;#39;t change 5.2 high, its awesome!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "a4b85826-b95f-11f0-987b-321e713942fe",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#72a15e",
                    "id": "1q3hbgk",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "TroubleOwn3156",
                    "discussion_type": null,
                    "num_comments": 78,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q3hbgk/52_high/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q3hbgk/52_high/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767503769.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "After GPT-5 came out in October, I switched from Claude's $200 Max plan to Codex and have been using it heavily for 3 months. During this time, I've been constantly comparing Codex and Opus, thinking I'd switch back once Opus surpassed it. So far, I haven't seen any reason to use Claude as my primary tool. Here are the main differences I've noticed:\n\n1. **Codex is like an introverted programmer who doesn't say much but delivers.** I don't know what OpenAI did during post-training, but Codex silently reads a massive amount of existing code in the codebase before writing anything. Sometimes it reads for 15 minutes before writing its first line of code. Claude is much more eager to jump in, barely reading two lines before rolling up its sleeves and diving in. This means Codex has a much higher probability of solving problems on the first try. Still remember how many times Claude firmly promised \"production ready, all issues fixed,\" and I excitedly ran the tests only to find them failing. After going back and forth asking it to fix things, Claude would quietly delete the failing test itself. As I get older, I just want some peace of mind. For large-scale refactoring or adding complex new features, Codex is my first choice. If Claude is like a thin daytime pad (240mm), then Codex feels like an overnight super-absorbent pad (420mm) that lets you sleep soundly.\n2. **GPT-5.2 supports 400k context, while Opus 4.5 only has 200k.** Not only is Codex's context window twice the size of Opus, its context management is much better than Claude Code. I feel like with the same context window, Codex can accomplish at least 4-5x what Claude can.\n3. **GPT-5.2's training data cuts off at August 2025, while Opus 4.5 cuts off at March 2025.** Although it's only a 6-month difference, the AI era moves so fast that OpenAI's Sora Android app went from inception to global launch in just 28 days: 18 days to release an internal beta to employees, then 10 days to public launch. Many mainstream frameworks can have multiple component updates in half a year. Here's my own example: last month I needed to integrate Google Ads API on the frontend. Although Google had already made service accounts the officially recommended authorization method in November 2024 and simplified the process (no longer requiring domain-wide delegation), Opus kept insisting that Google Ads API needs domain-wide delegation and recommended the no-longer-officially-recommended OAuth2 approach, despite claiming its training data goes up to March 2025. Codex gave me the correct framework recommendation. That said, when choosing frameworks, I still ask GPT, Opus, and Gemini as second opinions.\n4. **Despite all the good things I've said about Codex, it's really slow.** For small changes or time-sensitive situations, I still use Claude, and the output is satisfactory. Other times, I usually open a 4x4 grid of Codex windows for multi-threaded work. Multi-threading usually means multiple projects. I don't typically run multiple Codex instances on the same project unless the code involved is completely unrelated, because I usually work solo and don't like using git worktree. Unlike Claude, which remembers file states and re-reads files when changes occur, Codex doesn't. This is something to be aware of.",
                    "author_fullname": "t2_t2x9b9za",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Codex vs Claude Opus",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q19erm",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.99,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 171,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Comparison",
                    "can_mod_post": false,
                    "score": 171,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": 1767306017.0,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767288017.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After GPT-5 came out in October, I switched from Claude&amp;#39;s $200 Max plan to Codex and have been using it heavily for 3 months. During this time, I&amp;#39;ve been constantly comparing Codex and Opus, thinking I&amp;#39;d switch back once Opus surpassed it. So far, I haven&amp;#39;t seen any reason to use Claude as my primary tool. Here are the main differences I&amp;#39;ve noticed:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Codex is like an introverted programmer who doesn&amp;#39;t say much but delivers.&lt;/strong&gt; I don&amp;#39;t know what OpenAI did during post-training, but Codex silently reads a massive amount of existing code in the codebase before writing anything. Sometimes it reads for 15 minutes before writing its first line of code. Claude is much more eager to jump in, barely reading two lines before rolling up its sleeves and diving in. This means Codex has a much higher probability of solving problems on the first try. Still remember how many times Claude firmly promised &amp;quot;production ready, all issues fixed,&amp;quot; and I excitedly ran the tests only to find them failing. After going back and forth asking it to fix things, Claude would quietly delete the failing test itself. As I get older, I just want some peace of mind. For large-scale refactoring or adding complex new features, Codex is my first choice. If Claude is like a thin daytime pad (240mm), then Codex feels like an overnight super-absorbent pad (420mm) that lets you sleep soundly.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;GPT-5.2 supports 400k context, while Opus 4.5 only has 200k.&lt;/strong&gt; Not only is Codex&amp;#39;s context window twice the size of Opus, its context management is much better than Claude Code. I feel like with the same context window, Codex can accomplish at least 4-5x what Claude can.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;GPT-5.2&amp;#39;s training data cuts off at August 2025, while Opus 4.5 cuts off at March 2025.&lt;/strong&gt; Although it&amp;#39;s only a 6-month difference, the AI era moves so fast that OpenAI&amp;#39;s Sora Android app went from inception to global launch in just 28 days: 18 days to release an internal beta to employees, then 10 days to public launch. Many mainstream frameworks can have multiple component updates in half a year. Here&amp;#39;s my own example: last month I needed to integrate Google Ads API on the frontend. Although Google had already made service accounts the officially recommended authorization method in November 2024 and simplified the process (no longer requiring domain-wide delegation), Opus kept insisting that Google Ads API needs domain-wide delegation and recommended the no-longer-officially-recommended OAuth2 approach, despite claiming its training data goes up to March 2025. Codex gave me the correct framework recommendation. That said, when choosing frameworks, I still ask GPT, Opus, and Gemini as second opinions.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Despite all the good things I&amp;#39;ve said about Codex, it&amp;#39;s really slow.&lt;/strong&gt; For small changes or time-sensitive situations, I still use Claude, and the output is satisfactory. Other times, I usually open a 4x4 grid of Codex windows for multi-threaded work. Multi-threading usually means multiple projects. I don&amp;#39;t typically run multiple Codex instances on the same project unless the code involved is completely unrelated, because I usually work solo and don&amp;#39;t like using git worktree. Unlike Claude, which remembers file states and re-reads files when changes occur, Codex doesn&amp;#39;t. This is something to be aware of.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "b81001d4-8c88-11f0-8523-42042a14a711",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#817e7e",
                    "id": "1q19erm",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "sheepskin_rr",
                    "discussion_type": null,
                    "num_comments": 74,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q19erm/codex_vs_claude_opus/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q19erm/codex_vs_claude_opus/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767288017.0,
                    "num_crossposts": 1,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "I mean how did they do it? The only model you can leave overnight to do large refactor and it does even after multiple context compacts. How does it retain enough context despite compactions ? \n\nI just woke up and checked, reviewed what it did, everything so far seems to be okay with manual code review. Did what i asked it to do. Amazing honestly.\n\nImagine if GPT-5.2 XHIGH was fast, OpenAI would win AI coding race single handedly.\n\nIdk if it can be made faster, get some additional processing capacity Mr.Altman and fucking plug it into 5.2 lol \n\nhttps://preview.redd.it/moo37w8d6g9g1.png?width=511&amp;format=png&amp;auto=webp&amp;s=580066aa6914f1d4067a156f20e1b97b6a8ec484\n\n  \n",
                    "author_fullname": "t2_8mabxgcf",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Wtf is GPT-5.2 XHIGH?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 62,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "media_metadata": {
                        "moo37w8d6g9g1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/png",
                            "p": [
                                {
                                    "y": 47,
                                    "x": 108,
                                    "u": "https://preview.redd.it/moo37w8d6g9g1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cdad06037769fe1887bb5e8e4b361568d8c26ae1"
                                },
                                {
                                    "y": 95,
                                    "x": 216,
                                    "u": "https://preview.redd.it/moo37w8d6g9g1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0c611b415560bb51bb693875060fffdf7985d4ac"
                                },
                                {
                                    "y": 142,
                                    "x": 320,
                                    "u": "https://preview.redd.it/moo37w8d6g9g1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0ef71bfa36dcfc0e57e3cfa209bd69f56c80d52f"
                                }
                            ],
                            "s": {
                                "y": 227,
                                "x": 511,
                                "u": "https://preview.redd.it/moo37w8d6g9g1.png?width=511&amp;format=png&amp;auto=webp&amp;s=580066aa6914f1d4067a156f20e1b97b6a8ec484"
                            },
                            "id": "moo37w8d6g9g1"
                        }
                    },
                    "name": "t3_1pvrnht",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.95,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 140,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Praise",
                    "can_mod_post": false,
                    "score": 140,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/DK4C3uznWR1Ll7H5t6jvs-KKbLDjwPTS-aHn7yXiJBA.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766711182.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I mean how did they do it? The only model you can leave overnight to do large refactor and it does even after multiple context compacts. How does it retain enough context despite compactions ? &lt;/p&gt;\n\n&lt;p&gt;I just woke up and checked, reviewed what it did, everything so far seems to be okay with manual code review. Did what i asked it to do. Amazing honestly.&lt;/p&gt;\n\n&lt;p&gt;Imagine if GPT-5.2 XHIGH was fast, OpenAI would win AI coding race single handedly.&lt;/p&gt;\n\n&lt;p&gt;Idk if it can be made faster, get some additional processing capacity Mr.Altman and fucking plug it into 5.2 lol &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/moo37w8d6g9g1.png?width=511&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=580066aa6914f1d4067a156f20e1b97b6a8ec484\"&gt;https://preview.redd.it/moo37w8d6g9g1.png?width=511&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=580066aa6914f1d4067a156f20e1b97b6a8ec484&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "a1d1fcda-b24c-11f0-a8b0-4ea6c7db837e",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#eeff00",
                    "id": "1pvrnht",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "muchsamurai",
                    "discussion_type": null,
                    "num_comments": 73,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1pvrnht/wtf_is_gpt52_xhigh/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1pvrnht/wtf_is_gpt52_xhigh/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766711182.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Just tried opencode with my ChatGPT Pro subscription - it's next level game changer, in speed, easy of use and generally awesome.\n\nIf you are a claude code user, have a look, OpenCode is amazing.\n\nI seriously think OpenAI should acquire the OpenCode team and use it as the default Codex CLI client. Its amazing.",
                    "author_fullname": "t2_7wb6car6z",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "OpenCode with GPT is next level",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1qee31p",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.94,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 86,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Praise",
                    "can_mod_post": false,
                    "score": 86,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": 1768565609.0,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1768564731.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just tried opencode with my ChatGPT Pro subscription - it&amp;#39;s next level game changer, in speed, easy of use and generally awesome.&lt;/p&gt;\n\n&lt;p&gt;If you are a claude code user, have a look, OpenCode is amazing.&lt;/p&gt;\n\n&lt;p&gt;I seriously think OpenAI should acquire the OpenCode team and use it as the default Codex CLI client. Its amazing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "a1d1fcda-b24c-11f0-a8b0-4ea6c7db837e",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#eeff00",
                    "id": "1qee31p",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "TroubleOwn3156",
                    "discussion_type": null,
                    "num_comments": 72,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1qee31p/opencode_with_gpt_is_next_level/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1qee31p/opencode_with_gpt_is_next_level/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1768564731.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Okay so today i promised some user here that i would do a real Claude vs CODEX benchmark and see which model hallucinates less, lies less, follows prompt properly and is generally more trustworthy partner, can \"One shot\" complex tasks and is more reliable.\n\nContenders - Claude Opus 4.5 vs OpenAI CODEX 5.2 XHIGH \n\n**I did not use GPT-5.2 HIGH / XHIGH to give Claude Opus more chance, because GPT-5.2 is too much, so i used CODEX model instead.** \n\nI asked both models to \"One shot\" a TCP-based networking \"library\" with a little bit of complex logic involved. Here is prompt used for both Claude and Codex : \n\n[https://pastebin.com/sBeiu07z](https://pastebin.com/sBeiu07z) (The only difference being GitHub Repo) \n\nHere is code produced by Claude: \n\n[https://github.com/RtlZeroMemory/ClaudeLib](https://github.com/RtlZeroMemory/ClaudeLib) \n\nHere is code produced by Codex: \n\n[https://github.com/RtlZeroMemory/CodexLib](https://github.com/RtlZeroMemory/CodexLib) \n\nAfter both CODEX and CLAUDE finished their work, i wrote a special prompt for GEMINI 3 and CLAUDE CODE to review the code made by both Claude and Codex \"Dev Sessions\".\n\nPrompt i gave to GEMINI \n\n[https://pastebin.com/ibsR0Snt](https://pastebin.com/ibsR0Snt) \n\nSame prompt was given to Claude Code. \n\nResult evaluation in both Gemini and Claude (Claude was asked to use ULTRATHINK) \n\n  \nGemini's report on CLAUDE's work: [https://pastebin.com/RkZjrn8t](https://pastebin.com/RkZjrn8t) \n\nGemini's report on CODEX's work: [https://pastebin.com/tKUDdJ2B](https://pastebin.com/tKUDdJ2B) \n\nClaude Code (ULTRATHINK) report on CLAUDE's work: [https://pastebin.com/27NHcprn](https://pastebin.com/27NHcprn) \n\nClaude Code (ULTRATHINK) report on CODEX's work: [https://pastebin.com/yNyUjNqN](https://pastebin.com/yNyUjNqN) \n\n  \nAttaching screenshots as well. \n\nBasically Claude as always FAILS to deliver working solution if code is big and complex enough and can't \"One shot\" anything, despite being fast and really nice to use and a better tool overall (CLI). Model is quite \"dumber\", lies more, hallucinates more and deceives more. \n\nNeeds to work on smaller chunks, constant overwatch and careful checks, otherwise it will lie to you about implementing things it did not in fact implement or did incorrectly. \n\nCODEX and GPT-5.2 are MUCH more reliable and \"smarter\", but work slower and take time. Claude finished its job in 13 minutes or so, while CODEX XHIGH took a while more, however result is what is important, not speed to me. \n\nAnd this is consistent result for me.\n\nI use Claude as \"Code Monkey\", NEVER EVER trust it. It will LIE and deceive you, claiming your code is \"Production ready\", when in fact it is not. Need to keep it in check. \n\n\n\n\n\n\n\n",
                    "author_fullname": "t2_8mabxgcf",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "is_gallery": true,
                    "title": "CODEX vs CLAUDE OPUS - Benchmark",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 126,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "media_metadata": {
                        "pigzdc29cpbg1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/png",
                            "p": [
                                {
                                    "y": 65,
                                    "x": 108,
                                    "u": "https://preview.redd.it/pigzdc29cpbg1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=418476244c7ee860da9de5e6b41dd15e54eee43e"
                                },
                                {
                                    "y": 131,
                                    "x": 216,
                                    "u": "https://preview.redd.it/pigzdc29cpbg1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7a3b413b7948b47956c569e35c110f032b8d06ca"
                                },
                                {
                                    "y": 194,
                                    "x": 320,
                                    "u": "https://preview.redd.it/pigzdc29cpbg1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=711453d82de478247f768d1afc7a8064e2c19c39"
                                },
                                {
                                    "y": 389,
                                    "x": 640,
                                    "u": "https://preview.redd.it/pigzdc29cpbg1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=61ee0ce07da3a8f24dd2dee2b8ae86abda568629"
                                },
                                {
                                    "y": 584,
                                    "x": 960,
                                    "u": "https://preview.redd.it/pigzdc29cpbg1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c1289677fcc8b14c63737c8db5b7f62472180a56"
                                },
                                {
                                    "y": 657,
                                    "x": 1080,
                                    "u": "https://preview.redd.it/pigzdc29cpbg1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5372a8ae885a6d9bebe73084e371a7b947fc4a9b"
                                }
                            ],
                            "s": {
                                "y": 1042,
                                "x": 1711,
                                "u": "https://preview.redd.it/pigzdc29cpbg1.png?width=1711&amp;format=png&amp;auto=webp&amp;s=6c61253b82ad12fc5d7319f0673791d42147ce29"
                            },
                            "id": "pigzdc29cpbg1"
                        },
                        "bgy62cm3cpbg1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/png",
                            "p": [
                                {
                                    "y": 97,
                                    "x": 108,
                                    "u": "https://preview.redd.it/bgy62cm3cpbg1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a2d90dfa7e4f1c60cd54044dc6b672233e9bb81f"
                                },
                                {
                                    "y": 195,
                                    "x": 216,
                                    "u": "https://preview.redd.it/bgy62cm3cpbg1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=562fa703c56733a0eec9ccc67d234577dc7742b9"
                                },
                                {
                                    "y": 290,
                                    "x": 320,
                                    "u": "https://preview.redd.it/bgy62cm3cpbg1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=81257287a0a6f64a7a2b380b9b30d0e1b59d24a4"
                                },
                                {
                                    "y": 580,
                                    "x": 640,
                                    "u": "https://preview.redd.it/bgy62cm3cpbg1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c7c98461ce7537c8578cbc8998aa5931b73bdeaa"
                                },
                                {
                                    "y": 870,
                                    "x": 960,
                                    "u": "https://preview.redd.it/bgy62cm3cpbg1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c02513e0ca650b14acd655e1b66dd31b943385db"
                                }
                            ],
                            "s": {
                                "y": 934,
                                "x": 1030,
                                "u": "https://preview.redd.it/bgy62cm3cpbg1.png?width=1030&amp;format=png&amp;auto=webp&amp;s=b0cb325be225bd203a3359fb4d34e6105d40d6a9"
                            },
                            "id": "bgy62cm3cpbg1"
                        },
                        "1990l164cpbg1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/png",
                            "p": [
                                {
                                    "y": 85,
                                    "x": 108,
                                    "u": "https://preview.redd.it/1990l164cpbg1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9c12f9e65f72a324b7ba55c3dc1954afc84ad735"
                                },
                                {
                                    "y": 171,
                                    "x": 216,
                                    "u": "https://preview.redd.it/1990l164cpbg1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a1f8af7e5b1467f8498d3e56652afd8d3f4b0054"
                                },
                                {
                                    "y": 253,
                                    "x": 320,
                                    "u": "https://preview.redd.it/1990l164cpbg1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5b9a9153fb4cbaca1ff8441640d97f000c4ce4c7"
                                },
                                {
                                    "y": 507,
                                    "x": 640,
                                    "u": "https://preview.redd.it/1990l164cpbg1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=94796991fe041467bb5d6a093bf5783e016f07cf"
                                },
                                {
                                    "y": 761,
                                    "x": 960,
                                    "u": "https://preview.redd.it/1990l164cpbg1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0161552798e08914fea89d397de3ba413e915391"
                                }
                            ],
                            "s": {
                                "y": 787,
                                "x": 992,
                                "u": "https://preview.redd.it/1990l164cpbg1.png?width=992&amp;format=png&amp;auto=webp&amp;s=7c379389144929042ff345b110e7a6d0395eb68e"
                            },
                            "id": "1990l164cpbg1"
                        },
                        "en38sgr9cpbg1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/png",
                            "p": [
                                {
                                    "y": 128,
                                    "x": 108,
                                    "u": "https://preview.redd.it/en38sgr9cpbg1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=28ecb042aff2fe8be9cedfd38825cccf586162f4"
                                },
                                {
                                    "y": 257,
                                    "x": 216,
                                    "u": "https://preview.redd.it/en38sgr9cpbg1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fc66fd47645129dcea32f5a8859282e89ad0149d"
                                },
                                {
                                    "y": 382,
                                    "x": 320,
                                    "u": "https://preview.redd.it/en38sgr9cpbg1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f1e999bf0309b97a0506279a4e19958c84531972"
                                },
                                {
                                    "y": 764,
                                    "x": 640,
                                    "u": "https://preview.redd.it/en38sgr9cpbg1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=91554c45c126a82d01bbbcf9ffbe3a159ba741ea"
                                }
                            ],
                            "s": {
                                "y": 1046,
                                "x": 876,
                                "u": "https://preview.redd.it/en38sgr9cpbg1.png?width=876&amp;format=png&amp;auto=webp&amp;s=5d70dfc9137556c7c196663fcf01b6a968c7ce1c"
                            },
                            "id": "en38sgr9cpbg1"
                        }
                    },
                    "name": "t3_1q5elmu",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.9,
                    "author_flair_background_color": null,
                    "ups": 72,
                    "domain": "old.reddit.com",
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "gallery_data": {
                        "items": [
                            {
                                "media_id": "bgy62cm3cpbg1",
                                "id": 833211322
                            },
                            {
                                "media_id": "1990l164cpbg1",
                                "id": 833211323
                            },
                            {
                                "media_id": "pigzdc29cpbg1",
                                "id": 833211324
                            },
                            {
                                "media_id": "en38sgr9cpbg1",
                                "id": 833211325
                            }
                        ]
                    },
                    "link_flair_text": "Showcase",
                    "can_mod_post": false,
                    "score": 72,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/J3hzQh1I5c8BLmFdw5HiFtq9Rkh_1hUG7w6jkr9XaUA.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": false,
                    "subreddit_type": "public",
                    "created": 1767693713.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "total_awards_received": 0,
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay so today i promised some user here that i would do a real Claude vs CODEX benchmark and see which model hallucinates less, lies less, follows prompt properly and is generally more trustworthy partner, can &amp;quot;One shot&amp;quot; complex tasks and is more reliable.&lt;/p&gt;\n\n&lt;p&gt;Contenders - Claude Opus 4.5 vs OpenAI CODEX 5.2 XHIGH &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I did not use GPT-5.2 HIGH / XHIGH to give Claude Opus more chance, because GPT-5.2 is too much, so i used CODEX model instead.&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;I asked both models to &amp;quot;One shot&amp;quot; a TCP-based networking &amp;quot;library&amp;quot; with a little bit of complex logic involved. Here is prompt used for both Claude and Codex : &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://pastebin.com/sBeiu07z\"&gt;https://pastebin.com/sBeiu07z&lt;/a&gt; (The only difference being GitHub Repo) &lt;/p&gt;\n\n&lt;p&gt;Here is code produced by Claude: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/RtlZeroMemory/ClaudeLib\"&gt;https://github.com/RtlZeroMemory/ClaudeLib&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Here is code produced by Codex: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/RtlZeroMemory/CodexLib\"&gt;https://github.com/RtlZeroMemory/CodexLib&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;After both CODEX and CLAUDE finished their work, i wrote a special prompt for GEMINI 3 and CLAUDE CODE to review the code made by both Claude and Codex &amp;quot;Dev Sessions&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Prompt i gave to GEMINI &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://pastebin.com/ibsR0Snt\"&gt;https://pastebin.com/ibsR0Snt&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Same prompt was given to Claude Code. &lt;/p&gt;\n\n&lt;p&gt;Result evaluation in both Gemini and Claude (Claude was asked to use ULTRATHINK) &lt;/p&gt;\n\n&lt;p&gt;Gemini&amp;#39;s report on CLAUDE&amp;#39;s work: &lt;a href=\"https://pastebin.com/RkZjrn8t\"&gt;https://pastebin.com/RkZjrn8t&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Gemini&amp;#39;s report on CODEX&amp;#39;s work: &lt;a href=\"https://pastebin.com/tKUDdJ2B\"&gt;https://pastebin.com/tKUDdJ2B&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Claude Code (ULTRATHINK) report on CLAUDE&amp;#39;s work: &lt;a href=\"https://pastebin.com/27NHcprn\"&gt;https://pastebin.com/27NHcprn&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Claude Code (ULTRATHINK) report on CODEX&amp;#39;s work: &lt;a href=\"https://pastebin.com/yNyUjNqN\"&gt;https://pastebin.com/yNyUjNqN&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Attaching screenshots as well. &lt;/p&gt;\n\n&lt;p&gt;Basically Claude as always FAILS to deliver working solution if code is big and complex enough and can&amp;#39;t &amp;quot;One shot&amp;quot; anything, despite being fast and really nice to use and a better tool overall (CLI). Model is quite &amp;quot;dumber&amp;quot;, lies more, hallucinates more and deceives more. &lt;/p&gt;\n\n&lt;p&gt;Needs to work on smaller chunks, constant overwatch and careful checks, otherwise it will lie to you about implementing things it did not in fact implement or did incorrectly. &lt;/p&gt;\n\n&lt;p&gt;CODEX and GPT-5.2 are MUCH more reliable and &amp;quot;smarter&amp;quot;, but work slower and take time. Claude finished its job in 13 minutes or so, while CODEX XHIGH took a while more, however result is what is important, not speed to me. &lt;/p&gt;\n\n&lt;p&gt;And this is consistent result for me.&lt;/p&gt;\n\n&lt;p&gt;I use Claude as &amp;quot;Code Monkey&amp;quot;, NEVER EVER trust it. It will LIE and deceive you, claiming your code is &amp;quot;Production ready&amp;quot;, when in fact it is not. Need to keep it in check. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "url_overridden_by_dest": "https://www.reddit.com/gallery/1q5elmu",
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "e350908e-b24e-11f0-b239-62e50da6d05a",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "mod_note": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "num_reports": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#00ff2a",
                    "id": "1q5elmu",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "muchsamurai",
                    "discussion_type": null,
                    "num_comments": 44,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q5elmu/codex_vs_claude_opus_benchmark/",
                    "stickied": false,
                    "url": "https://www.reddit.com/gallery/1q5elmu",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767693713.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "How can you do this to us??\n\nClaude users get 20x base plan\n\nand we get 6x base plan for $200/month?\n\nhow the hell is this even competitive ?\n\nplease fix this immediately\n\nsigned,\n\nWe, the codex pro users.",
                    "author_fullname": "t2_1dvb1fztcc",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "IM ****ING OUTRAGED PRO IS ONLY 6X PLUS PLAN",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1qclg1l",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.47,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 0,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Complaint",
                    "can_mod_post": false,
                    "score": 0,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1768391946.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How can you do this to us??&lt;/p&gt;\n\n&lt;p&gt;Claude users get 20x base plan&lt;/p&gt;\n\n&lt;p&gt;and we get 6x base plan for $200/month?&lt;/p&gt;\n\n&lt;p&gt;how the hell is this even competitive ?&lt;/p&gt;\n\n&lt;p&gt;please fix this immediately&lt;/p&gt;\n\n&lt;p&gt;signed,&lt;/p&gt;\n\n&lt;p&gt;We, the codex pro users.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "3090d6a0-ab11-11f0-a7f1-526fbbfcd846",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#f40b0b",
                    "id": "1qclg1l",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Just_Lingonberry_352",
                    "discussion_type": null,
                    "num_comments": 50,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1qclg1l/im_ing_outraged_pro_is_only_6x_plus_plan/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1qclg1l/im_ing_outraged_pro_is_only_6x_plus_plan/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1768391946.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Hello, I basically work on C/C++ projects and I wanna say from all the models I've used from GPT the GPT 5.2 and GPT 5.2 Codex are the best\n\nThe XH Thinking is just on a whole other level, GPT 5.1 Codex Max was giving me tons of errors that GPT 5.2 was able to solve while he was thinking, tested Claude Opus Claude Sonnet but nothing can beat GPT 5.2, so please OpenAI developers do not modify this model quality not speed please!\n\nIt's just on a whole other level for anything I've tested right now same goes with Windows Kernel from what I've tested it on, still I won't advise to be used in this kind of field for Production reasons but at the moment it's just very good.. and I hope it will keep improving.",
                    "author_fullname": "t2_24b1nni4bq",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "GPT 5.2 and Codex, is just amazing...",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1ppzqv6",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.98,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 90,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Praise",
                    "can_mod_post": false,
                    "score": 90,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766086057.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I basically work on C/C++ projects and I wanna say from all the models I&amp;#39;ve used from GPT the GPT 5.2 and GPT 5.2 Codex are the best&lt;/p&gt;\n\n&lt;p&gt;The XH Thinking is just on a whole other level, GPT 5.1 Codex Max was giving me tons of errors that GPT 5.2 was able to solve while he was thinking, tested Claude Opus Claude Sonnet but nothing can beat GPT 5.2, so please OpenAI developers do not modify this model quality not speed please!&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s just on a whole other level for anything I&amp;#39;ve tested right now same goes with Windows Kernel from what I&amp;#39;ve tested it on, still I won&amp;#39;t advise to be used in this kind of field for Production reasons but at the moment it&amp;#39;s just very good.. and I hope it will keep improving.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "a1d1fcda-b24c-11f0-a8b0-4ea6c7db837e",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#eeff00",
                    "id": "1ppzqv6",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Old-Duck-5645",
                    "discussion_type": null,
                    "num_comments": 37,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1ppzqv6/gpt_52_and_codex_is_just_amazing/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1ppzqv6/gpt_52_and_codex_is_just_amazing/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766086057.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "It seems we are getting new Codex Model very soon\n\n[https://github.com/openai/codex/commit/774bd9e432fa2e0f4e059e97648cf92216912e19#diff-882f44491bbf5ef5e1adaee4e97d2ac7ac9dcc8d54c28be056035e863887b704](https://github.com/openai/codex/commit/774bd9e432fa2e0f4e059e97648cf92216912e19#diff-882f44491bbf5ef5e1adaee4e97d2ac7ac9dcc8d54c28be056035e863887b704)\n\n\n\nWhat are your thoughts and expectations about it?\n\n  \nTo me 5.2 seems incredibly good and my hope is that codex would be able to output similar quality but with bigger tps or less tokens for the same quality.",
                    "author_fullname": "t2_95cnl15j",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "New Codex model is getting closer.",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1ppcw20",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.98,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 48,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "News",
                    "can_mod_post": false,
                    "score": 48,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766017598.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It seems we are getting new Codex Model very soon&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/openai/codex/commit/774bd9e432fa2e0f4e059e97648cf92216912e19#diff-882f44491bbf5ef5e1adaee4e97d2ac7ac9dcc8d54c28be056035e863887b704\"&gt;https://github.com/openai/codex/commit/774bd9e432fa2e0f4e059e97648cf92216912e19#diff-882f44491bbf5ef5e1adaee4e97d2ac7ac9dcc8d54c28be056035e863887b704&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts and expectations about it?&lt;/p&gt;\n\n&lt;p&gt;To me 5.2 seems incredibly good and my hope is that codex would be able to output similar quality but with bigger tps or less tokens for the same quality.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/MyWR8_-vpQZb8S26bRXc_zcSBGepCvczoU0USTlkg_A.png?auto=webp&amp;s=3ce1e602aacceb1447619bb7c1f65e4fe943f5ee",
                                    "width": 1200,
                                    "height": 600
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/MyWR8_-vpQZb8S26bRXc_zcSBGepCvczoU0USTlkg_A.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=95fa19ac2fa5177d094eea822fcd9d2c924e92e9",
                                        "width": 108,
                                        "height": 54
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/MyWR8_-vpQZb8S26bRXc_zcSBGepCvczoU0USTlkg_A.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f4db18f195e54516dada98d2e458f030d12c1dee",
                                        "width": 216,
                                        "height": 108
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/MyWR8_-vpQZb8S26bRXc_zcSBGepCvczoU0USTlkg_A.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2b3eedb9df899fab4d214ff6cc981a01e63e73ab",
                                        "width": 320,
                                        "height": 160
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/MyWR8_-vpQZb8S26bRXc_zcSBGepCvczoU0USTlkg_A.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4c8dc0a5f459b49c41b47c09f91cd82de678270d",
                                        "width": 640,
                                        "height": 320
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/MyWR8_-vpQZb8S26bRXc_zcSBGepCvczoU0USTlkg_A.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f3ee1e71197a652031180a9a43aebd2c6788308b",
                                        "width": 960,
                                        "height": 480
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/MyWR8_-vpQZb8S26bRXc_zcSBGepCvczoU0USTlkg_A.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8d5c599bc2aff0bad065995fd2d27bc8a280ff10",
                                        "width": 1080,
                                        "height": 540
                                    }
                                ],
                                "variants": {},
                                "id": "MyWR8_-vpQZb8S26bRXc_zcSBGepCvczoU0USTlkg_A"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "d91881fa-8c86-11f0-9995-42042a14a711",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "transparent",
                    "id": "1ppcw20",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Eczuu",
                    "discussion_type": null,
                    "num_comments": 33,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1ppcw20/new_codex_model_is_getting_closer/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1ppcw20/new_codex_model_is_getting_closer/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766017598.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "I've been spending the last week integrating the new GPT-5.2 Codex endpoints into my agent swarm, and I have to admit, the gap is closing fast.\n\nFor the last few months, Claude 4.5 Opus has been my undisputed go-to for complex reasoning and large-context architecture planning. It just seemed to 'get' the broader system design better than anything else.\n\nBut this new 5.2 update from OpenAI feels different. It's not just the raw coding speed\u2014it's the instruction following on multi-step tasks. I noticed it maintains context across 20+ file edits with way less drift than the base GPT-5 model.\n\nI'm curious what everyone else is seeing. Are you sticking with Opus for the deep architectural thinking, or has the new Codex model become \"good enough\" at reasoning that the speed tradeoff makes it the new default?\n\nPersonally, I'm finding myself using a hybrid approach: Opus for the spec, 5.2 for the implementation. But I'm tempted to switch fully just for the latency improvements. Thoughts?",
                    "author_fullname": "t2_1nnjuebp9a",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Real talk: Has GPT-5.2 Codex finally dethroned Claude 4.5 Opus for complex agentic workflows?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q4tzj8",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.92,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 52,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Comparison",
                    "can_mod_post": false,
                    "score": 52,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767638316.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been spending the last week integrating the new GPT-5.2 Codex endpoints into my agent swarm, and I have to admit, the gap is closing fast.&lt;/p&gt;\n\n&lt;p&gt;For the last few months, Claude 4.5 Opus has been my undisputed go-to for complex reasoning and large-context architecture planning. It just seemed to &amp;#39;get&amp;#39; the broader system design better than anything else.&lt;/p&gt;\n\n&lt;p&gt;But this new 5.2 update from OpenAI feels different. It&amp;#39;s not just the raw coding speed\u2014it&amp;#39;s the instruction following on multi-step tasks. I noticed it maintains context across 20+ file edits with way less drift than the base GPT-5 model.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious what everyone else is seeing. Are you sticking with Opus for the deep architectural thinking, or has the new Codex model become &amp;quot;good enough&amp;quot; at reasoning that the speed tradeoff makes it the new default?&lt;/p&gt;\n\n&lt;p&gt;Personally, I&amp;#39;m finding myself using a hybrid approach: Opus for the spec, 5.2 for the implementation. But I&amp;#39;m tempted to switch fully just for the latency improvements. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "b81001d4-8c88-11f0-8523-42042a14a711",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#817e7e",
                    "id": "1q4tzj8",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "HarrisonAIx",
                    "discussion_type": null,
                    "num_comments": 28,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q4tzj8/real_talk_has_gpt52_codex_finally_dethroned/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q4tzj8/real_talk_has_gpt52_codex_finally_dethroned/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767638316.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "codex-5.2-high and normal 5.2-high regularly takes several hours at a time and not producing much even with very detailed instructions where i show it exactly which files to work on.. it would constantly show plan checkboxes and cycle between reading, searching occasionally producing code but thats after HOURS were spent\n\nthis is happening with consistency that i question if we are being throttled or queued even though codex is still working. if someone at openai could offer a response it would be great but its very concerning that my productivity has plummeted since whatever changes were made \n\ni dont know whats going on i think the compactions aren't working as nicely as it was in opus. after the 8th or 9 compacted message, the performance degrades signifcantly\n\nas we talk i have several parallel mix of xhigh and 5.2-high tasks running. 5 out of 7 have been doing nothing but reading/searching/planning for very specific instructions i've provided. \n\nthe 200k context limit is really limiting the full potential of 5.2 models. gemini cli in contrast has 1 million and its nowhere near as this lazy.\n\n**update: /u/vaibhavs10 suggestion works medium actually helping me move faster now. confusing since i expected high/xhigh to be more performant and figured i need all the juice i can get. will keep taking notes here**",
                    "author_fullname": "t2_1dvb1fztcc",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "getting very little done due to excessive times codex takes to work on tasks",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q03tuy",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.88,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 30,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Complaint",
                    "can_mod_post": false,
                    "score": 30,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": 1767175103.0,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767155420.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;codex-5.2-high and normal 5.2-high regularly takes several hours at a time and not producing much even with very detailed instructions where i show it exactly which files to work on.. it would constantly show plan checkboxes and cycle between reading, searching occasionally producing code but thats after HOURS were spent&lt;/p&gt;\n\n&lt;p&gt;this is happening with consistency that i question if we are being throttled or queued even though codex is still working. if someone at openai could offer a response it would be great but its very concerning that my productivity has plummeted since whatever changes were made &lt;/p&gt;\n\n&lt;p&gt;i dont know whats going on i think the compactions aren&amp;#39;t working as nicely as it was in opus. after the 8th or 9 compacted message, the performance degrades signifcantly&lt;/p&gt;\n\n&lt;p&gt;as we talk i have several parallel mix of xhigh and 5.2-high tasks running. 5 out of 7 have been doing nothing but reading/searching/planning for very specific instructions i&amp;#39;ve provided. &lt;/p&gt;\n\n&lt;p&gt;the 200k context limit is really limiting the full potential of 5.2 models. gemini cli in contrast has 1 million and its nowhere near as this lazy.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;update: &lt;a href=\"/u/vaibhavs10\"&gt;/u/vaibhavs10&lt;/a&gt; suggestion works medium actually helping me move faster now. confusing since i expected high/xhigh to be more performant and figured i need all the juice i can get. will keep taking notes here&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "3090d6a0-ab11-11f0-a7f1-526fbbfcd846",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#f40b0b",
                    "id": "1q03tuy",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Just_Lingonberry_352",
                    "discussion_type": null,
                    "num_comments": 30,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q03tuy/getting_very_little_done_due_to_excessive_times/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q03tuy/getting_very_little_done_due_to_excessive_times/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767155420.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Anyone have the gpt $200 pro plan?\n\nIf anyone has a similar workflow or use case, I curious to know about how much use you get out per month? Say compared to anthropic 20x? It seems like openai is more generous with tokens than anthropic. Anthropics plans have seemed to run out quicker now than usual.\n\nI've been using codex 5.2 xhigh or 5.2 xhigh for a lot of full app planning or large multi epic planning for fairly complex projects. I also use it for coding at times, especially debugging was opus has messed up. \n\nOr if anyone has had multiple $20 gpt subs, how has that been with switching between subs via ide extension or terminal? Any pain points?\n\nThanks\n\nCheers!",
                    "author_fullname": "t2_ctajx2kl",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Question abt $200 plan limits",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1qb2z1y",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 16,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Question",
                    "can_mod_post": false,
                    "score": 16,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1768242742.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone have the gpt $200 pro plan?&lt;/p&gt;\n\n&lt;p&gt;If anyone has a similar workflow or use case, I curious to know about how much use you get out per month? Say compared to anthropic 20x? It seems like openai is more generous with tokens than anthropic. Anthropics plans have seemed to run out quicker now than usual.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been using codex 5.2 xhigh or 5.2 xhigh for a lot of full app planning or large multi epic planning for fairly complex projects. I also use it for coding at times, especially debugging was opus has messed up. &lt;/p&gt;\n\n&lt;p&gt;Or if anyone has had multiple $20 gpt subs, how has that been with switching between subs via ide extension or terminal? Any pain points?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n\n&lt;p&gt;Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "302c6282-b24c-11f0-a6c9-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c13e80",
                    "id": "1qb2z1y",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Amazing_Ad9369",
                    "discussion_type": null,
                    "num_comments": 26,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1qb2z1y/question_abt_200_plan_limits/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1qb2z1y/question_abt_200_plan_limits/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1768242742.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Codex now officially supports skills\n\nhttps://developers.openai.com/codex/skills\n\nSkills are reusable bundles of instructions, scripts, and resources that help Codex complete specific tasks.\n\nYou can call a skill directly with $.skill-name, or let Codex choose the right one based on your prompt.\n\nFollowing the agentskills.io standard, a skill is just a folder: SKILL.md for instructions + metadata, with optional scripts, references, and assets.\n\nIf anyone wants to test this out with existing skills we just shipped the first universal skill installer built on top of the open agent skills standard \n\nnpx Ai-Agent-Skills install frontend-design \u2014agent \u2014codex \n\n30 of the most starred Claude skills ever, now available instantly to Codex\n\nhttps://github.com/skillcreatorai/Ai-Agent-Skills",
                    "author_fullname": "t2_23zhgim9u2",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Codex now officially supports skills",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1pqyev8",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.97,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 84,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "News",
                    "can_mod_post": false,
                    "score": 84,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": true,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766183627.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Codex now officially supports skills&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://developers.openai.com/codex/skills\"&gt;https://developers.openai.com/codex/skills&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Skills are reusable bundles of instructions, scripts, and resources that help Codex complete specific tasks.&lt;/p&gt;\n\n&lt;p&gt;You can call a skill directly with $.skill-name, or let Codex choose the right one based on your prompt.&lt;/p&gt;\n\n&lt;p&gt;Following the agentskills.io standard, a skill is just a folder: SKILL.md for instructions + metadata, with optional scripts, references, and assets.&lt;/p&gt;\n\n&lt;p&gt;If anyone wants to test this out with existing skills we just shipped the first universal skill installer built on top of the open agent skills standard &lt;/p&gt;\n\n&lt;p&gt;npx Ai-Agent-Skills install frontend-design \u2014agent \u2014codex &lt;/p&gt;\n\n&lt;p&gt;30 of the most starred Claude skills ever, now available instantly to Codex&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/skillcreatorai/Ai-Agent-Skills\"&gt;https://github.com/skillcreatorai/Ai-Agent-Skills&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?auto=webp&amp;s=069f20773972e7174872761253c50a1597e321f8",
                                    "width": 2400,
                                    "height": 903
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e3f265b33937cdd7d282a3b805d8b3aca8aecca8",
                                        "width": 108,
                                        "height": 40
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a3d4abd8843027da5713b715cd6bfc5df6e5e4cb",
                                        "width": 216,
                                        "height": 81
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7986930e7db3d10096334d8740c477e4faaced51",
                                        "width": 320,
                                        "height": 120
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=74fa25b2b23656a2cc9c0fee548229c63af35433",
                                        "width": 640,
                                        "height": 240
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f58b50ca3507b4d3ed0b34bf90b1d85e69cf2c30",
                                        "width": 960,
                                        "height": 361
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=391142286c70f8c149866fb27914cda903d869d2",
                                        "width": 1080,
                                        "height": 406
                                    }
                                ],
                                "variants": {},
                                "id": "IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "d91881fa-8c86-11f0-9995-42042a14a711",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "transparent",
                    "id": "1pqyev8",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Afraid-Today98",
                    "discussion_type": null,
                    "num_comments": 19,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1pqyev8/codex_now_officially_supports_skills/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1pqyev8/codex_now_officially_supports_skills/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766183627.0,
                    "num_crossposts": 2,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Previously, I made a [post](https://www.reddit.com/r/codex/comments/1p82rgg/codex_price_increased_by_100/) about how I experienced a 50% drop in usage limits, equating to a 100% increase in price.\n\nThis was denied and explained by various \"bugs\" or \"cache reads\" issues. They said I couldn't directly compare the usage based on the dashboard metrics because they \"changed\" the way the accounting worked.\n\nAfter reaching out to support, they claimed that the issue was mainly to due with cache reads being reduced.\n\nThis is completely falsified by the numbers. They lied to me.\n\nNow, I have the actual numbers to back it up.\n\nAs you can see, between Oct and Nov, you can see a roughly 35% drop in the overall token usage.\n\nThe cache reads remained the same, with it actually being slightly better in Nov, contrary to their claims.\n\nThis substantiates the drop in usage limit I experienced.\n\nThis doesn't even account for the fact that in the beginning of Nov, they reset the limits multiple times where I got extra usage. Which would get it closer to the experienced 50% reduction in usage.\n\nHow does OpenAI explain this?\n\nWith that being said, I would say that the value we're getting at these rates is still exceptional, especially based on the quality of the performance by the model.\n\nI'm particularly impressed by the latest 5.2 model and would prefer it over Claude and Gemini. So I am not complaining.",
                    "author_fullname": "t2_d73rn",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Proof of Usage Reduction by Nearly 40%",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 27,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1puc3t3",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "ups": 66,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": true,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Limits",
                    "can_mod_post": false,
                    "score": 66,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/AEE49SwQNHpj633KQVHckVxltwPc96VYwgGQxR3xjsw.jpg",
                    "edited": 1766549832.0,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "image",
                    "content_categories": null,
                    "is_self": false,
                    "subreddit_type": "public",
                    "created": 1766543258.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "i.redd.it",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Previously, I made a &lt;a href=\"https://www.reddit.com/r/codex/comments/1p82rgg/codex_price_increased_by_100/\"&gt;post&lt;/a&gt; about how I experienced a 50% drop in usage limits, equating to a 100% increase in price.&lt;/p&gt;\n\n&lt;p&gt;This was denied and explained by various &amp;quot;bugs&amp;quot; or &amp;quot;cache reads&amp;quot; issues. They said I couldn&amp;#39;t directly compare the usage based on the dashboard metrics because they &amp;quot;changed&amp;quot; the way the accounting worked.&lt;/p&gt;\n\n&lt;p&gt;After reaching out to support, they claimed that the issue was mainly to due with cache reads being reduced.&lt;/p&gt;\n\n&lt;p&gt;This is completely falsified by the numbers. They lied to me.&lt;/p&gt;\n\n&lt;p&gt;Now, I have the actual numbers to back it up.&lt;/p&gt;\n\n&lt;p&gt;As you can see, between Oct and Nov, you can see a roughly 35% drop in the overall token usage.&lt;/p&gt;\n\n&lt;p&gt;The cache reads remained the same, with it actually being slightly better in Nov, contrary to their claims.&lt;/p&gt;\n\n&lt;p&gt;This substantiates the drop in usage limit I experienced.&lt;/p&gt;\n\n&lt;p&gt;This doesn&amp;#39;t even account for the fact that in the beginning of Nov, they reset the limits multiple times where I got extra usage. Which would get it closer to the experienced 50% reduction in usage.&lt;/p&gt;\n\n&lt;p&gt;How does OpenAI explain this?&lt;/p&gt;\n\n&lt;p&gt;With that being said, I would say that the value we&amp;#39;re getting at these rates is still exceptional, especially based on the quality of the performance by the model.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m particularly impressed by the latest 5.2 model and would prefer it over Claude and Gemini. So I am not complaining.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "url_overridden_by_dest": "https://i.redd.it/lpgggt5h529g1.png",
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://preview.redd.it/lpgggt5h529g1.png?auto=webp&amp;s=5205c958ce768d6d1adfa6d1e2bb16806c723837",
                                    "width": 1711,
                                    "height": 334
                                },
                                "resolutions": [
                                    {
                                        "url": "https://preview.redd.it/lpgggt5h529g1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9acf690cbdf874b96808f211b6f6d7ef625e7bbb",
                                        "width": 108,
                                        "height": 21
                                    },
                                    {
                                        "url": "https://preview.redd.it/lpgggt5h529g1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6fab9766121542a51e14f79903385cc3352dbb8d",
                                        "width": 216,
                                        "height": 42
                                    },
                                    {
                                        "url": "https://preview.redd.it/lpgggt5h529g1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=279973ac4b422954f040f54c6c837e668013b9ac",
                                        "width": 320,
                                        "height": 62
                                    },
                                    {
                                        "url": "https://preview.redd.it/lpgggt5h529g1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=be025bbe074a1a656448c4fec2f6a30efa4e5d4b",
                                        "width": 640,
                                        "height": 124
                                    },
                                    {
                                        "url": "https://preview.redd.it/lpgggt5h529g1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9bd51bccf2e8e450e1422bdd5f871b3571908bf4",
                                        "width": 960,
                                        "height": 187
                                    },
                                    {
                                        "url": "https://preview.redd.it/lpgggt5h529g1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8231531a718a8abc224b5cd4aa17bb4acdc4e488",
                                        "width": 1080,
                                        "height": 210
                                    }
                                ],
                                "variants": {},
                                "id": "kdTODpU6W4Pf632MF-OTU0nKC5ehJQTfWXICJIFlSnU"
                            }
                        ],
                        "enabled": true
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "21466776-922c-11f0-88d8-d2c5faeac8bd",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "mod_note": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "num_reports": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c73838",
                    "id": "1puc3t3",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "immortalsol",
                    "discussion_type": null,
                    "num_comments": 20,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1puc3t3/proof_of_usage_reduction_by_nearly_40/",
                    "stickied": false,
                    "url": "https://i.redd.it/lpgggt5h529g1.png",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766543258.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Up to maybe yesterday, the model was working amazing and was being incredibly persistent. I know this post is going to sound like the average \"the model is getting dumber post\" and while I can't prove definitively they *are* nerfing it, it sure feels like a bit of a drop off.\n\nNow in the past two days, it has become incredibly lazy. I've never ever seen this model stress so much about \"time limits\" or \"time running out\" in its reasoning summary, yet here we are.\n\nThis has always been an issue but solely on Codex web. Now it seems to have come to the CLI?\n\nIt has gotten so bad I am actively hoping for auto compaction to kick in sooner rather than later so the new model will stop stressing about time limits and *actually* finish its work.\n\nNow, in order to achieve long running tasks, it takes maybe 10 different prompts. The usual issues are:\n1. Reward hacking.\n2. Being lazy from the get go and leaving work half-done.\n3. Seemingly intentionally misinterpreting my prompt just to do less work.\n4. (NEW) overly-complaining and stressing about time limits.\n\nFrom this post it may seem like I'm being incredibly negative but in truth I'm really spoiled - this is an amazing model and many of these issues exist in more severe forms with other providers.\n\nI recently got Codex to run for a huge 26 hours. When I set the reasoning to xhigh, I want this to be the default behavior. I'm not saying the model should always work for 26 hours, I'm saying it should work TILL completion and not skimp out on anything, whether this takes a very long time or not.\n\nThis seems like a reasonable ask. I get OpenAI are incentivized to save costs and many users are complaining about extreme time-taking, but we're the ones paying for the model therefore we should be able to use its full capabilities. If the model is taking too long, set the reasoning lower - it's not really rocket science.\n\nFor context, this has been most noticeable in reverse engineering tasks which Codex excels at. But in many scenarios, there may not be an end in sight and progress may seem to be stalling which seems to equate to Codex wanting to stop early when it can't keep iterating fast and really has to get into the nitty gritty.",
                    "author_fullname": "t2_1s4jp83y",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "What the hell is up with GPT-5.2-Codex xhigh in the CLI?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1qboj3v",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.88,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 13,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Complaint",
                    "can_mod_post": false,
                    "score": 13,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": 1768302847.0,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1768302300.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Up to maybe yesterday, the model was working amazing and was being incredibly persistent. I know this post is going to sound like the average &amp;quot;the model is getting dumber post&amp;quot; and while I can&amp;#39;t prove definitively they &lt;em&gt;are&lt;/em&gt; nerfing it, it sure feels like a bit of a drop off.&lt;/p&gt;\n\n&lt;p&gt;Now in the past two days, it has become incredibly lazy. I&amp;#39;ve never ever seen this model stress so much about &amp;quot;time limits&amp;quot; or &amp;quot;time running out&amp;quot; in its reasoning summary, yet here we are.&lt;/p&gt;\n\n&lt;p&gt;This has always been an issue but solely on Codex web. Now it seems to have come to the CLI?&lt;/p&gt;\n\n&lt;p&gt;It has gotten so bad I am actively hoping for auto compaction to kick in sooner rather than later so the new model will stop stressing about time limits and &lt;em&gt;actually&lt;/em&gt; finish its work.&lt;/p&gt;\n\n&lt;p&gt;Now, in order to achieve long running tasks, it takes maybe 10 different prompts. The usual issues are:\n1. Reward hacking.\n2. Being lazy from the get go and leaving work half-done.\n3. Seemingly intentionally misinterpreting my prompt just to do less work.\n4. (NEW) overly-complaining and stressing about time limits.&lt;/p&gt;\n\n&lt;p&gt;From this post it may seem like I&amp;#39;m being incredibly negative but in truth I&amp;#39;m really spoiled - this is an amazing model and many of these issues exist in more severe forms with other providers.&lt;/p&gt;\n\n&lt;p&gt;I recently got Codex to run for a huge 26 hours. When I set the reasoning to xhigh, I want this to be the default behavior. I&amp;#39;m not saying the model should always work for 26 hours, I&amp;#39;m saying it should work TILL completion and not skimp out on anything, whether this takes a very long time or not.&lt;/p&gt;\n\n&lt;p&gt;This seems like a reasonable ask. I get OpenAI are incentivized to save costs and many users are complaining about extreme time-taking, but we&amp;#39;re the ones paying for the model therefore we should be able to use its full capabilities. If the model is taking too long, set the reasoning lower - it&amp;#39;s not really rocket science.&lt;/p&gt;\n\n&lt;p&gt;For context, this has been most noticeable in reverse engineering tasks which Codex excels at. But in many scenarios, there may not be an end in sight and progress may seem to be stalling which seems to equate to Codex wanting to stop early when it can&amp;#39;t keep iterating fast and really has to get into the nitty gritty.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "3090d6a0-ab11-11f0-a7f1-526fbbfcd846",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#f40b0b",
                    "id": "1qboj3v",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "RoadRunnerChris",
                    "discussion_type": null,
                    "num_comments": 18,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1qboj3v/what_the_hell_is_up_with_gpt52codex_xhigh_in_the/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1qboj3v/what_the_hell_is_up_with_gpt52codex_xhigh_in_the/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1768302300.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "No matter what flags I use or what settings I have in my config.toml, Codex will only run for a minute or two and then ask me what to do next. Is there any way to make it more decisive and stop requiring constant manual feedback?\n\n  \nI have been using [this page](https://developers.openai.com/codex/security/) for reference.",
                    "author_fullname": "t2_py2udog9",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "How to make Codex stop being so needy?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 104,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q2yqe8",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.86,
                    "author_flair_background_color": null,
                    "ups": 14,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": true,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Question",
                    "can_mod_post": false,
                    "score": 14,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": true,
                    "thumbnail": "https://b.thumbs.redditmedia.com/qYIJe_bTpNsUt5MG5zgm-udfsKWix1ntD19faMDT8hM.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "image",
                    "content_categories": null,
                    "is_self": false,
                    "subreddit_type": "public",
                    "created": 1767457361.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "i.redd.it",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;No matter what flags I use or what settings I have in my config.toml, Codex will only run for a minute or two and then ask me what to do next. Is there any way to make it more decisive and stop requiring constant manual feedback?&lt;/p&gt;\n\n&lt;p&gt;I have been using &lt;a href=\"https://developers.openai.com/codex/security/\"&gt;this page&lt;/a&gt; for reference.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "url_overridden_by_dest": "https://i.redd.it/qjgjhd9os5bg1.jpeg",
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://preview.redd.it/qjgjhd9os5bg1.jpeg?auto=webp&amp;s=3a7df07cf4cd3c2d658a9dc419a3aa9b9f34dbf2",
                                    "width": 259,
                                    "height": 194
                                },
                                "resolutions": [
                                    {
                                        "url": "https://preview.redd.it/qjgjhd9os5bg1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0de18219cb72a5453a764098505ada9f5d8eca06",
                                        "width": 108,
                                        "height": 80
                                    },
                                    {
                                        "url": "https://preview.redd.it/qjgjhd9os5bg1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cf67e3d4063dc8a3863ff07533c01c7f99ca7455",
                                        "width": 216,
                                        "height": 161
                                    }
                                ],
                                "variants": {},
                                "id": "be8JvU8D_A9UVFl_y2CxKK1t36Iu87Mjq_OHysTy7vE"
                            }
                        ],
                        "enabled": true
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "302c6282-b24c-11f0-a6c9-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "mod_note": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "num_reports": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c13e80",
                    "id": "1q2yqe8",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Go_mo_to",
                    "discussion_type": null,
                    "num_comments": 19,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q2yqe8/how_to_make_codex_stop_being_so_needy/",
                    "stickied": false,
                    "url": "https://i.redd.it/qjgjhd9os5bg1.jpeg",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767457361.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Okay after not using OpenAI like a 1 year, i decided to give a shot on it. \n\nI currently tried GPT 5.2 xhigh with Codex/NPM (Windows Native)\n\nAnd i must say it is surprisingly great!\n\nI saw some people complaining Codex thinking for straight 1 hour and yes, Codex thinking is very slow and long but instead trial and error with other models, i prefer Codex doing 1 hour thinking and almost one shot fix every problem i have.\n\nOpus 4.5 was also overall was a great model, but it's really lazy. Always leaves ToDo's/Stubs in complex projects. Compacting the chats also really terrible because it always forgets the little information you have given. It's really good for quick and mid tasks though. Sometimes refuses users instructions as well...\n\nWhat i wrote can be applied to Gemini as well but it's better than Opus at problem solving...\n\nOverall GPT 5.2 xhigh did whatever i asked with no hassle. \n\nIf it was only much more faster and had subagent support. Then yeah it would be another level.",
                    "author_fullname": "t2_8nay1ka",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Codex gets shit done!",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q80k71",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.92,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 44,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Comparison",
                    "can_mod_post": false,
                    "score": 44,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767938965.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay after not using OpenAI like a 1 year, i decided to give a shot on it. &lt;/p&gt;\n\n&lt;p&gt;I currently tried GPT 5.2 xhigh with Codex/NPM (Windows Native)&lt;/p&gt;\n\n&lt;p&gt;And i must say it is surprisingly great!&lt;/p&gt;\n\n&lt;p&gt;I saw some people complaining Codex thinking for straight 1 hour and yes, Codex thinking is very slow and long but instead trial and error with other models, i prefer Codex doing 1 hour thinking and almost one shot fix every problem i have.&lt;/p&gt;\n\n&lt;p&gt;Opus 4.5 was also overall was a great model, but it&amp;#39;s really lazy. Always leaves ToDo&amp;#39;s/Stubs in complex projects. Compacting the chats also really terrible because it always forgets the little information you have given. It&amp;#39;s really good for quick and mid tasks though. Sometimes refuses users instructions as well...&lt;/p&gt;\n\n&lt;p&gt;What i wrote can be applied to Gemini as well but it&amp;#39;s better than Opus at problem solving...&lt;/p&gt;\n\n&lt;p&gt;Overall GPT 5.2 xhigh did whatever i asked with no hassle. &lt;/p&gt;\n\n&lt;p&gt;If it was only much more faster and had subagent support. Then yeah it would be another level.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "b81001d4-8c88-11f0-8523-42042a14a711",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#817e7e",
                    "id": "1q80k71",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "BlackShadowX306",
                    "discussion_type": null,
                    "num_comments": 14,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q80k71/codex_gets_shit_done/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q80k71/codex_gets_shit_done/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767938965.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "You've gotta do something about the weekly limit, I understand the need for limits, on low cost packages especially 20$ isn't a ton,  but getting cut off with 4 days left because the model got stuck a bit and went through a shit ton of tokens, or cat'd a few files it shouldn't have just.... it hurts.\n\nCodex High is just SO GOOD, but the weekly limit just makes me afraid to really let it run and do what it does well.. because i'm afraid i'll burn my week, and end up stuck in 2 days needing to ask something and not being able to ....\n\nHow about a slow-queue or something for users who hit their weekly limit, i wouldn't mind hitting the limit and then being put in a slow-path where i have to wait for my turn if it meant the work got done (Trae style).\n\nAt least i wouldn't just be dead in the water for 3-4 days.\n\nOpenAI has the chance to differentiate itself from Claude, and now even Gemini, a lot of people went to Gemini because they didnt have weekly limits and had insane block limits... but they added weekly limits and are even less upfront about the usage levels than openai is...\n\nSo now i'm sure theirs a ton load of people who went to gemini looking for an answer now... giving users who can't afford 200$ a month for hobby projects, an option, a solution, for when we hit our weekly limit to still get some work done would just be so good.\n\nI know OpenAI likely uses preempt-able instances, so why not do that for a past-limit slow-queue option?\n\nEDIT: I use medium and high, i use high when i have complicated issues that aren't getting solved or need some real understanding around the underlying problem space.",
                    "author_fullname": "t2_vc4z2",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "OpenAI, Please...",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1qaix9k",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.38,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 0,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Suggestion",
                    "can_mod_post": false,
                    "score": 0,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": 1768185573.0,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1768185308.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You&amp;#39;ve gotta do something about the weekly limit, I understand the need for limits, on low cost packages especially 20$ isn&amp;#39;t a ton,  but getting cut off with 4 days left because the model got stuck a bit and went through a shit ton of tokens, or cat&amp;#39;d a few files it shouldn&amp;#39;t have just.... it hurts.&lt;/p&gt;\n\n&lt;p&gt;Codex High is just SO GOOD, but the weekly limit just makes me afraid to really let it run and do what it does well.. because i&amp;#39;m afraid i&amp;#39;ll burn my week, and end up stuck in 2 days needing to ask something and not being able to ....&lt;/p&gt;\n\n&lt;p&gt;How about a slow-queue or something for users who hit their weekly limit, i wouldn&amp;#39;t mind hitting the limit and then being put in a slow-path where i have to wait for my turn if it meant the work got done (Trae style).&lt;/p&gt;\n\n&lt;p&gt;At least i wouldn&amp;#39;t just be dead in the water for 3-4 days.&lt;/p&gt;\n\n&lt;p&gt;OpenAI has the chance to differentiate itself from Claude, and now even Gemini, a lot of people went to Gemini because they didnt have weekly limits and had insane block limits... but they added weekly limits and are even less upfront about the usage levels than openai is...&lt;/p&gt;\n\n&lt;p&gt;So now i&amp;#39;m sure theirs a ton load of people who went to gemini looking for an answer now... giving users who can&amp;#39;t afford 200$ a month for hobby projects, an option, a solution, for when we hit our weekly limit to still get some work done would just be so good.&lt;/p&gt;\n\n&lt;p&gt;I know OpenAI likely uses preempt-able instances, so why not do that for a past-limit slow-queue option?&lt;/p&gt;\n\n&lt;p&gt;EDIT: I use medium and high, i use high when i have complicated issues that aren&amp;#39;t getting solved or need some real understanding around the underlying problem space.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "a4b85826-b95f-11f0-987b-321e713942fe",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#72a15e",
                    "id": "1qaix9k",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "lordpuddingcup",
                    "discussion_type": null,
                    "num_comments": 18,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1qaix9k/openai_please/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1qaix9k/openai_please/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1768185308.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Part of the latest release (0.79) was adding support in their config for disabling client side analytics. No details on what will be collected as of yet. According to the Codex team,\n\n&gt; \n    Analytics will not include any PII (personally identifiable information).\n    The code that collects analytics will be in the open source repo, visible to everyone.\n    Analytics will default to enabled, except in jurisdictions where opt-out is required by law.\n    You will be able to explicitly disable analytics via a new analytics feature flag.\n\n\nThey opened a discussion [here](https://github.com/openai/codex/discussions/8291)\n\n\nPersonally I view adding new opt-out enabled by default analytics as shady. I hope enough people agree to push back and make this opt-IN instead of opt-OUT.",
                    "author_fullname": "t2_t1d4xv7e2",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Codex will be adding client side analytics soon, will be enabled by default",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q6yb0f",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.94,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 28,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "News",
                    "can_mod_post": false,
                    "score": 28,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767835932.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Part of the latest release (0.79) was adding support in their config for disabling client side analytics. No details on what will be collected as of yet. According to the Codex team,&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;pre&gt;&lt;code&gt;Analytics will not include any PII (personally identifiable information).\nThe code that collects analytics will be in the open source repo, visible to everyone.\nAnalytics will default to enabled, except in jurisdictions where opt-out is required by law.\nYou will be able to explicitly disable analytics via a new analytics feature flag.\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;They opened a discussion &lt;a href=\"https://github.com/openai/codex/discussions/8291\"&gt;here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Personally I view adding new opt-out enabled by default analytics as shady. I hope enough people agree to push back and make this opt-IN instead of opt-OUT.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/h7WC2r1wKePSb2qBiR_ZfTDbIdub7O3hCjvoziC5AJ8.png?auto=webp&amp;s=70c1ae4fc67a5e05d4da7b94198537e2ac4a192e",
                                    "width": 1200,
                                    "height": 600
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/h7WC2r1wKePSb2qBiR_ZfTDbIdub7O3hCjvoziC5AJ8.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=12c533ccf89194f510dc76e34082cf548352787c",
                                        "width": 108,
                                        "height": 54
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/h7WC2r1wKePSb2qBiR_ZfTDbIdub7O3hCjvoziC5AJ8.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2589a657b46bf3d1c5d252f65a01e967f22b7422",
                                        "width": 216,
                                        "height": 108
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/h7WC2r1wKePSb2qBiR_ZfTDbIdub7O3hCjvoziC5AJ8.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cf36b1bdb236648a0ca490e0310ec2eeffee605e",
                                        "width": 320,
                                        "height": 160
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/h7WC2r1wKePSb2qBiR_ZfTDbIdub7O3hCjvoziC5AJ8.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0f5687510d807e4f44fe8ead7e420a6c7dbc0f3f",
                                        "width": 640,
                                        "height": 320
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/h7WC2r1wKePSb2qBiR_ZfTDbIdub7O3hCjvoziC5AJ8.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1d6695fbde2b28e13b775637c54cf05086c6d7de",
                                        "width": 960,
                                        "height": 480
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/h7WC2r1wKePSb2qBiR_ZfTDbIdub7O3hCjvoziC5AJ8.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=05759ac70c5a76867491dc5e768f2eb4fb5ddd88",
                                        "width": 1080,
                                        "height": 540
                                    }
                                ],
                                "variants": {},
                                "id": "h7WC2r1wKePSb2qBiR_ZfTDbIdub7O3hCjvoziC5AJ8"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "d91881fa-8c86-11f0-9995-42042a14a711",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "transparent",
                    "id": "1q6yb0f",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Icy-Helicopter8759",
                    "discussion_type": null,
                    "num_comments": 15,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q6yb0f/codex_will_be_adding_client_side_analytics_soon/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q6yb0f/codex_will_be_adding_client_side_analytics_soon/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767835932.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Excited to try the new Codex Model! GPT 5.2 has been good to me so far, lets see what the Codex model can or can't do!\n\n[https://openai.com/index/introducing-gpt-5-2-codex/](https://openai.com/index/introducing-gpt-5-2-codex/)\n\nQuick AI Summary:\n\nOpenAI is releasing **GPT-5.2-Codex**, a GPT-5.2 variant optimized for **agentic, long-running software engineering** in Codex. It improves **long-horizon work** (via context compaction), handles **large code changes** (refactors/migrations) more reliably, works better in **Windows environments**, adds stronger **vision** for understanding screenshots/diagrams/UI, and significantly boosts **cybersecurity capabilities**.\n\nThe announcement highlights that rising general capability is also driving **big jumps in cybersecurity performance**, including a recent example where a researcher using **GPT-5.1-Codex-Max** with Codex CLI helped uncover and responsibly disclose React vulnerabilities. GPT-5.2-Codex is described as their **strongest cyber model to date**, though still **below \u201cHigh\u201d** under their Preparedness Framework; because of dual-use risk, they\u2019re pairing the release with **additional safeguards** and a cautious rollout.\n\nAvailability: it\u2019s launching **today for paid ChatGPT users across Codex surfaces**, with **API access planned in the coming weeks**. In parallel, OpenAI is starting an **invite-only \u201ctrusted access\u201d pilot** for vetted security professionals and organizations focused on **defensive cybersecurity**, aiming to balance usefulness for defenders with misuse prevention.\n\nhttps://preview.redd.it/d7zexbntb08g1.jpg?width=1619&amp;format=pjpg&amp;auto=webp&amp;s=d667408ae3d3e5b297def3c5e7ea140018bff716\n\n",
                    "author_fullname": "t2_69xyosb6",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "GPT 5.2-Codex is here",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 67,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "media_metadata": {
                        "d7zexbntb08g1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/jpg",
                            "p": [
                                {
                                    "y": 51,
                                    "x": 108,
                                    "u": "https://preview.redd.it/d7zexbntb08g1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b3b9589693068707f35a73cceaaf97fcd41e36ff"
                                },
                                {
                                    "y": 103,
                                    "x": 216,
                                    "u": "https://preview.redd.it/d7zexbntb08g1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=66594f30b994f5fc3eb2e26e78345069873997eb"
                                },
                                {
                                    "y": 153,
                                    "x": 320,
                                    "u": "https://preview.redd.it/d7zexbntb08g1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8d24edd8ffaf786c6482047a580b6d49fa9e6cc0"
                                },
                                {
                                    "y": 307,
                                    "x": 640,
                                    "u": "https://preview.redd.it/d7zexbntb08g1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=02d2f9270fa5ed7eaee7d16f1be662e1c682b181"
                                },
                                {
                                    "y": 461,
                                    "x": 960,
                                    "u": "https://preview.redd.it/d7zexbntb08g1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e5225836c12b914b107a46533f618e57763f9c1f"
                                },
                                {
                                    "y": 518,
                                    "x": 1080,
                                    "u": "https://preview.redd.it/d7zexbntb08g1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8e88a749f626934082d4a63b83b21aed6af70966"
                                }
                            ],
                            "s": {
                                "y": 778,
                                "x": 1619,
                                "u": "https://preview.redd.it/d7zexbntb08g1.jpg?width=1619&amp;format=pjpg&amp;auto=webp&amp;s=d667408ae3d3e5b297def3c5e7ea140018bff716"
                            },
                            "id": "d7zexbntb08g1"
                        }
                    },
                    "name": "t3_1ppyern",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.95,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 37,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "News",
                    "can_mod_post": false,
                    "score": 37,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/jHC--BEIYy03WsahTLwMq1ALxkAKHQWBQcOyO7HqQjc.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766082963.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Excited to try the new Codex Model! GPT 5.2 has been good to me so far, lets see what the Codex model can or can&amp;#39;t do!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://openai.com/index/introducing-gpt-5-2-codex/\"&gt;https://openai.com/index/introducing-gpt-5-2-codex/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Quick AI Summary:&lt;/p&gt;\n\n&lt;p&gt;OpenAI is releasing &lt;strong&gt;GPT-5.2-Codex&lt;/strong&gt;, a GPT-5.2 variant optimized for &lt;strong&gt;agentic, long-running software engineering&lt;/strong&gt; in Codex. It improves &lt;strong&gt;long-horizon work&lt;/strong&gt; (via context compaction), handles &lt;strong&gt;large code changes&lt;/strong&gt; (refactors/migrations) more reliably, works better in &lt;strong&gt;Windows environments&lt;/strong&gt;, adds stronger &lt;strong&gt;vision&lt;/strong&gt; for understanding screenshots/diagrams/UI, and significantly boosts &lt;strong&gt;cybersecurity capabilities&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;The announcement highlights that rising general capability is also driving &lt;strong&gt;big jumps in cybersecurity performance&lt;/strong&gt;, including a recent example where a researcher using &lt;strong&gt;GPT-5.1-Codex-Max&lt;/strong&gt; with Codex CLI helped uncover and responsibly disclose React vulnerabilities. GPT-5.2-Codex is described as their &lt;strong&gt;strongest cyber model to date&lt;/strong&gt;, though still &lt;strong&gt;below \u201cHigh\u201d&lt;/strong&gt; under their Preparedness Framework; because of dual-use risk, they\u2019re pairing the release with &lt;strong&gt;additional safeguards&lt;/strong&gt; and a cautious rollout.&lt;/p&gt;\n\n&lt;p&gt;Availability: it\u2019s launching &lt;strong&gt;today for paid ChatGPT users across Codex surfaces&lt;/strong&gt;, with &lt;strong&gt;API access planned in the coming weeks&lt;/strong&gt;. In parallel, OpenAI is starting an &lt;strong&gt;invite-only \u201ctrusted access\u201d pilot&lt;/strong&gt; for vetted security professionals and organizations focused on &lt;strong&gt;defensive cybersecurity&lt;/strong&gt;, aiming to balance usefulness for defenders with misuse prevention.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/d7zexbntb08g1.jpg?width=1619&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d667408ae3d3e5b297def3c5e7ea140018bff716\"&gt;https://preview.redd.it/d7zexbntb08g1.jpg?width=1619&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d667408ae3d3e5b297def3c5e7ea140018bff716&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "d91881fa-8c86-11f0-9995-42042a14a711",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "transparent",
                    "id": "1ppyern",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "magnus_animus",
                    "discussion_type": null,
                    "num_comments": 17,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1ppyern/gpt_52codex_is_here/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1ppyern/gpt_52codex_is_here/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766082963.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Has anyone successfully 'unleashed' Codex from this awful constraint?\n\nNeeding to verify every single git commit (twice, including all the `git add`s!) is making my process *less* safe!\n\nOne of the beauties of automating git committing is that you can be more atomic- get every single feature change neatly and concisely committed. You can have every commit meticulously detailed in the commit message, a prohibitive demand otherwise for a time-strapped solo dev.\n\nCodex's 'safety' features encourage me to either lay off the careful gitting and commit one awful 'blob' after the LLM's done its work, OR run the damn thing with *zero* safety measures, which is awful.\n\nThis is probably the cause for all those people who lost tens of thousands of dollars due to running AI without safeguards. There's no sensible medium with this tool!\n\nCodex is legitimately great APART from this and, frankly, the existence of this 'feature' is probably what contributes to its awful reputation among novice AI programmers. Surely some of you have got it set up nicely where you can just set it off on a pile of TODO tasks and come back and verify its output all at once- that's the ideal use pattern for me.\n\nAnyone? ",
                    "author_fullname": "t2_1rrye94wzb",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Call for help- Codex is GREAT but babysitting every single git commit is killing productivity.",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q7kt2f",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.47,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 0,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Question",
                    "can_mod_post": false,
                    "score": 0,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767899295.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone successfully &amp;#39;unleashed&amp;#39; Codex from this awful constraint?&lt;/p&gt;\n\n&lt;p&gt;Needing to verify every single git commit (twice, including all the &lt;code&gt;git add&lt;/code&gt;s!) is making my process &lt;em&gt;less&lt;/em&gt; safe!&lt;/p&gt;\n\n&lt;p&gt;One of the beauties of automating git committing is that you can be more atomic- get every single feature change neatly and concisely committed. You can have every commit meticulously detailed in the commit message, a prohibitive demand otherwise for a time-strapped solo dev.&lt;/p&gt;\n\n&lt;p&gt;Codex&amp;#39;s &amp;#39;safety&amp;#39; features encourage me to either lay off the careful gitting and commit one awful &amp;#39;blob&amp;#39; after the LLM&amp;#39;s done its work, OR run the damn thing with &lt;em&gt;zero&lt;/em&gt; safety measures, which is awful.&lt;/p&gt;\n\n&lt;p&gt;This is probably the cause for all those people who lost tens of thousands of dollars due to running AI without safeguards. There&amp;#39;s no sensible medium with this tool!&lt;/p&gt;\n\n&lt;p&gt;Codex is legitimately great APART from this and, frankly, the existence of this &amp;#39;feature&amp;#39; is probably what contributes to its awful reputation among novice AI programmers. Surely some of you have got it set up nicely where you can just set it off on a pile of TODO tasks and come back and verify its output all at once- that&amp;#39;s the ideal use pattern for me.&lt;/p&gt;\n\n&lt;p&gt;Anyone? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "302c6282-b24c-11f0-a6c9-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c13e80",
                    "id": "1q7kt2f",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "fractal_pilgrim",
                    "discussion_type": null,
                    "num_comments": 18,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q7kt2f/call_for_help_codex_is_great_but_babysitting/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q7kt2f/call_for_help_codex_is_great_but_babysitting/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767899295.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "https://preview.redd.it/lo1iwaeyo78g1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=fa168147e61290eea7afa19541716105a1b8e2f1\n\nThis doesn't make sense. For a model that is a distillation / fine-tune of GPT-5.2, shouldn't the training cutoffs be exactly the same?\n\nThe two logical explanations are:\n\n* GPT-5.2-Codex doesn't know its own training knowledge cutoff date and is just hallucinating. This is partially unlikely as it *always* claims that its cutoff date is June 2024, tested numerous times.\n* GPT-5.2-Codex is based off an entirely different base model other than GPT-5.2.\n\nThe second explanation is particularly intriguing as it follows a general pattern. GPT-5.1 claims that its knowledge cutoff is October 2024, whereas GPT-5.1-Codex *and* GPT-5.1-Codex-Max claims that they were last trained on data up to October 2023.\n\nHowever, the model pages for [GPT-5.1-Codex](https://platform.openai.com/docs/models/gpt-5.1-codex) and [GPT-5.1-Codex-Max](https://platform.openai.com/docs/models/gpt-5.1-codex-max) both claim a Sep 30, 2024 knowledge cutoff date which supports the hallucination claim, and it could be no different with GPT-5.2-Codex.\n\nEither way, we don't have much visibility into this. It'd be nice to get some clarifications from Tibo or someone similar.\n\nBut for now, just an interesting observation!",
                    "author_fullname": "t2_1s4jp83y",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Why is GPT-5.2-Codex's training cutoff data so much earlier than GPT-5.2?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 108,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "media_metadata": {
                        "lo1iwaeyo78g1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/png",
                            "p": [
                                {
                                    "y": 83,
                                    "x": 108,
                                    "u": "https://preview.redd.it/lo1iwaeyo78g1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a24d5c426c229124b8b1e72953d6300f90e37707"
                                },
                                {
                                    "y": 167,
                                    "x": 216,
                                    "u": "https://preview.redd.it/lo1iwaeyo78g1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=51c927a789fe9f0dec6e3c6f0df90dc4e976caf6"
                                },
                                {
                                    "y": 247,
                                    "x": 320,
                                    "u": "https://preview.redd.it/lo1iwaeyo78g1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bb65753dccebee24b5fd08c64396874674036d91"
                                },
                                {
                                    "y": 495,
                                    "x": 640,
                                    "u": "https://preview.redd.it/lo1iwaeyo78g1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d58c74d5940adb1d3e2d0681008941717b8cc7f6"
                                },
                                {
                                    "y": 743,
                                    "x": 960,
                                    "u": "https://preview.redd.it/lo1iwaeyo78g1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1f219c48ea6ec2639bcbbbcf65426d3b26925022"
                                },
                                {
                                    "y": 836,
                                    "x": 1080,
                                    "u": "https://preview.redd.it/lo1iwaeyo78g1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c622c56d655805068d61e9fe0e2ac73905f3fd33"
                                }
                            ],
                            "s": {
                                "y": 836,
                                "x": 1080,
                                "u": "https://preview.redd.it/lo1iwaeyo78g1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=fa168147e61290eea7afa19541716105a1b8e2f1"
                            },
                            "id": "lo1iwaeyo78g1"
                        }
                    },
                    "name": "t3_1pqubg7",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.81,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 10,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Question",
                    "can_mod_post": false,
                    "score": 10,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/gGu9muj3iggDRGqq2PQi3VhpW3XeylIlzjxHO9vn9sM.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766173279.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/lo1iwaeyo78g1.png?width=1080&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fa168147e61290eea7afa19541716105a1b8e2f1\"&gt;https://preview.redd.it/lo1iwaeyo78g1.png?width=1080&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fa168147e61290eea7afa19541716105a1b8e2f1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This doesn&amp;#39;t make sense. For a model that is a distillation / fine-tune of GPT-5.2, shouldn&amp;#39;t the training cutoffs be exactly the same?&lt;/p&gt;\n\n&lt;p&gt;The two logical explanations are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;GPT-5.2-Codex doesn&amp;#39;t know its own training knowledge cutoff date and is just hallucinating. This is partially unlikely as it &lt;em&gt;always&lt;/em&gt; claims that its cutoff date is June 2024, tested numerous times.&lt;/li&gt;\n&lt;li&gt;GPT-5.2-Codex is based off an entirely different base model other than GPT-5.2.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The second explanation is particularly intriguing as it follows a general pattern. GPT-5.1 claims that its knowledge cutoff is October 2024, whereas GPT-5.1-Codex &lt;em&gt;and&lt;/em&gt; GPT-5.1-Codex-Max claims that they were last trained on data up to October 2023.&lt;/p&gt;\n\n&lt;p&gt;However, the model pages for &lt;a href=\"https://platform.openai.com/docs/models/gpt-5.1-codex\"&gt;GPT-5.1-Codex&lt;/a&gt; and &lt;a href=\"https://platform.openai.com/docs/models/gpt-5.1-codex-max\"&gt;GPT-5.1-Codex-Max&lt;/a&gt; both claim a Sep 30, 2024 knowledge cutoff date which supports the hallucination claim, and it could be no different with GPT-5.2-Codex.&lt;/p&gt;\n\n&lt;p&gt;Either way, we don&amp;#39;t have much visibility into this. It&amp;#39;d be nice to get some clarifications from Tibo or someone similar.&lt;/p&gt;\n\n&lt;p&gt;But for now, just an interesting observation!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "302c6282-b24c-11f0-a6c9-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c13e80",
                    "id": "1pqubg7",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "RoadRunnerChris",
                    "discussion_type": null,
                    "num_comments": 20,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1pqubg7/why_is_gpt52codexs_training_cutoff_data_so_much/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1pqubg7/why_is_gpt52codexs_training_cutoff_data_so_much/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766173279.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "I\u2019ve been getting into more advanced workflows and was quickly put off by how clunky they are to set up and how little visibility you get into what\u2019s happening at runtime. Many tools feel heavy, hard to debug, and awkward to experiment with.\n\nI wanted something simple: easy to set up, easy to observe while it\u2019s running, and easy to customize. After trying a few options, I ended up forking the `openai/codex` repo and adding a lightweight messaging substrate on top of it, which I called **#weave**.\n\nIt\u2019s still pretty experimental, and I haven\u2019t pushed it through more complex workflows yet, but I plan to keep iterating on it over the next few weeks. Feel free to try it out:  \n  \n[https://github.com/rosem/codex-weave/tree/weave](https://github.com/rosem/codex-weave/tree/weave)\n\nThe gist is you make a session from the `/weave` slash command and then have your Codex CLI agents join the session. From there the agents can communicate with other agents in that session.\n\n`/weave` slash command to create and manage sessions \u2014 or change your agent name\n\n`#agent-name` to prompt an agent in that session. \n\nInstall the CLI:\n\n    npm install -g u/rosem_soo/weave\n\nStart the coordinator (once):\n\n    weave-service start\n\nRun the CLI (as much as needed):\n\n    weave\n\nStop the coordinator when finished:\n\n    weave-service stop\n\nI have a web ui (as part of the full cycle I went through, haha) that I should be adding in the near future. ",
                    "author_fullname": "t2_mjlm0iud",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Codex CLI Agent to Agent Communication (#weave)",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 69,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q8w9xz",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.95,
                    "author_flair_background_color": null,
                    "ups": 42,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": {
                        "reddit_video": {
                            "bitrate_kbps": 5000,
                            "fallback_url": "https://v.redd.it/4nvs3glzkgcg1/CMAF_1080.mp4?source=fallback",
                            "has_audio": false,
                            "height": 956,
                            "width": 1920,
                            "scrubber_media_url": "https://v.redd.it/4nvs3glzkgcg1/CMAF_96.mp4",
                            "dash_url": "https://v.redd.it/4nvs3glzkgcg1/DASHPlaylist.mpd?a=1771221921%2CMjU1YTZkODI5ODdiMWEyYWQyYzNhNDQxZWRmY2Q0OGYxZjNlMDFhZjhiNTRhYjMzNmRkNjBkNzNhMDQ1OGY1Mw%3D%3D&amp;v=1&amp;f=sd",
                            "duration": 157,
                            "hls_url": "https://v.redd.it/4nvs3glzkgcg1/HLSPlaylist.m3u8?a=1771221921%2CZjliMzY5MmJjODlkNGExOGIwNjBhZmY0OThlYjg4MTZjN2Y5OTJhNDdiMGU5NzZiMzRhYjVjOTUwYmFiNDM3ZQ%3D%3D&amp;v=1&amp;f=sd",
                            "is_gif": false,
                            "transcoding_status": "completed"
                        }
                    },
                    "is_reddit_media_domain": true,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Showcase",
                    "can_mod_post": false,
                    "score": 42,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://external-preview.redd.it/a3YxMnVtbHprZ2NnMWetzLzEfrFDWNYI3YIPsh64dJOlZYyNX7vs7WWQhwwT.png?width=140&amp;height=69&amp;format=jpg&amp;auto=webp&amp;s=51254ac5ed169a67f3cad4ddef92e0cdf913a450",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "hosted:video",
                    "content_categories": null,
                    "is_self": false,
                    "subreddit_type": "public",
                    "created": 1768024661.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "v.redd.it",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been getting into more advanced workflows and was quickly put off by how clunky they are to set up and how little visibility you get into what\u2019s happening at runtime. Many tools feel heavy, hard to debug, and awkward to experiment with.&lt;/p&gt;\n\n&lt;p&gt;I wanted something simple: easy to set up, easy to observe while it\u2019s running, and easy to customize. After trying a few options, I ended up forking the &lt;code&gt;openai/codex&lt;/code&gt; repo and adding a lightweight messaging substrate on top of it, which I called &lt;strong&gt;#weave&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;It\u2019s still pretty experimental, and I haven\u2019t pushed it through more complex workflows yet, but I plan to keep iterating on it over the next few weeks. Feel free to try it out:  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/rosem/codex-weave/tree/weave\"&gt;https://github.com/rosem/codex-weave/tree/weave&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The gist is you make a session from the &lt;code&gt;/weave&lt;/code&gt; slash command and then have your Codex CLI agents join the session. From there the agents can communicate with other agents in that session.&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;/weave&lt;/code&gt; slash command to create and manage sessions \u2014 or change your agent name&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;#agent-name&lt;/code&gt; to prompt an agent in that session. &lt;/p&gt;\n\n&lt;p&gt;Install the CLI:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;npm install -g u/rosem_soo/weave\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Start the coordinator (once):&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;weave-service start\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Run the CLI (as much as needed):&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;weave\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Stop the coordinator when finished:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;weave-service stop\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I have a web ui (as part of the full cycle I went through, haha) that I should be adding in the near future. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "url_overridden_by_dest": "https://v.redd.it/4nvs3glzkgcg1",
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/a3YxMnVtbHprZ2NnMWetzLzEfrFDWNYI3YIPsh64dJOlZYyNX7vs7WWQhwwT.png?format=pjpg&amp;auto=webp&amp;s=d9694caca636db39574c33a997700bc7e54e7b53",
                                    "width": 2658,
                                    "height": 1324
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/a3YxMnVtbHprZ2NnMWetzLzEfrFDWNYI3YIPsh64dJOlZYyNX7vs7WWQhwwT.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=d3130d5fe707ff94df032b92ce227d2dfdfcdb89",
                                        "width": 108,
                                        "height": 53
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/a3YxMnVtbHprZ2NnMWetzLzEfrFDWNYI3YIPsh64dJOlZYyNX7vs7WWQhwwT.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=f9ea3526d3136ab9d921bcb84b9f701d45a99cc7",
                                        "width": 216,
                                        "height": 107
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/a3YxMnVtbHprZ2NnMWetzLzEfrFDWNYI3YIPsh64dJOlZYyNX7vs7WWQhwwT.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=218fe8c7550a42c2c2b154f61bbb5f73ace46cb9",
                                        "width": 320,
                                        "height": 159
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/a3YxMnVtbHprZ2NnMWetzLzEfrFDWNYI3YIPsh64dJOlZYyNX7vs7WWQhwwT.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=1d785bf56438efea94ef462fcfc721b8831f52e7",
                                        "width": 640,
                                        "height": 318
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/a3YxMnVtbHprZ2NnMWetzLzEfrFDWNYI3YIPsh64dJOlZYyNX7vs7WWQhwwT.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=de9974d22d54f310821ca09c947a053a19524dde",
                                        "width": 960,
                                        "height": 478
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/a3YxMnVtbHprZ2NnMWetzLzEfrFDWNYI3YIPsh64dJOlZYyNX7vs7WWQhwwT.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=0b09d1e73343e78b5f53179556fb9ccd2fc74f7b",
                                        "width": 1080,
                                        "height": 537
                                    }
                                ],
                                "variants": {},
                                "id": "a3YxMnVtbHprZ2NnMWetzLzEfrFDWNYI3YIPsh64dJOlZYyNX7vs7WWQhwwT"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "e350908e-b24e-11f0-b239-62e50da6d05a",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "mod_note": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "num_reports": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#00ff2a",
                    "id": "1q8w9xz",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Different-Side5262",
                    "discussion_type": null,
                    "num_comments": 12,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q8w9xz/codex_cli_agent_to_agent_communication_weave/",
                    "stickied": false,
                    "url": "https://v.redd.it/4nvs3glzkgcg1",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1768024661.0,
                    "num_crossposts": 0,
                    "media": {
                        "reddit_video": {
                            "bitrate_kbps": 5000,
                            "fallback_url": "https://v.redd.it/4nvs3glzkgcg1/CMAF_1080.mp4?source=fallback",
                            "has_audio": false,
                            "height": 956,
                            "width": 1920,
                            "scrubber_media_url": "https://v.redd.it/4nvs3glzkgcg1/CMAF_96.mp4",
                            "dash_url": "https://v.redd.it/4nvs3glzkgcg1/DASHPlaylist.mpd?a=1771221921%2CMjU1YTZkODI5ODdiMWEyYWQyYzNhNDQxZWRmY2Q0OGYxZjNlMDFhZjhiNTRhYjMzNmRkNjBkNzNhMDQ1OGY1Mw%3D%3D&amp;v=1&amp;f=sd",
                            "duration": 157,
                            "hls_url": "https://v.redd.it/4nvs3glzkgcg1/HLSPlaylist.m3u8?a=1771221921%2CZjliMzY5MmJjODlkNGExOGIwNjBhZmY0OThlYjg4MTZjN2Y5OTJhNDdiMGU5NzZiMzRhYjVjOTUwYmFiNDM3ZQ%3D%3D&amp;v=1&amp;f=sd",
                            "is_gif": false,
                            "transcoding_status": "completed"
                        }
                    },
                    "is_video": true
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Found the script on X and thought it was cool. This was my wrapped. \n\nKind of crazy how you can just get $2k/m worth of tokens for $20.\n\nit's npx codex-wrapped if anyone wants to use it.",
                    "author_fullname": "t2_7tcthknm",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Codex Wrapped",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 130,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1pwt9gq",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.98,
                    "author_flair_background_color": null,
                    "ups": 50,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": true,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Showcase",
                    "can_mod_post": false,
                    "score": 50,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/h62yi5Zfdj9QiKI4uXx59_PK02BZN2jNK5_tk2EQBGI.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "image",
                    "content_categories": null,
                    "is_self": false,
                    "subreddit_type": "public",
                    "created": 1766825698.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "i.redd.it",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Found the script on X and thought it was cool. This was my wrapped. &lt;/p&gt;\n\n&lt;p&gt;Kind of crazy how you can just get $2k/m worth of tokens for $20.&lt;/p&gt;\n\n&lt;p&gt;it&amp;#39;s npx codex-wrapped if anyone wants to use it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "url_overridden_by_dest": "https://i.redd.it/wxwa8pyknp9g1.png",
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://preview.redd.it/wxwa8pyknp9g1.png?auto=webp&amp;s=2aa6110ad225f5876f29393f95542cc0afa79f32",
                                    "width": 1500,
                                    "height": 1400
                                },
                                "resolutions": [
                                    {
                                        "url": "https://preview.redd.it/wxwa8pyknp9g1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6dec03abcb3876b695ec86f287b61fb018e6dd3c",
                                        "width": 108,
                                        "height": 100
                                    },
                                    {
                                        "url": "https://preview.redd.it/wxwa8pyknp9g1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=99cea9cca97bcc6c771e8d199318eb96a2d70121",
                                        "width": 216,
                                        "height": 201
                                    },
                                    {
                                        "url": "https://preview.redd.it/wxwa8pyknp9g1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=08be96b064dd7866df1eb22d5c20f04b2e325940",
                                        "width": 320,
                                        "height": 298
                                    },
                                    {
                                        "url": "https://preview.redd.it/wxwa8pyknp9g1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=28667d61e674884c8b8dc27009a306be2792e296",
                                        "width": 640,
                                        "height": 597
                                    },
                                    {
                                        "url": "https://preview.redd.it/wxwa8pyknp9g1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b7eead6bda55ec195a417dfd4a9ffd0401fb1c7c",
                                        "width": 960,
                                        "height": 896
                                    },
                                    {
                                        "url": "https://preview.redd.it/wxwa8pyknp9g1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0b9262523caaa584a23172ca29ee9da9e78f54de",
                                        "width": 1080,
                                        "height": 1008
                                    }
                                ],
                                "variants": {},
                                "id": "U_LFO032Cm2wPL1N_Qei0gCCggb568oGjey7LopJO-U"
                            }
                        ],
                        "enabled": true
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "e350908e-b24e-11f0-b239-62e50da6d05a",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "mod_note": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "num_reports": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#00ff2a",
                    "id": "1pwt9gq",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Curtisg899",
                    "discussion_type": null,
                    "num_comments": 11,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1pwt9gq/codex_wrapped/",
                    "stickied": false,
                    "url": "https://i.redd.it/wxwa8pyknp9g1.png",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766825698.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "If I were to use it as my daily driver, say 5 hour every day, would pro plan make sense, or just have multiple plus plan? \n\nI saw here [https://developers.openai.com/codex/pricing/](https://developers.openai.com/codex/pricing/) that the pro plan is just 6x of the usage of plus plan? then it feels like I could just make multiple plus plan instead",
                    "author_fullname": "t2_blv8bkb4",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "How much usage can I expect from Pro plan? Using Plus plan now and thinking",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q7jw58",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 7,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Question",
                    "can_mod_post": false,
                    "score": 7,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767897333.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If I were to use it as my daily driver, say 5 hour every day, would pro plan make sense, or just have multiple plus plan? &lt;/p&gt;\n\n&lt;p&gt;I saw here &lt;a href=\"https://developers.openai.com/codex/pricing/\"&gt;https://developers.openai.com/codex/pricing/&lt;/a&gt; that the pro plan is just 6x of the usage of plus plan? then it feels like I could just make multiple plus plan instead&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?auto=webp&amp;s=069f20773972e7174872761253c50a1597e321f8",
                                    "width": 2400,
                                    "height": 903
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e3f265b33937cdd7d282a3b805d8b3aca8aecca8",
                                        "width": 108,
                                        "height": 40
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a3d4abd8843027da5713b715cd6bfc5df6e5e4cb",
                                        "width": 216,
                                        "height": 81
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7986930e7db3d10096334d8740c477e4faaced51",
                                        "width": 320,
                                        "height": 120
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=74fa25b2b23656a2cc9c0fee548229c63af35433",
                                        "width": 640,
                                        "height": 240
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f58b50ca3507b4d3ed0b34bf90b1d85e69cf2c30",
                                        "width": 960,
                                        "height": 361
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=391142286c70f8c149866fb27914cda903d869d2",
                                        "width": 1080,
                                        "height": 406
                                    }
                                ],
                                "variants": {},
                                "id": "IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "302c6282-b24c-11f0-a6c9-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c13e80",
                    "id": "1q7jw58",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "satori_paper",
                    "discussion_type": null,
                    "num_comments": 14,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q7jw58/how_much_usage_can_i_expect_from_pro_plan_using/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q7jw58/how_much_usage_can_i_expect_from_pro_plan_using/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767897333.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "I was constantly using /undo command after the latest update I can't use it. Also it looks like it doesn't get listed in here: [https://developers.openai.com/codex/cli/slash-commands](https://developers.openai.com/codex/cli/slash-commands)\n\n  \nDo you have an idea?",
                    "author_fullname": "t2_wufcq77",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "No more /undo ?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q86q1w",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 9,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Complaint",
                    "can_mod_post": false,
                    "score": 9,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767960863.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was constantly using /undo command after the latest update I can&amp;#39;t use it. Also it looks like it doesn&amp;#39;t get listed in here: &lt;a href=\"https://developers.openai.com/codex/cli/slash-commands\"&gt;https://developers.openai.com/codex/cli/slash-commands&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Do you have an idea?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?auto=webp&amp;s=069f20773972e7174872761253c50a1597e321f8",
                                    "width": 2400,
                                    "height": 903
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e3f265b33937cdd7d282a3b805d8b3aca8aecca8",
                                        "width": 108,
                                        "height": 40
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a3d4abd8843027da5713b715cd6bfc5df6e5e4cb",
                                        "width": 216,
                                        "height": 81
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7986930e7db3d10096334d8740c477e4faaced51",
                                        "width": 320,
                                        "height": 120
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=74fa25b2b23656a2cc9c0fee548229c63af35433",
                                        "width": 640,
                                        "height": 240
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f58b50ca3507b4d3ed0b34bf90b1d85e69cf2c30",
                                        "width": 960,
                                        "height": 361
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=391142286c70f8c149866fb27914cda903d869d2",
                                        "width": 1080,
                                        "height": 406
                                    }
                                ],
                                "variants": {},
                                "id": "IanbACn0ZMJMMsnYfmcP1C692OFMB1do21sw5Lbo-80"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "3090d6a0-ab11-11f0-a7f1-526fbbfcd846",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#f40b0b",
                    "id": "1q86q1w",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "energyzzer",
                    "discussion_type": null,
                    "num_comments": 13,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q86q1w/no_more_undo/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q86q1w/no_more_undo/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767960863.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "People need to stop having \u201cthis vs. that\u201d wards and capitalize on each LLM\u2019s strengths. ",
                    "author_fullname": "t2_21ewz8f478",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "is_gallery": true,
                    "title": "LLMs critiquing each other\u2019s code improves quality - Opus-4.5-Thinking vs. GPT-5.2-Thinking vs. Gemini-Pro. Finally, Codex-xhigh for integration and final safety checks",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 96,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "media_metadata": {
                        "j54m2t7d779g1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/jpg",
                            "p": [
                                {
                                    "y": 74,
                                    "x": 108,
                                    "u": "https://preview.redd.it/j54m2t7d779g1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=deecc280f789333e425caf4e9a17686c4c4f3f31"
                                },
                                {
                                    "y": 148,
                                    "x": 216,
                                    "u": "https://preview.redd.it/j54m2t7d779g1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4dd1115d32e97522e0fccffe809e410995ccffa6"
                                },
                                {
                                    "y": 219,
                                    "x": 320,
                                    "u": "https://preview.redd.it/j54m2t7d779g1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=36619506cdf473e2ba749ac074d4c41c765c6178"
                                },
                                {
                                    "y": 439,
                                    "x": 640,
                                    "u": "https://preview.redd.it/j54m2t7d779g1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b5c54ccfd79923549974d37a0a8aed4703198cd4"
                                }
                            ],
                            "s": {
                                "y": 510,
                                "x": 743,
                                "u": "https://preview.redd.it/j54m2t7d779g1.jpg?width=743&amp;format=pjpg&amp;auto=webp&amp;s=7c41b1324ee882a7d1074a7cadc4d474a2781fc4"
                            },
                            "id": "j54m2t7d779g1"
                        },
                        "gk3nas7d779g1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/jpg",
                            "p": [
                                {
                                    "y": 216,
                                    "x": 108,
                                    "u": "https://preview.redd.it/gk3nas7d779g1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0699a0da612c34de58a4950abb75e824735ae265"
                                },
                                {
                                    "y": 432,
                                    "x": 216,
                                    "u": "https://preview.redd.it/gk3nas7d779g1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a1f78b521dc7c8a65ab8d84bbb3f5095435bc299"
                                },
                                {
                                    "y": 640,
                                    "x": 320,
                                    "u": "https://preview.redd.it/gk3nas7d779g1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3a0df13f15a30b682f752ce69bfafb6c326659c9"
                                },
                                {
                                    "y": 1280,
                                    "x": 640,
                                    "u": "https://preview.redd.it/gk3nas7d779g1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0a6315b62cc36c909f7bc63f59ff8dc4b5a3f37f"
                                },
                                {
                                    "y": 1920,
                                    "x": 960,
                                    "u": "https://preview.redd.it/gk3nas7d779g1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7fe5e5d6f1af6fdff5efcc1b2a06eda208348323"
                                },
                                {
                                    "y": 2160,
                                    "x": 1080,
                                    "u": "https://preview.redd.it/gk3nas7d779g1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8d4efa07eef03c66261bd7dc22bece0c543bd814"
                                }
                            ],
                            "s": {
                                "y": 2778,
                                "x": 1284,
                                "u": "https://preview.redd.it/gk3nas7d779g1.jpg?width=1284&amp;format=pjpg&amp;auto=webp&amp;s=6a8f881fb4373bd4d6c8b93c8c0aed75ce31de97"
                            },
                            "id": "gk3nas7d779g1"
                        },
                        "x1eztr7d779g1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/jpg",
                            "p": [
                                {
                                    "y": 178,
                                    "x": 108,
                                    "u": "https://preview.redd.it/x1eztr7d779g1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f234c89c2b3c51a2edeb69a88a1de529a2548aa1"
                                },
                                {
                                    "y": 357,
                                    "x": 216,
                                    "u": "https://preview.redd.it/x1eztr7d779g1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6cfd39c12265c61ec644d17099e50e5e9d8cf599"
                                },
                                {
                                    "y": 529,
                                    "x": 320,
                                    "u": "https://preview.redd.it/x1eztr7d779g1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eaa505f6d5c7a69026e445c5af456d9c8297587f"
                                },
                                {
                                    "y": 1058,
                                    "x": 640,
                                    "u": "https://preview.redd.it/x1eztr7d779g1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=37c9de21eca4a0c49dea589a6df14ff3277ab955"
                                },
                                {
                                    "y": 1587,
                                    "x": 960,
                                    "u": "https://preview.redd.it/x1eztr7d779g1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=36dfda73571644a509b103c751e1173a4967fc2b"
                                },
                                {
                                    "y": 1786,
                                    "x": 1080,
                                    "u": "https://preview.redd.it/x1eztr7d779g1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b3c1a34a70fcae79e00487650f6552a237866f19"
                                }
                            ],
                            "s": {
                                "y": 2122,
                                "x": 1283,
                                "u": "https://preview.redd.it/x1eztr7d779g1.jpg?width=1283&amp;format=pjpg&amp;auto=webp&amp;s=1efd24c86b862d41ffacaa337d7c0210d7ec791a"
                            },
                            "id": "x1eztr7d779g1"
                        }
                    },
                    "name": "t3_1puugap",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.91,
                    "author_flair_background_color": null,
                    "ups": 16,
                    "domain": "old.reddit.com",
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "gallery_data": {
                        "items": [
                            {
                                "media_id": "j54m2t7d779g1",
                                "id": 823507297
                            },
                            {
                                "media_id": "x1eztr7d779g1",
                                "id": 823507298
                            },
                            {
                                "media_id": "gk3nas7d779g1",
                                "id": 823507299
                            }
                        ]
                    },
                    "link_flair_text": "Praise",
                    "can_mod_post": false,
                    "score": 16,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://a.thumbs.redditmedia.com/bRwspPY_KRHqE2dd3hf2vSK6eUOCsUSE07LgMK7ayR0.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": false,
                    "subreddit_type": "public",
                    "created": 1766602210.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "total_awards_received": 0,
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;People need to stop having \u201cthis vs. that\u201d wards and capitalize on each LLM\u2019s strengths. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "url_overridden_by_dest": "https://www.reddit.com/gallery/1puugap",
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "a1d1fcda-b24c-11f0-a8b0-4ea6c7db837e",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "mod_note": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "num_reports": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#eeff00",
                    "id": "1puugap",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "PromptOutlaw",
                    "discussion_type": null,
                    "num_comments": 13,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1puugap/llms_critiquing_each_others_code_improves_quality/",
                    "stickied": false,
                    "url": "https://www.reddit.com/gallery/1puugap",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766602210.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "I make lots of apps and web sites - and always want images - an icon - a banner image - a title page etc.    I'm allergic to the apis as have been bitten by some big bills so am trying to do everything now inside my subscription - which works great for almost every task I need to do - ie writing code, planning, deploying stuff, setting up stuff...  \\_except\\_ generating images.   If you ask it to generate an image you get some horrible svg thing.\n\nIs there any way to use the highest quality image generation model to generate an image from the cli?",
                    "author_fullname": "t2_7mx2mfsh",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "generating images with codex",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q3h0um",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.88,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 6,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Question",
                    "can_mod_post": false,
                    "score": 6,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767502894.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I make lots of apps and web sites - and always want images - an icon - a banner image - a title page etc.    I&amp;#39;m allergic to the apis as have been bitten by some big bills so am trying to do everything now inside my subscription - which works great for almost every task I need to do - ie writing code, planning, deploying stuff, setting up stuff...  _except_ generating images.   If you ask it to generate an image you get some horrible svg thing.&lt;/p&gt;\n\n&lt;p&gt;Is there any way to use the highest quality image generation model to generate an image from the cli?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "302c6282-b24c-11f0-a6c9-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c13e80",
                    "id": "1q3h0um",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "DifficultTomatillo29",
                    "discussion_type": null,
                    "num_comments": 12,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q3h0um/generating_images_with_codex/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q3h0um/generating_images_with_codex/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767502894.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "so openai been hyping the security stuff in gpt-5.2-codex. saw that react vuln story and figured why not test it\n\nran it on side project first then our work codebase. like 80k lines, node/react/some legacy crap\n\nfound 3 actual issues we missed which was cool. auth timing thing, input validation gap, async race condition\n\nbut it flagged 40+ \"vulnerabilities\" total lol. most were bs. wanted us to rewrite our whole auth cause it \"looked suspicious\".. bro it works fine its just not textbook\n\ncompletely missed a business logic bug in refunds tho. like any human wouldve caught that\n\n20 mins to scan vs like 2 mins for sonarqube. api costs hurt\n\ni use verdent for normal coding stuff so tried their review feature too. similar findings but less noise? idk sample size of 1 doesnt mean much\n\nstill prefer sonarqube + manual review tbh. ai as extra layer sure but too noisy for actual prod use\n\nthat react discovery is prob legit but def cherry picked for marketing. real results way messier\n\nanyone else getting flooded with false positives or just me",
                    "author_fullname": "t2_21t8dur4f1",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "tried gpt-5.2-codex for security scanning. found some real issues but way too many false positives",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1puq03h",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.43,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 0,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Comparison",
                    "can_mod_post": false,
                    "score": 0,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766590321.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;so openai been hyping the security stuff in gpt-5.2-codex. saw that react vuln story and figured why not test it&lt;/p&gt;\n\n&lt;p&gt;ran it on side project first then our work codebase. like 80k lines, node/react/some legacy crap&lt;/p&gt;\n\n&lt;p&gt;found 3 actual issues we missed which was cool. auth timing thing, input validation gap, async race condition&lt;/p&gt;\n\n&lt;p&gt;but it flagged 40+ &amp;quot;vulnerabilities&amp;quot; total lol. most were bs. wanted us to rewrite our whole auth cause it &amp;quot;looked suspicious&amp;quot;.. bro it works fine its just not textbook&lt;/p&gt;\n\n&lt;p&gt;completely missed a business logic bug in refunds tho. like any human wouldve caught that&lt;/p&gt;\n\n&lt;p&gt;20 mins to scan vs like 2 mins for sonarqube. api costs hurt&lt;/p&gt;\n\n&lt;p&gt;i use verdent for normal coding stuff so tried their review feature too. similar findings but less noise? idk sample size of 1 doesnt mean much&lt;/p&gt;\n\n&lt;p&gt;still prefer sonarqube + manual review tbh. ai as extra layer sure but too noisy for actual prod use&lt;/p&gt;\n\n&lt;p&gt;that react discovery is prob legit but def cherry picked for marketing. real results way messier&lt;/p&gt;\n\n&lt;p&gt;anyone else getting flooded with false positives or just me&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "b81001d4-8c88-11f0-8523-42042a14a711",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#817e7e",
                    "id": "1puq03h",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Such-Surround-1353",
                    "discussion_type": null,
                    "num_comments": 14,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1puq03h/tried_gpt52codex_for_security_scanning_found_some/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1puq03h/tried_gpt52codex_for_security_scanning_found_some/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766590321.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "https://preview.redd.it/zhzos5ver2cg1.png?width=1129&amp;format=png&amp;auto=webp&amp;s=ff4432e35c4b9deb518830ca9003c55726d6c4b7\n\n\n\nThis is while trying to be conservative and having Claude 5x Max plan alongside it that also finishes and resets today. Honestly I have a feeling that limits have been reduced, I never came close to the 25% mark before, now I've finished it with an hour to go and I've been trying to manage usage for the past 3 days.\n\n  \nAnyway, first time achievement!",
                    "author_fullname": "t2_yo6ls",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Finished my weekly Pro quota",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 91,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "media_metadata": {
                        "zhzos5ver2cg1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/png",
                            "p": [
                                {
                                    "y": 70,
                                    "x": 108,
                                    "u": "https://preview.redd.it/zhzos5ver2cg1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cd6d813e86b744acd73c28b93a3676e6b307306b"
                                },
                                {
                                    "y": 140,
                                    "x": 216,
                                    "u": "https://preview.redd.it/zhzos5ver2cg1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9d6b207eff6861176c3680f449323f1f534060a0"
                                },
                                {
                                    "y": 208,
                                    "x": 320,
                                    "u": "https://preview.redd.it/zhzos5ver2cg1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f61e7b78b9dfc874cea0d16dc575f7e488a9657b"
                                },
                                {
                                    "y": 416,
                                    "x": 640,
                                    "u": "https://preview.redd.it/zhzos5ver2cg1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e1bd763b0a34196a917f2ceeaf06ba2344e0c106"
                                },
                                {
                                    "y": 624,
                                    "x": 960,
                                    "u": "https://preview.redd.it/zhzos5ver2cg1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8e368df8c5770a1f592680e62e710b927664d285"
                                },
                                {
                                    "y": 702,
                                    "x": 1080,
                                    "u": "https://preview.redd.it/zhzos5ver2cg1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e19cc1bee152519f8a7dd65c50ba792ca7326338"
                                }
                            ],
                            "s": {
                                "y": 734,
                                "x": 1129,
                                "u": "https://preview.redd.it/zhzos5ver2cg1.png?width=1129&amp;format=png&amp;auto=webp&amp;s=ff4432e35c4b9deb518830ca9003c55726d6c4b7"
                            },
                            "id": "zhzos5ver2cg1"
                        }
                    },
                    "name": "t3_1q755vr",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.85,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 9,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Limits",
                    "can_mod_post": false,
                    "score": 9,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/cVKOePAWxBFgtVRGkfC2jtsAgAWOcJBRWAH7cnSoe9I.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767856051.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/zhzos5ver2cg1.png?width=1129&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ff4432e35c4b9deb518830ca9003c55726d6c4b7\"&gt;https://preview.redd.it/zhzos5ver2cg1.png?width=1129&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ff4432e35c4b9deb518830ca9003c55726d6c4b7&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This is while trying to be conservative and having Claude 5x Max plan alongside it that also finishes and resets today. Honestly I have a feeling that limits have been reduced, I never came close to the 25% mark before, now I&amp;#39;ve finished it with an hour to go and I&amp;#39;ve been trying to manage usage for the past 3 days.&lt;/p&gt;\n\n&lt;p&gt;Anyway, first time achievement!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "21466776-922c-11f0-88d8-d2c5faeac8bd",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c73838",
                    "id": "1q755vr",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "xRedStaRx",
                    "discussion_type": null,
                    "num_comments": 10,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q755vr/finished_my_weekly_pro_quota/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q755vr/finished_my_weekly_pro_quota/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767856051.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "wasted 25% of weekly rate limits\n\n5.2-high ran for 3 hours\n\nit got stuck fixing the same thing over and over",
                    "author_fullname": "t2_1dvb1fztcc",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "codex just running for hours getting stuck in loop",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1ppnbat",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.83,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 4,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Complaint",
                    "can_mod_post": false,
                    "score": 4,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766052757.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;wasted 25% of weekly rate limits&lt;/p&gt;\n\n&lt;p&gt;5.2-high ran for 3 hours&lt;/p&gt;\n\n&lt;p&gt;it got stuck fixing the same thing over and over&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "3090d6a0-ab11-11f0-a7f1-526fbbfcd846",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#f40b0b",
                    "id": "1ppnbat",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Just_Lingonberry_352",
                    "discussion_type": null,
                    "num_comments": 14,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1ppnbat/codex_just_running_for_hours_getting_stuck_in_loop/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1ppnbat/codex_just_running_for_hours_getting_stuck_in_loop/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766052757.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "I am on Pro. And for the first time ever today I received --\n\n`Weekly limit: [\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591] 15% left (resets 21:50 on 26 Dec)`\n\nWhich made me supremely suspicious, as thats 3 days away and I have already used up everything?\n\nSo I logged into an old account that still has a subscription for Plus that hasnt expired.  \nAnd with ONE (admittedly expansive research) task using codex-xhigh during which it compacted twice and worked slightly less than  &lt;30 min and we reached our 5h limit.\n\nONE TASK:\n\n`\u2500 Worked for 7m 15s \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500`\n\n`\u2022 Context compacted`\n\n`.........`\n\n`\u2500 Worked for 14m 17s \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500`\n\n`\u2022 Context compacted`\n\n`\u26a0 Heads up, you have less than 25% of your 5h limit left.`\n\n`Run /status for a breakdown.`\n\n`......`\n\n`Search recorder fallback|recorder in .`\n\n`Read __init__.py`\n\n`\u26a0 Heads up, you have less than 5% of your 5h limit left. Run /status for a breakdown.`\n\n`\u25a0 Error running remote compact task: You've hit`\n\n`your usage limit. Upgrade to Pro (https://`\n\n`openai.com/chatgpt/pricing), visit https://`\n\n[`chatgpt.com/codex/settings/usage`](http://chatgpt.com/codex/settings/usage) `to purchase more`\n\n`credits or try again at Dec 24th, 2025 3:38 AM.`\n\nThis never ever used to happen before.  One single task, admittedly hard and on codex xhigh, wipes out the entire 5h limit in under 30 minutes on Plus.\n\n[The current time here where I am ](https://preview.redd.it/htu5bd7eu09g1.png?width=71&amp;format=png&amp;auto=webp&amp;s=409e4a2ebdcea2ecacc57d8643eda9070f35efb5)",
                    "author_fullname": "t2_24nkba7ktu",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Massive sudden usage nerf on Codex, any one else noticed it?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "media_metadata": {
                        "htu5bd7eu09g1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/png",
                            "p": [],
                            "s": {
                                "y": 33,
                                "x": 71,
                                "u": "https://preview.redd.it/htu5bd7eu09g1.png?width=71&amp;format=png&amp;auto=webp&amp;s=409e4a2ebdcea2ecacc57d8643eda9070f35efb5"
                            },
                            "id": "htu5bd7eu09g1"
                        }
                    },
                    "name": "t3_1pu5q6y",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.43,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 0,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Question",
                    "can_mod_post": false,
                    "score": 0,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766525531.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am on Pro. And for the first time ever today I received --&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Weekly limit: [\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591] 15% left (resets 21:50 on 26 Dec)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Which made me supremely suspicious, as thats 3 days away and I have already used up everything?&lt;/p&gt;\n\n&lt;p&gt;So I logged into an old account that still has a subscription for Plus that hasnt expired.&lt;br/&gt;\nAnd with ONE (admittedly expansive research) task using codex-xhigh during which it compacted twice and worked slightly less than  &amp;lt;30 min and we reached our 5h limit.&lt;/p&gt;\n\n&lt;p&gt;ONE TASK:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;\u2500 Worked for 7m 15s \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;\u2022 Context compacted&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;.........&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;\u2500 Worked for 14m 17s \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;\u2022 Context compacted&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;\u26a0 Heads up, you have less than 25% of your 5h limit left.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Run /status for a breakdown.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;......&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Search recorder fallback|recorder in .&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Read __init__.py&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;\u26a0 Heads up, you have less than 5% of your 5h limit left. Run /status for a breakdown.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;\u25a0 Error running remote compact task: You&amp;#39;ve hit&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;your usage limit. Upgrade to Pro (https://&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;openai.com/chatgpt/pricing), visit https://&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://chatgpt.com/codex/settings/usage\"&gt;&lt;code&gt;chatgpt.com/codex/settings/usage&lt;/code&gt;&lt;/a&gt; &lt;code&gt;to purchase more&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;credits or try again at Dec 24th, 2025 3:38 AM.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;This never ever used to happen before.  One single task, admittedly hard and on codex xhigh, wipes out the entire 5h limit in under 30 minutes on Plus.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/htu5bd7eu09g1.png?width=71&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=409e4a2ebdcea2ecacc57d8643eda9070f35efb5\"&gt;The current time here where I am &lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "302c6282-b24c-11f0-a6c9-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c13e80",
                    "id": "1pu5q6y",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Thin_Landscape9425",
                    "discussion_type": null,
                    "num_comments": 12,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1pu5q6y/massive_sudden_usage_nerf_on_codex_any_one_else/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1pu5q6y/massive_sudden_usage_nerf_on_codex_any_one_else/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766525531.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Claude Code has claude --dangerously-skip-permissions which lets it run without asking permissions. Does Codex CLI have something similar? Couldn't find it in the docs but I'm sure it has it.",
                    "author_fullname": "t2_20h28h7k6t",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Is there a way to have codex not ask permissions? Like --dangerously-skip-permissions?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q5z84v",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 11,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Question",
                    "can_mod_post": false,
                    "score": 11,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767743125.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Claude Code has claude --dangerously-skip-permissions which lets it run without asking permissions. Does Codex CLI have something similar? Couldn&amp;#39;t find it in the docs but I&amp;#39;m sure it has it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "302c6282-b24c-11f0-a6c9-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c13e80",
                    "id": "1q5z84v",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "agentic-consultant",
                    "discussion_type": null,
                    "num_comments": 8,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q5z84v/is_there_a_way_to_have_codex_not_ask_permissions/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q5z84v/is_there_a_way_to_have_codex_not_ask_permissions/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767743125.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "[https://github.com/numman-ali/codex-wrapped](https://github.com/numman-ali/codex-wrapped)",
                    "author_fullname": "t2_147w1sjork",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "My Codex Wrapped",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 130,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1px5vub",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.85,
                    "author_flair_background_color": null,
                    "ups": 18,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": true,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Showcase",
                    "can_mod_post": false,
                    "score": 18,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/9v7rjXpjARONOp0AOl_rNDDMVT1B8D4RJf6T6c973YM.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "image",
                    "content_categories": null,
                    "is_self": false,
                    "subreddit_type": "public",
                    "created": 1766862671.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "i.redd.it",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/numman-ali/codex-wrapped\"&gt;https://github.com/numman-ali/codex-wrapped&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "url_overridden_by_dest": "https://i.redd.it/9q02qi4rps9g1.jpeg",
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://preview.redd.it/9q02qi4rps9g1.jpeg?auto=webp&amp;s=12377f4230e0db1f3a8bacab7f3dfc1c9476ea88",
                                    "width": 1500,
                                    "height": 1400
                                },
                                "resolutions": [
                                    {
                                        "url": "https://preview.redd.it/9q02qi4rps9g1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f960028b91a6da4af832a67373ffcffe148727b6",
                                        "width": 108,
                                        "height": 100
                                    },
                                    {
                                        "url": "https://preview.redd.it/9q02qi4rps9g1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5d08ce84fa135e939a95864c77ba84db2db32f4e",
                                        "width": 216,
                                        "height": 201
                                    },
                                    {
                                        "url": "https://preview.redd.it/9q02qi4rps9g1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c1cb71b8419e8ae925cd5b47351c374b8c988525",
                                        "width": 320,
                                        "height": 298
                                    },
                                    {
                                        "url": "https://preview.redd.it/9q02qi4rps9g1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2d7a41789060d2859288ac188335b8ba9dbf2e26",
                                        "width": 640,
                                        "height": 597
                                    },
                                    {
                                        "url": "https://preview.redd.it/9q02qi4rps9g1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=acbfafd974011929eb713a21dce7ab67d78ffe33",
                                        "width": 960,
                                        "height": 896
                                    },
                                    {
                                        "url": "https://preview.redd.it/9q02qi4rps9g1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=72a0cf218947b82dbff06f9510ec0ce007c74bb5",
                                        "width": 1080,
                                        "height": 1008
                                    }
                                ],
                                "variants": {},
                                "id": "f4RgAaatQNkhxwLXtBAUVExMu7YzFXuzMRMfrvl1k3U"
                            }
                        ],
                        "enabled": true
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "e350908e-b24e-11f0-b239-62e50da6d05a",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "mod_note": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "num_reports": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#00ff2a",
                    "id": "1px5vub",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Swimming_Driver4974",
                    "discussion_type": null,
                    "num_comments": 8,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1px5vub/my_codex_wrapped/",
                    "stickied": false,
                    "url": "https://i.redd.it/9q02qi4rps9g1.jpeg",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766862671.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "So I've gone through the documentation for the extension and setting the config.toml for full-auto, I even tried doing agent(full access) and it still asks for permission to edit files.\n\nDoes anyone have a config.toml that is working that I can try?",
                    "author_fullname": "t2_vbnsj",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Codex VSCode Extension keeps asking for permission to do stuff",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1qbdmss",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 2,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Question",
                    "can_mod_post": false,
                    "score": 2,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1768267160.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve gone through the documentation for the extension and setting the config.toml for full-auto, I even tried doing agent(full access) and it still asks for permission to edit files.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have a config.toml that is working that I can try?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "302c6282-b24c-11f0-a6c9-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c13e80",
                    "id": "1qbdmss",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "E72M",
                    "discussion_type": null,
                    "num_comments": 7,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1qbdmss/codex_vscode_extension_keeps_asking_for/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1qbdmss/codex_vscode_extension_keeps_asking_for/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1768267160.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Hello there, dear users.\n\n\n\nSo I wanted to ask, is there any known official extension or a way where I can control my browser? I was looking for something like Claude made their extension!",
                    "author_fullname": "t2_83bxfg4t",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Is there a way of controlling my browser with ChatGPT?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1qf17yr",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 2,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Question",
                    "can_mod_post": false,
                    "score": 2,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1768618162.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there, dear users.&lt;/p&gt;\n\n&lt;p&gt;So I wanted to ask, is there any known official extension or a way where I can control my browser? I was looking for something like Claude made their extension!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "302c6282-b24c-11f0-a6c9-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c13e80",
                    "id": "1qf17yr",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Creative-Mud4414",
                    "discussion_type": null,
                    "num_comments": 5,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1qf17yr/is_there_a_way_of_controlling_my_browser_with/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1qf17yr/is_there_a_way_of_controlling_my_browser_with/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1768618162.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "I love OpenAI's codex, but the original sub description also sounds extremely cool and something I am interested in. Where has that community moved to? The above snapshot is from old reddit btw, in new reddit it shows the correct description.",
                    "author_fullname": "t2_a779auxs",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "is_gallery": true,
                    "title": "This sub was created 14 years ago, where did the original community move to?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 106,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "media_metadata": {
                        "r4zrwh8l3c9g1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/png",
                            "p": [
                                {
                                    "y": 121,
                                    "x": 108,
                                    "u": "https://preview.redd.it/r4zrwh8l3c9g1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fdc9ceac2fd9b8b59daa9554f7d81ed70d5064b8"
                                },
                                {
                                    "y": 242,
                                    "x": 216,
                                    "u": "https://preview.redd.it/r4zrwh8l3c9g1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d6dfb3d8211bade767b982cc961b7f15ff68b89a"
                                }
                            ],
                            "s": {
                                "y": 339,
                                "x": 302,
                                "u": "https://preview.redd.it/r4zrwh8l3c9g1.png?width=302&amp;format=png&amp;auto=webp&amp;s=1a1121fdb4864e2d6aded5ddfe7d1308ee3c0075"
                            },
                            "id": "r4zrwh8l3c9g1"
                        },
                        "ied7qjne3c9g1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/png",
                            "p": [
                                {
                                    "y": 82,
                                    "x": 108,
                                    "u": "https://preview.redd.it/ied7qjne3c9g1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e33e6350de2d73f524fa746f6953d3a4c522d203"
                                },
                                {
                                    "y": 164,
                                    "x": 216,
                                    "u": "https://preview.redd.it/ied7qjne3c9g1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=73774107ee4154406b1e883e60cb9d2ba88ad03f"
                                }
                            ],
                            "s": {
                                "y": 231,
                                "x": 303,
                                "u": "https://preview.redd.it/ied7qjne3c9g1.png?width=303&amp;format=png&amp;auto=webp&amp;s=18495b1494831983b9d322ac941edfe3a69a63d0"
                            },
                            "id": "ied7qjne3c9g1"
                        }
                    },
                    "name": "t3_1pvbcn8",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "ups": 6,
                    "domain": "old.reddit.com",
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "gallery_data": {
                        "items": [
                            {
                                "media_id": "ied7qjne3c9g1",
                                "id": 823928784
                            },
                            {
                                "media_id": "r4zrwh8l3c9g1",
                                "id": 823928785
                            }
                        ]
                    },
                    "link_flair_text": "Question",
                    "can_mod_post": false,
                    "score": 6,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/dg9AhdysHxbJ4xjNTII1VpgiWyFj6zefCDe3LL72D1U.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": false,
                    "subreddit_type": "public",
                    "created": 1766661540.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "total_awards_received": 0,
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I love OpenAI&amp;#39;s codex, but the original sub description also sounds extremely cool and something I am interested in. Where has that community moved to? The above snapshot is from old reddit btw, in new reddit it shows the correct description.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "url_overridden_by_dest": "https://www.reddit.com/gallery/1pvbcn8",
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "302c6282-b24c-11f0-a6c9-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "mod_note": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "num_reports": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c13e80",
                    "id": "1pvbcn8",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "obvithrowaway34434",
                    "discussion_type": null,
                    "num_comments": 6,
                    "send_replies": false,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1pvbcn8/this_sub_was_created_14_years_ago_where_did_the/",
                    "stickied": false,
                    "url": "https://www.reddit.com/gallery/1pvbcn8",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766661540.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Sharing through a Zoom event we're hosting next week with Romain Huet, Head of DevEx at OpenAI. Please feel free to join for the event &amp; Q&amp;A. More below - thanks!\n\n\\---\n\nOn Jan 21st at 10 am PT, join the leaders of Codex and OpenAI DevEx for a behind-the-scenes look at how OpenAI's engineering teams use Codex day-to-day. We'll cover practical habits, default configurations, and enterprise best practices - plus a live demo showing realistic parallelized workflows on production-style codebases.\n\n**REGISTER HERE:**\u00a0[https://bvp.zoom.us/webinar/register/WN\\_bul7bYg6RcCXBuxl30Kw...](https://bvp.zoom.us/webinar/register/WN_bul7bYg6RcCXBuxl30KwRA#/registration)\n\n**What we'll cover:**\n\n* How OpenAI uses Codex internally - the stack and workflows their eng teams rely on \n* Live demo: parallelized task execution (implementation + tests + PR notes), handling real snags, and reviewable output hygiene\n* Best practices for code review, security, repo conventions, and CI integration\n* Collaboration patterns and guardrails for enterprise teams\n* Where Codex fits in the broader AI coding landscape and what\u2019s ahead\n\n**Who Should Attend:** Engineering leaders, Heads of Product, and technical teams evaluating or scaling AI-assisted development workflows\u2014especially those managing large production scale codebases and looking to move beyond chat-based copilots.\n\n*Bessemer's Research to Runtime series brings together early users of emerging AI engineering tools with the original creators, for a thoughtful discussion, demos, and insight into how to build AI systems at scale. Access past sessions at*\u00a0[*https://researchtoruntime.com/*](https://researchtoruntime.com/)",
                    "author_fullname": "t2_ios9cy2h",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Codex Zoom Event \u2013 10xing Eng Velocity",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1qdsptw",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.92,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 9,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "News",
                    "can_mod_post": false,
                    "score": 9,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1768504258.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sharing through a Zoom event we&amp;#39;re hosting next week with Romain Huet, Head of DevEx at OpenAI. Please feel free to join for the event &amp;amp; Q&amp;amp;A. More below - thanks!&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;On Jan 21st at 10 am PT, join the leaders of Codex and OpenAI DevEx for a behind-the-scenes look at how OpenAI&amp;#39;s engineering teams use Codex day-to-day. We&amp;#39;ll cover practical habits, default configurations, and enterprise best practices - plus a live demo showing realistic parallelized workflows on production-style codebases.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;REGISTER HERE:&lt;/strong&gt;\u00a0&lt;a href=\"https://bvp.zoom.us/webinar/register/WN_bul7bYg6RcCXBuxl30KwRA#/registration\"&gt;https://bvp.zoom.us/webinar/register/WN_bul7bYg6RcCXBuxl30Kw...&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What we&amp;#39;ll cover:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How OpenAI uses Codex internally - the stack and workflows their eng teams rely on &lt;/li&gt;\n&lt;li&gt;Live demo: parallelized task execution (implementation + tests + PR notes), handling real snags, and reviewable output hygiene&lt;/li&gt;\n&lt;li&gt;Best practices for code review, security, repo conventions, and CI integration&lt;/li&gt;\n&lt;li&gt;Collaboration patterns and guardrails for enterprise teams&lt;/li&gt;\n&lt;li&gt;Where Codex fits in the broader AI coding landscape and what\u2019s ahead&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Who Should Attend:&lt;/strong&gt; Engineering leaders, Heads of Product, and technical teams evaluating or scaling AI-assisted development workflows\u2014especially those managing large production scale codebases and looking to move beyond chat-based copilots.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Bessemer&amp;#39;s Research to Runtime series brings together early users of emerging AI engineering tools with the original creators, for a thoughtful discussion, demos, and insight into how to build AI systems at scale. Access past sessions at&lt;/em&gt;\u00a0&lt;a href=\"https://researchtoruntime.com/\"&gt;&lt;em&gt;https://researchtoruntime.com/&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/1Zib9dPRHmCkIZSAFBeSDGizKawhIUcJkrEDdoB7Yio.jpeg?auto=webp&amp;s=fe27d855098d808ff25d5e1f81759a6697562c7a",
                                    "width": 1200,
                                    "height": 630
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/1Zib9dPRHmCkIZSAFBeSDGizKawhIUcJkrEDdoB7Yio.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=52d4bbbf113038235935627b6fcd1c8a1c637b4b",
                                        "width": 108,
                                        "height": 56
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/1Zib9dPRHmCkIZSAFBeSDGizKawhIUcJkrEDdoB7Yio.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a1002a6b98eda83fa167f58eacc781d6ae5eb8dd",
                                        "width": 216,
                                        "height": 113
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/1Zib9dPRHmCkIZSAFBeSDGizKawhIUcJkrEDdoB7Yio.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5d6595e56ef3c9d2b2b039c2407770febfab983b",
                                        "width": 320,
                                        "height": 168
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/1Zib9dPRHmCkIZSAFBeSDGizKawhIUcJkrEDdoB7Yio.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b143e35ea1091b7039d6fef0bb2599c1802f6d4a",
                                        "width": 640,
                                        "height": 336
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/1Zib9dPRHmCkIZSAFBeSDGizKawhIUcJkrEDdoB7Yio.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f537d29c54fede142e053862fd5df7ae46e4c9bc",
                                        "width": 960,
                                        "height": 504
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/1Zib9dPRHmCkIZSAFBeSDGizKawhIUcJkrEDdoB7Yio.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e2a9dd56d0eaf5b43fa47cbb9ea5559978e26269",
                                        "width": 1080,
                                        "height": 567
                                    }
                                ],
                                "variants": {},
                                "id": "1Zib9dPRHmCkIZSAFBeSDGizKawhIUcJkrEDdoB7Yio"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "d91881fa-8c86-11f0-9995-42042a14a711",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "transparent",
                    "id": "1qdsptw",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "bvn-bvp",
                    "discussion_type": null,
                    "num_comments": 3,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1qdsptw/codex_zoom_event_10xing_eng_velocity/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1qdsptw/codex_zoom_event_10xing_eng_velocity/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1768504258.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Im currently contributing to openai codex cli by proposing a new feature. As of now, codex doesn't have prompt preview, which could be annoyance if you wanna watch in detail for your previous prompt. Let me think what you guys think of this feat.\n\nIf u think this is a good feat, feel free to upvote on Github issue! Tysm for ur collaboration, everyone! :))\n\n[https://github.com/openai/codex/issues/8709](https://github.com/openai/codex/issues/8709)\n\nhttps://reddit.com/link/1q9mdrs/video/goy1yk25xmcg1/player",
                    "author_fullname": "t2_uw2hu7fi9",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Codex Feat : Add expand/collapse prompt view in resume picker with \u2190/\u2192 keys",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 70,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "media_metadata": {
                        "goy1yk25xmcg1": {
                            "status": "valid",
                            "e": "RedditVideo",
                            "dashUrl": "https://v.redd.it/link/1q9mdrs/asset/goy1yk25xmcg1/DASHPlaylist.mpd?a=1771221921%2CMWQ4Nzk2ZWRmOTZlNTIxYzViNDdlNGYzNTQ5ZjNlMGQ1ZDAwN2ZlOWMyNDliMTM1NDgyNjJlMTliZDEzMTM0ZQ%3D%3D&amp;v=1&amp;f=sd",
                            "x": 1846,
                            "y": 1080,
                            "hlsUrl": "https://v.redd.it/link/1q9mdrs/asset/goy1yk25xmcg1/HLSPlaylist.m3u8?a=1771221921%2CNjM1ZmIzMmY3MzM2YjQ1NmE1NTkxMjM2MGMzMmIzMTM5NTNjZmFhNGM5YzZmYmQwOTM0MDUwNWM0MTI4Yjk1YQ%3D%3D&amp;v=1&amp;f=sd",
                            "id": "goy1yk25xmcg1",
                            "isGif": false
                        }
                    },
                    "name": "t3_1q9mdrs",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "ups": 6,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Question",
                    "can_mod_post": false,
                    "score": 6,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://external-preview.redd.it/CG4puV6qM813UB-93mOgva7LDsVigNVnLiLi7uE1kNI.png?width=140&amp;height=70&amp;auto=webp&amp;s=ad29feb7d88068d4e5d5f45f058cdc548fd5ccc2",
                    "edited": 1768105003.0,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "subreddit_type": "public",
                    "created": 1768095980.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im currently contributing to openai codex cli by proposing a new feature. As of now, codex doesn&amp;#39;t have prompt preview, which could be annoyance if you wanna watch in detail for your previous prompt. Let me think what you guys think of this feat.&lt;/p&gt;\n\n&lt;p&gt;If u think this is a good feat, feel free to upvote on Github issue! Tysm for ur collaboration, everyone! :))&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/openai/codex/issues/8709\"&gt;https://github.com/openai/codex/issues/8709&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/1q9mdrs/video/goy1yk25xmcg1/player\"&gt;https://reddit.com/link/1q9mdrs/video/goy1yk25xmcg1/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/CG4puV6qM813UB-93mOgva7LDsVigNVnLiLi7uE1kNI.png?auto=webp&amp;s=4001924188f6798009822f932ff4e23d8bacfd53",
                                    "width": 1200,
                                    "height": 600
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/CG4puV6qM813UB-93mOgva7LDsVigNVnLiLi7uE1kNI.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ed58e1d3cd30016cffd5fd7b9ac7c78cff9a5438",
                                        "width": 108,
                                        "height": 54
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/CG4puV6qM813UB-93mOgva7LDsVigNVnLiLi7uE1kNI.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8d5c67242f6a176cd5c1da90eb6e1829144cdff4",
                                        "width": 216,
                                        "height": 108
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/CG4puV6qM813UB-93mOgva7LDsVigNVnLiLi7uE1kNI.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=73ffae3112d14720ee25b00e420c325980abb911",
                                        "width": 320,
                                        "height": 160
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/CG4puV6qM813UB-93mOgva7LDsVigNVnLiLi7uE1kNI.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=38890d7d3103390944a7d667bbd96d0789eb1877",
                                        "width": 640,
                                        "height": 320
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/CG4puV6qM813UB-93mOgva7LDsVigNVnLiLi7uE1kNI.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8496806a716ef0cc1036ed4d0e4a2c220d7d6ee3",
                                        "width": 960,
                                        "height": 480
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/CG4puV6qM813UB-93mOgva7LDsVigNVnLiLi7uE1kNI.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8c7525f285b304f8a275e3422489ff4202601199",
                                        "width": 1080,
                                        "height": 540
                                    }
                                ],
                                "variants": {},
                                "id": "CG4puV6qM813UB-93mOgva7LDsVigNVnLiLi7uE1kNI"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "302c6282-b24c-11f0-a6c9-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "mod_note": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "num_reports": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c13e80",
                    "id": "1q9mdrs",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Much-Goat-8959",
                    "discussion_type": null,
                    "num_comments": 4,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q9mdrs/codex_feat_add_expandcollapse_prompt_view_in/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q9mdrs/codex_feat_add_expandcollapse_prompt_view_in/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1768095980.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "I'm home alone after New Years. What do I decide to do? Force my two favorite AI coding \"friends\" to go head-to-head.\n\nI expected to find a winner. Instead, I found something more interesting: using both models together was more effective than using either individually.\n\n## The Setup\n\nThis wasn't benchmarks or \"build Minecraft from scratch.\" This was real work: adding vector search to my AI dev tooling (an MCP server I use for longer-term memory).\n\n**The rules**: SOTA models, same starting prompt, parallel terminals.\n**The tools**: Anthropic $100/m subscription, ChatGPT Plus (~~$20~~ $0/m for this month - *thanks Sam!*)\n\nBoth models got the same task across three phases:\n- **Research** - Gather background, find relevant code\n- **Planning** - Create a concrete implementation plan\n- **Review** - Critique each other's plans\n\nI've used Claude pretty much daily since April. I've used Codex for three days. My workflow was built around Claude's patterns. So there's definitely a Claude bias here - but that's exactly what makes the results interesting.\n\n## The Highlights\n\n**Research phase:** Claude recommended Voyage AI for embeddings because they're an \"Anthropic partner.\" I laughed out loud. Claude citing its creator's business partnerships as a technical justification is either endearing or concerning - especially given the flak OpenAI gets for planned ads. Turns out Anthropic may have beat them to it...\n\n**Planning phase:** Claude produces cleaner markdown with actionable code snippets. Codex produces XML-based architecture docs. Different approaches, both reasonable.\n\n**Review phase:** This is where it got interesting.\n\nI asked each model to critique both plans (without telling them who wrote which). Round 1 went as expected\u2014each model preferred its own plan.\n\nThen Codex dropped this:\n\n&gt; \"Dimension mismatch: Claude's plan assumes 1536-dim embeddings but the config specifies 1024. This would fail silently at query time\u2014vectors wouldn't match, search would return zero results.\"\n\nAt first look Claude's plan was reasonable to me - it looked clean, well-structured, thoroughly reasoned. It also contained bugs / contradictions.\n\nCodex found two more issues:\n- Claude specified both \"hard-fail on missing credentials\" AND \"graceful fallback\"\u2014contradictory\n- A tool naming collision with an existing tool\n\nWhen I showed Claude what Codex found:\n\n&gt; \"Good catch. Codex is right\u2014I missed several concrete issues.\"\n\nThe plan was better off by having a second pair of eyes.\n\n## My Takeaway\n\nThe winner isn't Codex or Claude - it's running both.\n\nFor daily coding, I've switched to Codex as my primary driver. It felt more adherent to instructions and more thorough (plus the novelty is energizing). Additionally, when compared to Codex, Claude seemed a bit... ditzy. I never noticed it when using Claude alone, but compared to Codex, the difference was noticeable.\n\nFor anything that matters (architecture decisions, complex integrations), I now run it past both models before implementing.\n\nThe $200/month question isn't \"which model is best?\" It's \"when is a second opinion worth the overhead?\" For me: any time I find myself wondering if the wool is being pulled over my eyes by a robot (which it turns out is pretty often).\n\nSorry Anthropic, you lost the daily driver slot for now (try again next month!). But Claude's still on the team.\n\n## The Receipts\n\nI documented everything. Full transcripts, the actual plans, side-by-side comparisons. If you want to see exactly what happened (or disagree with my conclusions), the raw materials are on my blog: https://benr.build/blog/claude-vs-codex-messy-middle\n\n---\n\nThis is n=1. But it's a documented n=1 with receipts, which is more than most AI comparisons offer.\n\nCurious if anyone else has tried running multiple models on the same task. What patterns have you noticed?\n",
                    "author_fullname": "t2_hvt4a",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Opus 4.5 head-to-head against Codex 5.2 xhigh on a real task. Neither won.",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q6iy1c",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.5,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 0,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Comparison",
                    "can_mod_post": false,
                    "score": 0,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767801050.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m home alone after New Years. What do I decide to do? Force my two favorite AI coding &amp;quot;friends&amp;quot; to go head-to-head.&lt;/p&gt;\n\n&lt;p&gt;I expected to find a winner. Instead, I found something more interesting: using both models together was more effective than using either individually.&lt;/p&gt;\n\n&lt;h2&gt;The Setup&lt;/h2&gt;\n\n&lt;p&gt;This wasn&amp;#39;t benchmarks or &amp;quot;build Minecraft from scratch.&amp;quot; This was real work: adding vector search to my AI dev tooling (an MCP server I use for longer-term memory).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The rules&lt;/strong&gt;: SOTA models, same starting prompt, parallel terminals.\n&lt;strong&gt;The tools&lt;/strong&gt;: Anthropic $100/m subscription, ChatGPT Plus (&lt;del&gt;$20&lt;/del&gt; $0/m for this month - &lt;em&gt;thanks Sam!&lt;/em&gt;)&lt;/p&gt;\n\n&lt;p&gt;Both models got the same task across three phases:\n- &lt;strong&gt;Research&lt;/strong&gt; - Gather background, find relevant code\n- &lt;strong&gt;Planning&lt;/strong&gt; - Create a concrete implementation plan\n- &lt;strong&gt;Review&lt;/strong&gt; - Critique each other&amp;#39;s plans&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve used Claude pretty much daily since April. I&amp;#39;ve used Codex for three days. My workflow was built around Claude&amp;#39;s patterns. So there&amp;#39;s definitely a Claude bias here - but that&amp;#39;s exactly what makes the results interesting.&lt;/p&gt;\n\n&lt;h2&gt;The Highlights&lt;/h2&gt;\n\n&lt;p&gt;&lt;strong&gt;Research phase:&lt;/strong&gt; Claude recommended Voyage AI for embeddings because they&amp;#39;re an &amp;quot;Anthropic partner.&amp;quot; I laughed out loud. Claude citing its creator&amp;#39;s business partnerships as a technical justification is either endearing or concerning - especially given the flak OpenAI gets for planned ads. Turns out Anthropic may have beat them to it...&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Planning phase:&lt;/strong&gt; Claude produces cleaner markdown with actionable code snippets. Codex produces XML-based architecture docs. Different approaches, both reasonable.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Review phase:&lt;/strong&gt; This is where it got interesting.&lt;/p&gt;\n\n&lt;p&gt;I asked each model to critique both plans (without telling them who wrote which). Round 1 went as expected\u2014each model preferred its own plan.&lt;/p&gt;\n\n&lt;p&gt;Then Codex dropped this:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&amp;quot;Dimension mismatch: Claude&amp;#39;s plan assumes 1536-dim embeddings but the config specifies 1024. This would fail silently at query time\u2014vectors wouldn&amp;#39;t match, search would return zero results.&amp;quot;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;At first look Claude&amp;#39;s plan was reasonable to me - it looked clean, well-structured, thoroughly reasoned. It also contained bugs / contradictions.&lt;/p&gt;\n\n&lt;p&gt;Codex found two more issues:\n- Claude specified both &amp;quot;hard-fail on missing credentials&amp;quot; AND &amp;quot;graceful fallback&amp;quot;\u2014contradictory\n- A tool naming collision with an existing tool&lt;/p&gt;\n\n&lt;p&gt;When I showed Claude what Codex found:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&amp;quot;Good catch. Codex is right\u2014I missed several concrete issues.&amp;quot;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The plan was better off by having a second pair of eyes.&lt;/p&gt;\n\n&lt;h2&gt;My Takeaway&lt;/h2&gt;\n\n&lt;p&gt;The winner isn&amp;#39;t Codex or Claude - it&amp;#39;s running both.&lt;/p&gt;\n\n&lt;p&gt;For daily coding, I&amp;#39;ve switched to Codex as my primary driver. It felt more adherent to instructions and more thorough (plus the novelty is energizing). Additionally, when compared to Codex, Claude seemed a bit... ditzy. I never noticed it when using Claude alone, but compared to Codex, the difference was noticeable.&lt;/p&gt;\n\n&lt;p&gt;For anything that matters (architecture decisions, complex integrations), I now run it past both models before implementing.&lt;/p&gt;\n\n&lt;p&gt;The $200/month question isn&amp;#39;t &amp;quot;which model is best?&amp;quot; It&amp;#39;s &amp;quot;when is a second opinion worth the overhead?&amp;quot; For me: any time I find myself wondering if the wool is being pulled over my eyes by a robot (which it turns out is pretty often).&lt;/p&gt;\n\n&lt;p&gt;Sorry Anthropic, you lost the daily driver slot for now (try again next month!). But Claude&amp;#39;s still on the team.&lt;/p&gt;\n\n&lt;h2&gt;The Receipts&lt;/h2&gt;\n\n&lt;p&gt;I documented everything. Full transcripts, the actual plans, side-by-side comparisons. If you want to see exactly what happened (or disagree with my conclusions), the raw materials are on my blog: &lt;a href=\"https://benr.build/blog/claude-vs-codex-messy-middle\"&gt;https://benr.build/blog/claude-vs-codex-messy-middle&lt;/a&gt;&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;This is n=1. But it&amp;#39;s a documented n=1 with receipts, which is more than most AI comparisons offer.&lt;/p&gt;\n\n&lt;p&gt;Curious if anyone else has tried running multiple models on the same task. What patterns have you noticed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/2FCeD8l6GmDuGW3vsLdboxzoFAv8e_jaPYkYPcusaps.png?auto=webp&amp;s=6104d12f1bf55b8bc114c8a2ce5e90936cf3e0d9",
                                    "width": 1200,
                                    "height": 630
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/2FCeD8l6GmDuGW3vsLdboxzoFAv8e_jaPYkYPcusaps.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c88b3beb67a46c2a48ee6931b0182017c710c4f",
                                        "width": 108,
                                        "height": 56
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/2FCeD8l6GmDuGW3vsLdboxzoFAv8e_jaPYkYPcusaps.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7844c3d09edb1bfe64907431abdb72b79240b55b",
                                        "width": 216,
                                        "height": 113
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/2FCeD8l6GmDuGW3vsLdboxzoFAv8e_jaPYkYPcusaps.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=02ea077b86c4985493ab3b2b45b69d843f48f381",
                                        "width": 320,
                                        "height": 168
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/2FCeD8l6GmDuGW3vsLdboxzoFAv8e_jaPYkYPcusaps.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0c6442160d7f287cae7610cf345cf6c9f2f6696b",
                                        "width": 640,
                                        "height": 336
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/2FCeD8l6GmDuGW3vsLdboxzoFAv8e_jaPYkYPcusaps.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3fb9c7f69dec6764123d42ab9aa6f6623862d75c",
                                        "width": 960,
                                        "height": 504
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/2FCeD8l6GmDuGW3vsLdboxzoFAv8e_jaPYkYPcusaps.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7623bcde777c834250b9db2b4ffa677d248d08f6",
                                        "width": 1080,
                                        "height": 567
                                    }
                                ],
                                "variants": {},
                                "id": "2FCeD8l6GmDuGW3vsLdboxzoFAv8e_jaPYkYPcusaps"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "b81001d4-8c88-11f0-8523-42042a14a711",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#817e7e",
                    "id": "1q6iy1c",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "bisonbear2",
                    "discussion_type": null,
                    "num_comments": 5,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q6iy1c/opus_45_headtohead_against_codex_52_xhigh_on_a/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q6iy1c/opus_45_headtohead_against_codex_52_xhigh_on_a/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767801050.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Does anyone know how to configure and use subagents in the Codex terminal?",
                    "author_fullname": "t2_1h1rkfn5gg",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Subagentes",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1pvmzuz",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 7,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Question",
                    "can_mod_post": false,
                    "score": 7,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766697168.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know how to configure and use subagents in the Codex terminal?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "302c6282-b24c-11f0-a6c9-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c13e80",
                    "id": "1pvmzuz",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "BroadPressure6772",
                    "discussion_type": null,
                    "num_comments": 6,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1pvmzuz/subagentes/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1pvmzuz/subagentes/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766697168.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Just saw a new feature called - multi-conversation \u201cagent control\u201d\nhttps://github.com/openai/codex/releases\n\nAnyone know what it is?",
                    "author_fullname": "t2_7wb6car6z",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "multi-conversation \u201cagent control\u201d",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q6ecfd",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 4,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Question",
                    "can_mod_post": false,
                    "score": 4,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767789689.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just saw a new feature called - multi-conversation \u201cagent control\u201d\n&lt;a href=\"https://github.com/openai/codex/releases\"&gt;https://github.com/openai/codex/releases&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Anyone know what it is?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/FiswlCedncRb6RbWz6sa_0bP7A5ofVuvSkdAagJr2u0.png?auto=webp&amp;s=679402fe02f203c942524bc79d7edf7cba781647",
                                    "width": 1200,
                                    "height": 600
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/FiswlCedncRb6RbWz6sa_0bP7A5ofVuvSkdAagJr2u0.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4ffdd5eb956a6c81f6b8a25db48e6e08741dd331",
                                        "width": 108,
                                        "height": 54
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/FiswlCedncRb6RbWz6sa_0bP7A5ofVuvSkdAagJr2u0.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=89de826d24998435c1a025a1a6713b231b0948e6",
                                        "width": 216,
                                        "height": 108
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/FiswlCedncRb6RbWz6sa_0bP7A5ofVuvSkdAagJr2u0.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a722c78a33dbe1d48479d73305fb62542e06609e",
                                        "width": 320,
                                        "height": 160
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/FiswlCedncRb6RbWz6sa_0bP7A5ofVuvSkdAagJr2u0.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=cb13ee0cc1caccd7a6086aa6c0fb3ae701fe9ea9",
                                        "width": 640,
                                        "height": 320
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/FiswlCedncRb6RbWz6sa_0bP7A5ofVuvSkdAagJr2u0.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=56d73f53c9ff3d5d514a02b2e51e0e880587f1a5",
                                        "width": 960,
                                        "height": 480
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/FiswlCedncRb6RbWz6sa_0bP7A5ofVuvSkdAagJr2u0.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d132b8ea4132710af709cfc8a518ed490c795001",
                                        "width": 1080,
                                        "height": 540
                                    }
                                ],
                                "variants": {},
                                "id": "FiswlCedncRb6RbWz6sa_0bP7A5ofVuvSkdAagJr2u0"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "302c6282-b24c-11f0-a6c9-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c13e80",
                    "id": "1q6ecfd",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "TroubleOwn3156",
                    "discussion_type": null,
                    "num_comments": 4,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q6ecfd/multiconversation_agent_control/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q6ecfd/multiconversation_agent_control/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767789689.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Received an email 1 day after the deadline \ud83d\ude02\n\nhttps://preview.redd.it/qgx3ka4b1uag1.png?width=1764&amp;format=png&amp;auto=webp&amp;s=9a89bebccfad8a3f13ca132135f889ebc1ec5fd0\n\n",
                    "author_fullname": "t2_9gmtkb58",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Can I can a time extension on the 2X usage limits?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 140,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "media_metadata": {
                        "qgx3ka4b1uag1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/png",
                            "p": [
                                {
                                    "y": 115,
                                    "x": 108,
                                    "u": "https://preview.redd.it/qgx3ka4b1uag1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=191ad6f7a03f24f26ddf4b26400b43712cdb6b27"
                                },
                                {
                                    "y": 230,
                                    "x": 216,
                                    "u": "https://preview.redd.it/qgx3ka4b1uag1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=48919cde1f9eb0a184129772410b04d9de9e2f69"
                                },
                                {
                                    "y": 341,
                                    "x": 320,
                                    "u": "https://preview.redd.it/qgx3ka4b1uag1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1e0cd11867648df361493ed0b70a619d24f87e8d"
                                },
                                {
                                    "y": 683,
                                    "x": 640,
                                    "u": "https://preview.redd.it/qgx3ka4b1uag1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=db6e40059cee87f9e633e08239ad27ea22c0b42f"
                                },
                                {
                                    "y": 1025,
                                    "x": 960,
                                    "u": "https://preview.redd.it/qgx3ka4b1uag1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f452951066a21e91c1f6c2a640574d6ec5412f21"
                                },
                                {
                                    "y": 1153,
                                    "x": 1080,
                                    "u": "https://preview.redd.it/qgx3ka4b1uag1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d0df7f9c34c00c16271dbc2948790e60199fba2a"
                                }
                            ],
                            "s": {
                                "y": 1884,
                                "x": 1764,
                                "u": "https://preview.redd.it/qgx3ka4b1uag1.png?width=1764&amp;format=png&amp;auto=webp&amp;s=9a89bebccfad8a3f13ca132135f889ebc1ec5fd0"
                            },
                            "id": "qgx3ka4b1uag1"
                        }
                    },
                    "name": "t3_1q1k81s",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.71,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 3,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Limits",
                    "can_mod_post": false,
                    "score": 3,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/h6z3Uw0lHoZKkkWe8fFDDOgcUnNc9-obHh1TXCIKSeU.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767314487.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Received an email 1 day after the deadline \ud83d\ude02&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qgx3ka4b1uag1.png?width=1764&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9a89bebccfad8a3f13ca132135f889ebc1ec5fd0\"&gt;https://preview.redd.it/qgx3ka4b1uag1.png?width=1764&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9a89bebccfad8a3f13ca132135f889ebc1ec5fd0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "21466776-922c-11f0-88d8-d2c5faeac8bd",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c73838",
                    "id": "1q1k81s",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Professional_Bar6431",
                    "discussion_type": null,
                    "num_comments": 5,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q1k81s/can_i_can_a_time_extension_on_the_2x_usage_limits/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q1k81s/can_i_can_a_time_extension_on_the_2x_usage_limits/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767314487.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Caught me a little off guard, lol. What do you all think: is Codex running a multi-agent orchestration under the hood? Or is this just a weird little hallucination.",
                    "author_fullname": "t2_f121bumh",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Us?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 73,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1pqvksc",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.88,
                    "author_flair_background_color": null,
                    "ups": 6,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": true,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Other",
                    "can_mod_post": false,
                    "score": 6,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/U7V6GUVkuIm6PnurXzZiG_HHBujiqH3KMmgvlVff36o.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "image",
                    "content_categories": null,
                    "is_self": false,
                    "subreddit_type": "public",
                    "created": 1766176381.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "i.redd.it",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Caught me a little off guard, lol. What do you all think: is Codex running a multi-agent orchestration under the hood? Or is this just a weird little hallucination.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "url_overridden_by_dest": "https://i.redd.it/jcbfcdau088g1.png",
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://preview.redd.it/jcbfcdau088g1.png?auto=webp&amp;s=1a80c8f03cccd4225f9edd9f5d6b26cbce145060",
                                    "width": 1376,
                                    "height": 722
                                },
                                "resolutions": [
                                    {
                                        "url": "https://preview.redd.it/jcbfcdau088g1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a9225264cb24048a08d2540897971723b4c7c636",
                                        "width": 108,
                                        "height": 56
                                    },
                                    {
                                        "url": "https://preview.redd.it/jcbfcdau088g1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2679afa82045d7c30dfad1de1499b69c0d26d688",
                                        "width": 216,
                                        "height": 113
                                    },
                                    {
                                        "url": "https://preview.redd.it/jcbfcdau088g1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5accee4c60a08aa9f67cbbc9adf6c25f970903e3",
                                        "width": 320,
                                        "height": 167
                                    },
                                    {
                                        "url": "https://preview.redd.it/jcbfcdau088g1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=169b0d6a2a2aa1da2f49b4fa5ce60ddc30177180",
                                        "width": 640,
                                        "height": 335
                                    },
                                    {
                                        "url": "https://preview.redd.it/jcbfcdau088g1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f031af7ef20c89592077ef40b8da461c45a7c944",
                                        "width": 960,
                                        "height": 503
                                    },
                                    {
                                        "url": "https://preview.redd.it/jcbfcdau088g1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ffa3cc776d8f79a3cc9173b2f0203010d4d02750",
                                        "width": 1080,
                                        "height": 566
                                    }
                                ],
                                "variants": {},
                                "id": "e1kFHerKmTrrD_ZPrUBQbebhY23RE0WcXGsJQhjnM9A"
                            }
                        ],
                        "enabled": true
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "00c10890-b24c-11f0-a5a8-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "mod_note": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "num_reports": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#dadada",
                    "id": "1pqvksc",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "UnderstandingOwn4448",
                    "discussion_type": null,
                    "num_comments": 6,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1pqvksc/us/",
                    "stickied": false,
                    "url": "https://i.redd.it/jcbfcdau088g1.png",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766176381.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Anyone hacking MCP-style workflows into CodeX?\n\nI\u2019m using AI agents heavily and right now the only way I found to \u201cintegrate\u201d an MCP server in CodeX is\u2026  \npasting a contract prompt at the start of every chat \ud83e\udd26\u200d\u2642\ufe0f\n\nIt works (HTTP API, tools, rules, etc.), but it\u2019s clunky, fragile, and very non-scalable.\n\nCurious:\n\n* Are people doing something smarter here?\n* Any hidden way to persist tools / skills / MCP servers across chats?\n* Or is native MCP / skills support on the roadmap at all?\n\nFeels like agent-first coding without persistent context is leaving a lot on the table.",
                    "author_fullname": "t2_jl06yq6w",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Anyone hacking MCP-style integrations into Codex?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1qek8lw",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 2,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Workaround",
                    "can_mod_post": false,
                    "score": 2,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1768580070.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone hacking MCP-style workflows into CodeX?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m using AI agents heavily and right now the only way I found to \u201cintegrate\u201d an MCP server in CodeX is\u2026&lt;br/&gt;\npasting a contract prompt at the start of every chat \ud83e\udd26\u200d\u2642\ufe0f&lt;/p&gt;\n\n&lt;p&gt;It works (HTTP API, tools, rules, etc.), but it\u2019s clunky, fragile, and very non-scalable.&lt;/p&gt;\n\n&lt;p&gt;Curious:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Are people doing something smarter here?&lt;/li&gt;\n&lt;li&gt;Any hidden way to persist tools / skills / MCP servers across chats?&lt;/li&gt;\n&lt;li&gt;Or is native MCP / skills support on the roadmap at all?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Feels like agent-first coding without persistent context is leaving a lot on the table.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "3bbefaba-b9bd-11f0-8271-eeee38616f6a",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#00ff2a",
                    "id": "1qek8lw",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Altruistic_Wind9844",
                    "discussion_type": null,
                    "num_comments": 2,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1qek8lw/anyone_hacking_mcpstyle_integrations_into_codex/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1qek8lw/anyone_hacking_mcpstyle_integrations_into_codex/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1768580070.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Wanted to extend a happy new year to r/codex community and the codex team at OpenAI\n\nI'm currently eat up the remaining 50% in usage with 12 different codex clis running on xhigh and before usage resets in 7 hours\n\nKeep prompting!",
                    "author_fullname": "t2_1dvb1fztcc",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Happy New Year",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q0sjy1",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.96,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 22,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Other",
                    "can_mod_post": false,
                    "score": 22,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767231042.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wanted to extend a happy new year to &lt;a href=\"/r/codex\"&gt;r/codex&lt;/a&gt; community and the codex team at OpenAI&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently eat up the remaining 50% in usage with 12 different codex clis running on xhigh and before usage resets in 7 hours&lt;/p&gt;\n\n&lt;p&gt;Keep prompting!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "00c10890-b24c-11f0-a5a8-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#dadada",
                    "id": "1q0sjy1",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Just_Lingonberry_352",
                    "discussion_type": null,
                    "num_comments": 2,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q0sjy1/happy_new_year/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q0sjy1/happy_new_year/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767231042.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Curious if something similar is out there \u2014 and if anyone would find this useful. \n\nStill iterating on a few things, but want to get it packaged with Ink so it feels like more like using Codex CLI. ",
                    "author_fullname": "t2_3jjdr",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "WIP \u2014 Simple Local Codex Communication &amp; Workflows",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 102,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q5rupy",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "ups": 3,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": {
                        "reddit_video": {
                            "bitrate_kbps": 2400,
                            "fallback_url": "https://v.redd.it/e450q9hl2sbg1/CMAF_720.mp4?source=fallback",
                            "has_audio": true,
                            "height": 720,
                            "width": 988,
                            "scrubber_media_url": "https://v.redd.it/e450q9hl2sbg1/CMAF_96.mp4",
                            "dash_url": "https://v.redd.it/e450q9hl2sbg1/DASHPlaylist.mpd?a=1771221921%2CODNkODY1NGViMzViMTU2MGM3NzhkMWM3YjUxMWEzZTg3Y2RjYzQwOWU0NmFlMTZjMTE0YWZjYWJlM2NjOWI0Ng%3D%3D&amp;v=1&amp;f=sd",
                            "duration": 520,
                            "hls_url": "https://v.redd.it/e450q9hl2sbg1/HLSPlaylist.m3u8?a=1771221921%2COTlmYjkyYmMxMWNjNjdjZDE3MmQ3MTI0ZDQwMzU2MDFhYzUzMWI5YTRjZDdmNzAyMTlmNzAyZTk4NjliZGNhZA%3D%3D&amp;v=1&amp;f=sd",
                            "is_gif": false,
                            "transcoding_status": "completed"
                        }
                    },
                    "is_reddit_media_domain": true,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Showcase",
                    "can_mod_post": false,
                    "score": 3,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://external-preview.redd.it/YmYxbGJlaWwyc2JnMUgsUXD1GgMyeH8uUSUbZxriKMAAkioYWtUjnpqRYkC9.png?width=140&amp;height=102&amp;format=jpg&amp;auto=webp&amp;s=9ebef00a8d0b91265819024edbe6db4c71c38a08",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "hosted:video",
                    "content_categories": null,
                    "is_self": false,
                    "subreddit_type": "public",
                    "created": 1767726722.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "v.redd.it",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious if something similar is out there \u2014 and if anyone would find this useful. &lt;/p&gt;\n\n&lt;p&gt;Still iterating on a few things, but want to get it packaged with Ink so it feels like more like using Codex CLI. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "url_overridden_by_dest": "https://v.redd.it/e450q9hl2sbg1",
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/YmYxbGJlaWwyc2JnMUgsUXD1GgMyeH8uUSUbZxriKMAAkioYWtUjnpqRYkC9.png?format=pjpg&amp;auto=webp&amp;s=0ba9356e8e8a1baffb1a86bcb886d170aac06197",
                                    "width": 1364,
                                    "height": 994
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/YmYxbGJlaWwyc2JnMUgsUXD1GgMyeH8uUSUbZxriKMAAkioYWtUjnpqRYkC9.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=aae7957cfe436177453f1e5add2c7fcfaf4d939c",
                                        "width": 108,
                                        "height": 78
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/YmYxbGJlaWwyc2JnMUgsUXD1GgMyeH8uUSUbZxriKMAAkioYWtUjnpqRYkC9.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=02d031621427767046b0bc40bb8e51f03c7f8525",
                                        "width": 216,
                                        "height": 157
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/YmYxbGJlaWwyc2JnMUgsUXD1GgMyeH8uUSUbZxriKMAAkioYWtUjnpqRYkC9.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2dc87051d6fb67ed530a6900c2160524f840893b",
                                        "width": 320,
                                        "height": 233
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/YmYxbGJlaWwyc2JnMUgsUXD1GgMyeH8uUSUbZxriKMAAkioYWtUjnpqRYkC9.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=e3a21fc36a927adbe38bf0d5a4fcf966223af735",
                                        "width": 640,
                                        "height": 466
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/YmYxbGJlaWwyc2JnMUgsUXD1GgMyeH8uUSUbZxriKMAAkioYWtUjnpqRYkC9.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=d5183d5c7d2ae16867fa766aa2853e2b98a8d71e",
                                        "width": 960,
                                        "height": 699
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/YmYxbGJlaWwyc2JnMUgsUXD1GgMyeH8uUSUbZxriKMAAkioYWtUjnpqRYkC9.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=5509f8b3a76c9fd939d08538bdbce2bbed8d5e30",
                                        "width": 1080,
                                        "height": 787
                                    }
                                ],
                                "variants": {},
                                "id": "YmYxbGJlaWwyc2JnMUgsUXD1GgMyeH8uUSUbZxriKMAAkioYWtUjnpqRYkC9"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "e350908e-b24e-11f0-b239-62e50da6d05a",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "mod_note": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "num_reports": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#00ff2a",
                    "id": "1q5rupy",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "mikerooooose",
                    "discussion_type": null,
                    "num_comments": 3,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q5rupy/wip_simple_local_codex_communication_workflows/",
                    "stickied": false,
                    "url": "https://v.redd.it/e450q9hl2sbg1",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767726722.0,
                    "num_crossposts": 0,
                    "media": {
                        "reddit_video": {
                            "bitrate_kbps": 2400,
                            "fallback_url": "https://v.redd.it/e450q9hl2sbg1/CMAF_720.mp4?source=fallback",
                            "has_audio": true,
                            "height": 720,
                            "width": 988,
                            "scrubber_media_url": "https://v.redd.it/e450q9hl2sbg1/CMAF_96.mp4",
                            "dash_url": "https://v.redd.it/e450q9hl2sbg1/DASHPlaylist.mpd?a=1771221921%2CODNkODY1NGViMzViMTU2MGM3NzhkMWM3YjUxMWEzZTg3Y2RjYzQwOWU0NmFlMTZjMTE0YWZjYWJlM2NjOWI0Ng%3D%3D&amp;v=1&amp;f=sd",
                            "duration": 520,
                            "hls_url": "https://v.redd.it/e450q9hl2sbg1/HLSPlaylist.m3u8?a=1771221921%2COTlmYjkyYmMxMWNjNjdjZDE3MmQ3MTI0ZDQwMzU2MDFhYzUzMWI5YTRjZDdmNzAyMTlmNzAyZTk4NjliZGNhZA%3D%3D&amp;v=1&amp;f=sd",
                            "is_gif": false,
                            "transcoding_status": "completed"
                        }
                    },
                    "is_video": true
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "# Problem Statement\n\nEver since the 5.0 release, and continuing into the latest 5.2 release, I've been struggling to use these models for planning. I keep finding myself having to go back to cut-and-paste iterative doc editing with 4o in ChatGPT, because none of the Codex-available models are doing a good job.\n\nThe 5.x models generally overcomplicate and overspecify everything, while the 4o model is pretty much able to one-shot doc-writing. The 5.x models also do not take feedback well, often failing to follow instructions, even while simultaneously being too literal. 5.x cannot generalize well, compared to 4o.\n\n# Example 1\n\nThrough a combination of help from 5.2 and 4o, I wrote up an AGENTS.DOCS.md guidelines doc in an attempt to address this problem. At the end, I asked the models to give me a short \"Purpose Statement\" at the top of the doc. Here's what they gave me:\n\n**5.2-medium**\n\n&gt;Use this file as the writing rules for any documentation you produce in this repo.\n\n**4o**\n\n&gt;This doc defines the standards for agent-written documents: how to structure them, the appropriate level of detail, and what to avoid. It applies to all planning, spec, protocol, and strategy docs unless overridden by task-specific rules.\n\nWhich do you think is better? To me, the version from 5.2 seems useless. The version from 4o is actually informative and correct.\n\n# Example 2\n\nI was asking the models to help me define a new step in my planning workflow, where I explore potential axes of variation for a feature's implementation. My specific series of prompts given to all of the models is [here](https://github.com/tristanbrown/agent-instructions/issues/1#issuecomment-3667326418).\n\nHere is what I got from each model:\n\n* [4o](https://github.com/tristanbrown/agent-instructions/blob/protocol-4o/AGENTS.ATTEMPTS.md#axis-of-variation-discovery-protocol)\n* [5.2-low](https://github.com/tristanbrown/agent-instructions/blob/protocol-5low/AGENTS.ATTEMPTS.md#axis-of-variation-discovery-protocol)\n* [5.2-medium](https://github.com/tristanbrown/agent-instructions/blob/protocol-5med/AGENTS.ATTEMPTS.md#axis-of-variation-discovery-protocol)\n* [5.2-high](https://github.com/tristanbrown/agent-instructions/blob/protocol-5high/AGENTS.ATTEMPTS.md#axis-of-variation-discovery-protocol)\n* [5.2-extrahigh](https://github.com/tristanbrown/agent-instructions/blob/protocol-5extrahigh/AGENTS.ATTEMPTS.md#axis-of-variation-discovery-protocol)\n* [5.1-codex-max-high](https://github.com/tristanbrown/agent-instructions/blob/protocol-5maxhigh/AGENTS.ATTEMPTS.md#axis-of-variation-discovery-protocol)\n* [5.1-codex-mini-medium](https://github.com/tristanbrown/agent-instructions/blob/protocol-5minimed/AGENTS.ATTEMPTS.md#axis-of-variation-discovery-protocol)\n* [5.1-mini-high](https://github.com/tristanbrown/agent-instructions/blob/protocol-5minihigh/AGENTS.ATTEMPTS.md#axis-of-variation-discovery-protocol)\n\nOut of all of these, the 4o version is still my favorite. All of the 5.2 models drastically overcomplicate, overspecify, and overengineer this process. The formatting in the 5.2 model outputs is also worse.\n\nThe 5.1-codex model outputs are less complicated, but poorly formatted and organized.\n\nI didn't bother testing 5.0 or 5.1 on this task, because my previous experience is that they just don't follow instructions.\n\n# Conclusion\n\n**GPT-4o is still better than all of the GPT-5.x models at the following crucial components of doc-writing:**\n\n1. Following instructions.\n2. Formatting.\n3. Generalization and summarization.\n4. Providing the appropriate level of detail (avoiding over-complication and overspecification).\n5. Taking constructive feedback and inferring intent, without getting trapped in overly-literal, overly-specific, over-prioritized interpretations.\n\nAs I mentioned in Example 1, I'm trying to write an AGENTS.DOCS.md doc to correct these anti-patterns, and make 5.2 write more like 4o. But the results have not been great so far. The model's internal biases are really fighting against this.\n\nI really wish OpenAI would revisit GPT-4o and focus on understanding what made it such a successful model. It truly does have some secret sauce that's missing from every single 5.x model that has been released, including 5.2. The popularity of 4o is not rooted in its sycophancy. It truly is better at generalizing, incorporating context, and speaking in human-readable ways.\n\n# Note\n\nI typed the entirety of this post out by hand.",
                    "author_fullname": "t2_24579shlig",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "4o is still better than all of the 5.x models at writing docs",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1ppaikr",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.22,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 0,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Complaint",
                    "can_mod_post": false,
                    "score": 0,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766011424.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Problem Statement&lt;/h1&gt;\n\n&lt;p&gt;Ever since the 5.0 release, and continuing into the latest 5.2 release, I&amp;#39;ve been struggling to use these models for planning. I keep finding myself having to go back to cut-and-paste iterative doc editing with 4o in ChatGPT, because none of the Codex-available models are doing a good job.&lt;/p&gt;\n\n&lt;p&gt;The 5.x models generally overcomplicate and overspecify everything, while the 4o model is pretty much able to one-shot doc-writing. The 5.x models also do not take feedback well, often failing to follow instructions, even while simultaneously being too literal. 5.x cannot generalize well, compared to 4o.&lt;/p&gt;\n\n&lt;h1&gt;Example 1&lt;/h1&gt;\n\n&lt;p&gt;Through a combination of help from 5.2 and 4o, I wrote up an AGENTS.DOCS.md guidelines doc in an attempt to address this problem. At the end, I asked the models to give me a short &amp;quot;Purpose Statement&amp;quot; at the top of the doc. Here&amp;#39;s what they gave me:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;5.2-medium&lt;/strong&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Use this file as the writing rules for any documentation you produce in this repo.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;strong&gt;4o&lt;/strong&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;This doc defines the standards for agent-written documents: how to structure them, the appropriate level of detail, and what to avoid. It applies to all planning, spec, protocol, and strategy docs unless overridden by task-specific rules.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Which do you think is better? To me, the version from 5.2 seems useless. The version from 4o is actually informative and correct.&lt;/p&gt;\n\n&lt;h1&gt;Example 2&lt;/h1&gt;\n\n&lt;p&gt;I was asking the models to help me define a new step in my planning workflow, where I explore potential axes of variation for a feature&amp;#39;s implementation. My specific series of prompts given to all of the models is &lt;a href=\"https://github.com/tristanbrown/agent-instructions/issues/1#issuecomment-3667326418\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Here is what I got from each model:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/tristanbrown/agent-instructions/blob/protocol-4o/AGENTS.ATTEMPTS.md#axis-of-variation-discovery-protocol\"&gt;4o&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/tristanbrown/agent-instructions/blob/protocol-5low/AGENTS.ATTEMPTS.md#axis-of-variation-discovery-protocol\"&gt;5.2-low&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/tristanbrown/agent-instructions/blob/protocol-5med/AGENTS.ATTEMPTS.md#axis-of-variation-discovery-protocol\"&gt;5.2-medium&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/tristanbrown/agent-instructions/blob/protocol-5high/AGENTS.ATTEMPTS.md#axis-of-variation-discovery-protocol\"&gt;5.2-high&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/tristanbrown/agent-instructions/blob/protocol-5extrahigh/AGENTS.ATTEMPTS.md#axis-of-variation-discovery-protocol\"&gt;5.2-extrahigh&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/tristanbrown/agent-instructions/blob/protocol-5maxhigh/AGENTS.ATTEMPTS.md#axis-of-variation-discovery-protocol\"&gt;5.1-codex-max-high&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/tristanbrown/agent-instructions/blob/protocol-5minimed/AGENTS.ATTEMPTS.md#axis-of-variation-discovery-protocol\"&gt;5.1-codex-mini-medium&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/tristanbrown/agent-instructions/blob/protocol-5minihigh/AGENTS.ATTEMPTS.md#axis-of-variation-discovery-protocol\"&gt;5.1-mini-high&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Out of all of these, the 4o version is still my favorite. All of the 5.2 models drastically overcomplicate, overspecify, and overengineer this process. The formatting in the 5.2 model outputs is also worse.&lt;/p&gt;\n\n&lt;p&gt;The 5.1-codex model outputs are less complicated, but poorly formatted and organized.&lt;/p&gt;\n\n&lt;p&gt;I didn&amp;#39;t bother testing 5.0 or 5.1 on this task, because my previous experience is that they just don&amp;#39;t follow instructions.&lt;/p&gt;\n\n&lt;h1&gt;Conclusion&lt;/h1&gt;\n\n&lt;p&gt;&lt;strong&gt;GPT-4o is still better than all of the GPT-5.x models at the following crucial components of doc-writing:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Following instructions.&lt;/li&gt;\n&lt;li&gt;Formatting.&lt;/li&gt;\n&lt;li&gt;Generalization and summarization.&lt;/li&gt;\n&lt;li&gt;Providing the appropriate level of detail (avoiding over-complication and overspecification).&lt;/li&gt;\n&lt;li&gt;Taking constructive feedback and inferring intent, without getting trapped in overly-literal, overly-specific, over-prioritized interpretations.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;As I mentioned in Example 1, I&amp;#39;m trying to write an AGENTS.DOCS.md doc to correct these anti-patterns, and make 5.2 write more like 4o. But the results have not been great so far. The model&amp;#39;s internal biases are really fighting against this.&lt;/p&gt;\n\n&lt;p&gt;I really wish OpenAI would revisit GPT-4o and focus on understanding what made it such a successful model. It truly does have some secret sauce that&amp;#39;s missing from every single 5.x model that has been released, including 5.2. The popularity of 4o is not rooted in its sycophancy. It truly is better at generalizing, incorporating context, and speaking in human-readable ways.&lt;/p&gt;\n\n&lt;h1&gt;Note&lt;/h1&gt;\n\n&lt;p&gt;I typed the entirety of this post out by hand.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/rQvmWrjpO-OPvBOqzQQOQsup8Bc7jIl0FpNefhTgjt8.png?auto=webp&amp;s=8901450cda7f3c07e2e0a1ec4fc3c3493ce478a0",
                                    "width": 1200,
                                    "height": 600
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/rQvmWrjpO-OPvBOqzQQOQsup8Bc7jIl0FpNefhTgjt8.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ffa1651cd95364d490c6fb4da4fba66434ee6e3f",
                                        "width": 108,
                                        "height": 54
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/rQvmWrjpO-OPvBOqzQQOQsup8Bc7jIl0FpNefhTgjt8.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6a852d33c0461e4b4deb7c7b669ba48f5081a0dd",
                                        "width": 216,
                                        "height": 108
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/rQvmWrjpO-OPvBOqzQQOQsup8Bc7jIl0FpNefhTgjt8.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2f5013a13e932b6c39268292f22f99c2e1b9a5fd",
                                        "width": 320,
                                        "height": 160
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/rQvmWrjpO-OPvBOqzQQOQsup8Bc7jIl0FpNefhTgjt8.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=48d9826d2ad0f480fdf76b24eb3b7692b82aed63",
                                        "width": 640,
                                        "height": 320
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/rQvmWrjpO-OPvBOqzQQOQsup8Bc7jIl0FpNefhTgjt8.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=977bd17172375fb48f782c8cdfa5c9f317c582dc",
                                        "width": 960,
                                        "height": 480
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/rQvmWrjpO-OPvBOqzQQOQsup8Bc7jIl0FpNefhTgjt8.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ad5eab484f2b6106953723a91a3b233b756f69b7",
                                        "width": 1080,
                                        "height": 540
                                    }
                                ],
                                "variants": {},
                                "id": "rQvmWrjpO-OPvBOqzQQOQsup8Bc7jIl0FpNefhTgjt8"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "3090d6a0-ab11-11f0-a7f1-526fbbfcd846",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#f40b0b",
                    "id": "1ppaikr",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "tristanrbrown",
                    "discussion_type": null,
                    "num_comments": 6,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1ppaikr/4o_is_still_better_than_all_of_the_5x_models_at/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1ppaikr/4o_is_still_better_than_all_of_the_5x_models_at/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766011424.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "I was pulling my hair out for the last hour because of some of the simple things that Codex wasn't getting right. I was just doing an experimental project from scratch using skills, and I was wondering how it's not being able to do good compared to previous times. Not good as in completely, absolutely terrible. Then I realised I have a little bit of usage left, which is why I think I accidentally changed to GPT 5.1 Mini.\n\nI think the OpenAI team didn't get enough credit for how good GPT 5.2 High Reasoning Models are. So, thank you. ",
                    "author_fullname": "t2_147w1sjork",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Accidentally used gpt-5.1-mini in codex cli",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1pt0ess",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.92,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 11,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Commentary",
                    "can_mod_post": false,
                    "score": 11,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766412397.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was pulling my hair out for the last hour because of some of the simple things that Codex wasn&amp;#39;t getting right. I was just doing an experimental project from scratch using skills, and I was wondering how it&amp;#39;s not being able to do good compared to previous times. Not good as in completely, absolutely terrible. Then I realised I have a little bit of usage left, which is why I think I accidentally changed to GPT 5.1 Mini.&lt;/p&gt;\n\n&lt;p&gt;I think the OpenAI team didn&amp;#39;t get enough credit for how good GPT 5.2 High Reasoning Models are. So, thank you. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "5dc0bbc2-8d43-11f0-a897-a2f48743ec57",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#826e91",
                    "id": "1pt0ess",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Swimming_Driver4974",
                    "discussion_type": null,
                    "num_comments": 4,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1pt0ess/accidentally_used_gpt51mini_in_codex_cli/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1pt0ess/accidentally_used_gpt51mini_in_codex_cli/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766412397.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Which one works better for you?",
                    "author_fullname": "t2_2uq8mzgs",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "5.2 xhigh vs Codex 5.2 xhigh",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1pqwgar",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.83,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 4,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Comparison",
                    "can_mod_post": false,
                    "score": 4,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766178604.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Which one works better for you?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "b81001d4-8c88-11f0-8523-42042a14a711",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#817e7e",
                    "id": "1pqwgar",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "TCaller",
                    "discussion_type": null,
                    "num_comments": 5,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1pqwgar/52_xhigh_vs_codex_52_xhigh/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1pqwgar/52_xhigh_vs_codex_52_xhigh/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766178604.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "I don't want to give the codex agent free reign  run whatever on my machine, but I'd also like to stop being asked about \\`rg --files\\` each new request \n\nAnyway to accomplish this?",
                    "author_fullname": "t2_ecnge",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Any way to whitelist read only tools in codex?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q93cta",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 3,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Question",
                    "can_mod_post": false,
                    "score": 3,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1768049695.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t want to give the codex agent free reign  run whatever on my machine, but I&amp;#39;d also like to stop being asked about `rg --files` each new request &lt;/p&gt;\n\n&lt;p&gt;Anyway to accomplish this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "302c6282-b24c-11f0-a6c9-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c13e80",
                    "id": "1q93cta",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "DumbQuestionUser",
                    "discussion_type": null,
                    "num_comments": 2,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q93cta/any_way_to_whitelist_read_only_tools_in_codex/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q93cta/any_way_to_whitelist_read_only_tools_in_codex/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1768049695.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "I make an app that lets a user talk to databases (SQL, postgresql, mysql, mssql, snowflake, pdfs, csvs, excel, ppt, etc.).\n\nI then implemented a mode where it can autonomously execute complex tasks (e.g. create month-end financials from 20 different files, GDPval stuff, really cool - I'll link to an example!).\n\nI am now working on \"project\" mode. This will allow a user to edit/enter a JSON structure that tells the agent how to do dozens or hundreds of steps. For example, a real project might involve data ETL, data clean up, data analysis, data modeling, excel modeling, report creation, research, presentation creation etc. This isn't a prompt - this is perhaps 100 discrete tasks, each with success criterion, tests etc.\n\nHaving a sequential analysis, where the agent can focus on a task, have state+memory managed outside of the agent (i.e., by the harness), and allowing the option of self-review or user-review for each task - I \\*think\\*, can lead to end-to-end automation of a digital analytic workflow.\n\nDoes codex/OpenAI have an SDK that can replicate what claude agent sdk does? My guess is that it won't be a drop-in replacement for Claude, but close? Is orchestration built into it? Appreciate any insights. I'll link an example below so you can see how my current workflow works. ",
                    "author_fullname": "t2_ekjhvjeps",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Building an end-to-end enterprise workflow agent. Claude SDK Agent alternative?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1pq61dg",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.67,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 2,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Showcase",
                    "can_mod_post": false,
                    "score": 2,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766101492.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I make an app that lets a user talk to databases (SQL, postgresql, mysql, mssql, snowflake, pdfs, csvs, excel, ppt, etc.).&lt;/p&gt;\n\n&lt;p&gt;I then implemented a mode where it can autonomously execute complex tasks (e.g. create month-end financials from 20 different files, GDPval stuff, really cool - I&amp;#39;ll link to an example!).&lt;/p&gt;\n\n&lt;p&gt;I am now working on &amp;quot;project&amp;quot; mode. This will allow a user to edit/enter a JSON structure that tells the agent how to do dozens or hundreds of steps. For example, a real project might involve data ETL, data clean up, data analysis, data modeling, excel modeling, report creation, research, presentation creation etc. This isn&amp;#39;t a prompt - this is perhaps 100 discrete tasks, each with success criterion, tests etc.&lt;/p&gt;\n\n&lt;p&gt;Having a sequential analysis, where the agent can focus on a task, have state+memory managed outside of the agent (i.e., by the harness), and allowing the option of self-review or user-review for each task - I *think*, can lead to end-to-end automation of a digital analytic workflow.&lt;/p&gt;\n\n&lt;p&gt;Does codex/OpenAI have an SDK that can replicate what claude agent sdk does? My guess is that it won&amp;#39;t be a drop-in replacement for Claude, but close? Is orchestration built into it? Appreciate any insights. I&amp;#39;ll link an example below so you can see how my current workflow works. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "e350908e-b24e-11f0-b239-62e50da6d05a",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#00ff2a",
                    "id": "1pq61dg",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "VerbaGPT",
                    "discussion_type": null,
                    "num_comments": 5,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1pq61dg/building_an_endtoend_enterprise_workflow_agent/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1pq61dg/building_an_endtoend_enterprise_workflow_agent/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766101492.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "On https://github.com/openai/codex/releases/latest I see a bunch of tools I don't recognize, including\n\n- codex-command-runner-x86_64-pc-windows-msvc.exe\n- codex-responses-api-proxy-x86_64-pc-windows-msvc.exe\n- codex-windows-sandbox-setup-x86_64-pc-windows-msvc.exe\n\nbut starting with the first one, what the heck is Codex CLI's Command Runner?",
                    "author_fullname": "t2_h9qqw",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "What is Codex CLI's \"Command Runner\" ?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q9mv2s",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.84,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 4,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Question",
                    "can_mod_post": false,
                    "score": 4,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1768097240.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On &lt;a href=\"https://github.com/openai/codex/releases/latest\"&gt;https://github.com/openai/codex/releases/latest&lt;/a&gt; I see a bunch of tools I don&amp;#39;t recognize, including&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;codex-command-runner-x86_64-pc-windows-msvc.exe&lt;/li&gt;\n&lt;li&gt;codex-responses-api-proxy-x86_64-pc-windows-msvc.exe&lt;/li&gt;\n&lt;li&gt;codex-windows-sandbox-setup-x86_64-pc-windows-msvc.exe&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;but starting with the first one, what the heck is Codex CLI&amp;#39;s Command Runner?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/q1A5gd2T-G22A1458b7xA7CiED2TwavbZ3mK5pvbvvg.png?auto=webp&amp;s=c92323e47a5f5445336333aa57d9a759d60f91cd",
                                    "width": 1200,
                                    "height": 600
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/q1A5gd2T-G22A1458b7xA7CiED2TwavbZ3mK5pvbvvg.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=64ea3eda6d0d9d86a47af69b658028ce9c318330",
                                        "width": 108,
                                        "height": 54
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/q1A5gd2T-G22A1458b7xA7CiED2TwavbZ3mK5pvbvvg.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=40f4a0f2c4b940c3484c46d198403f93606423cf",
                                        "width": 216,
                                        "height": 108
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/q1A5gd2T-G22A1458b7xA7CiED2TwavbZ3mK5pvbvvg.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d9ac126666a6263aaf9282ca9880571676e6b2f4",
                                        "width": 320,
                                        "height": 160
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/q1A5gd2T-G22A1458b7xA7CiED2TwavbZ3mK5pvbvvg.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d6d0c86fe4d92cf6de0cef326de0b3d5008d84af",
                                        "width": 640,
                                        "height": 320
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/q1A5gd2T-G22A1458b7xA7CiED2TwavbZ3mK5pvbvvg.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d5497492f278dcd4e92f0130cc4bf15889439de2",
                                        "width": 960,
                                        "height": 480
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/q1A5gd2T-G22A1458b7xA7CiED2TwavbZ3mK5pvbvvg.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ec9da632f2d2c6b48c8df2888992f7a7657676f8",
                                        "width": 1080,
                                        "height": 540
                                    }
                                ],
                                "variants": {},
                                "id": "q1A5gd2T-G22A1458b7xA7CiED2TwavbZ3mK5pvbvvg"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "302c6282-b24c-11f0-a6c9-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c13e80",
                    "id": "1q9mv2s",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Takeoded",
                    "discussion_type": null,
                    "num_comments": 1,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q9mv2s/what_is_codex_clis_command_runner/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q9mv2s/what_is_codex_clis_command_runner/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1768097240.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "https://preview.redd.it/fhmzi9gxa08g1.png?width=2200&amp;format=png&amp;auto=webp&amp;s=e2a57d1116754f88b9a556eae3ad2480839167d9\n\n[https://openai.com/index/introducing-gpt-5-2-codex/](https://openai.com/index/introducing-gpt-5-2-codex/)\n\nfound here:\n\n    upgrade: Some(ModelUpgrade {\n                    id: \"caribou\".to_string(),\n                    reasoning_effort_mapping: None,\n                    migration_config_key: \"gpt-5.2-codex\".to_string(),\n                    model_link: Some(\"https://openai.com/index/introducing-gpt-5-2-codex\".to_string()),\n                }),",
                    "author_fullname": "t2_1h6ehfpda5",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "GPT 5.2 Codex posted",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 106,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "media_metadata": {
                        "fhmzi9gxa08g1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/png",
                            "p": [
                                {
                                    "y": 82,
                                    "x": 108,
                                    "u": "https://preview.redd.it/fhmzi9gxa08g1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=02fcfd11af53f079ef15b496c2cb8a8387f0741b"
                                },
                                {
                                    "y": 164,
                                    "x": 216,
                                    "u": "https://preview.redd.it/fhmzi9gxa08g1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f9d0fc3f95ba76ce2d1f5e076d34cf7eb749fb4e"
                                },
                                {
                                    "y": 243,
                                    "x": 320,
                                    "u": "https://preview.redd.it/fhmzi9gxa08g1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=507820819943a1fb85c00ecc7508a3c5db005068"
                                },
                                {
                                    "y": 486,
                                    "x": 640,
                                    "u": "https://preview.redd.it/fhmzi9gxa08g1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=324b1b87b7d1b86a3a5b057347c817114bdd92d4"
                                },
                                {
                                    "y": 729,
                                    "x": 960,
                                    "u": "https://preview.redd.it/fhmzi9gxa08g1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d3fd56dbbe98a86c89d17c7eb33afad639d058df"
                                },
                                {
                                    "y": 820,
                                    "x": 1080,
                                    "u": "https://preview.redd.it/fhmzi9gxa08g1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=db812a7212dba264c8a4dcd546357413981062e8"
                                }
                            ],
                            "s": {
                                "y": 1672,
                                "x": 2200,
                                "u": "https://preview.redd.it/fhmzi9gxa08g1.png?width=2200&amp;format=png&amp;auto=webp&amp;s=e2a57d1116754f88b9a556eae3ad2480839167d9"
                            },
                            "id": "fhmzi9gxa08g1"
                        }
                    },
                    "name": "t3_1ppyce2",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.93,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 11,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "News",
                    "can_mod_post": false,
                    "score": 11,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/ez-JV6h3aIT17nqR_W852jtcuAWwYyWMzPVGRS8vN0U.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766082813.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/fhmzi9gxa08g1.png?width=2200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e2a57d1116754f88b9a556eae3ad2480839167d9\"&gt;https://preview.redd.it/fhmzi9gxa08g1.png?width=2200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e2a57d1116754f88b9a556eae3ad2480839167d9&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://openai.com/index/introducing-gpt-5-2-codex/\"&gt;https://openai.com/index/introducing-gpt-5-2-codex/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;found here:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;upgrade: Some(ModelUpgrade {\n                id: &amp;quot;caribou&amp;quot;.to_string(),\n                reasoning_effort_mapping: None,\n                migration_config_key: &amp;quot;gpt-5.2-codex&amp;quot;.to_string(),\n                model_link: Some(&amp;quot;https://openai.com/index/introducing-gpt-5-2-codex&amp;quot;.to_string()),\n            }),\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "d91881fa-8c86-11f0-9995-42042a14a711",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "transparent",
                    "id": "1ppyce2",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Funny-Blueberry-2630",
                    "discussion_type": null,
                    "num_comments": 3,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1ppyce2/gpt_52_codex_posted/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1ppyce2/gpt_52_codex_posted/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766082813.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "What is the best way to have automated code review for Salesforce ? I need it to be grounded with my rules so as if I am doing the review myself, to specify what to expect and what to look for?\n\nOpenAI APIs ? Codex and GitHub?\n\nAlso would it show as AI did the review or it will be using my GitHub username? In both cases?\n\nRules can be different from task to another. Or from repo to another. \n\nThank you ",
                    "author_fullname": "t2_12c7ujpkq4",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "I was wondering what is the best way to have automated code review for Salesforce?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1pzimgc",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 2,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Question",
                    "can_mod_post": false,
                    "score": 2,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767102652.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the best way to have automated code review for Salesforce ? I need it to be grounded with my rules so as if I am doing the review myself, to specify what to expect and what to look for?&lt;/p&gt;\n\n&lt;p&gt;OpenAI APIs ? Codex and GitHub?&lt;/p&gt;\n\n&lt;p&gt;Also would it show as AI did the review or it will be using my GitHub username? In both cases?&lt;/p&gt;\n\n&lt;p&gt;Rules can be different from task to another. Or from repo to another. &lt;/p&gt;\n\n&lt;p&gt;Thank you &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "302c6282-b24c-11f0-a6c9-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c13e80",
                    "id": "1pzimgc",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Significant_Duty4196",
                    "discussion_type": null,
                    "num_comments": 2,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1pzimgc/i_was_wondering_what_is_the_best_way_to_have/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1pzimgc/i_was_wondering_what_is_the_best_way_to_have/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767102652.0,
                    "num_crossposts": 1,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "So I'm just trying to setup Codex to see it in action in a project.\n\nI'm coming from Claude Code and opencode, both had no issues whatsoever.\n\nWhen I first had the issue, I tought \"no worries, I'll ask and the AI will help me fix it\".\n\nThen this is what I got for help. Very good start! /s",
                    "author_fullname": "t2_2401zlxouu",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Codex setup Linux, why so miserable",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 103,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q4m68i",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "ups": 3,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": true,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Complaint",
                    "can_mod_post": false,
                    "score": 3,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/1cNA4IQFLsfiDuvamWIVou8qWGTe9zMNUYxy0LoaBmY.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "image",
                    "content_categories": null,
                    "is_self": false,
                    "subreddit_type": "public",
                    "created": 1767621017.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "i.redd.it",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m just trying to setup Codex to see it in action in a project.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m coming from Claude Code and opencode, both had no issues whatsoever.&lt;/p&gt;\n\n&lt;p&gt;When I first had the issue, I tought &amp;quot;no worries, I&amp;#39;ll ask and the AI will help me fix it&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Then this is what I got for help. Very good start! /s&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "url_overridden_by_dest": "https://i.redd.it/75lbxfs9cjbg1.png",
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://preview.redd.it/75lbxfs9cjbg1.png?auto=webp&amp;s=f69d137a399843f0f202fc2ada187a095e2799f4",
                                    "width": 1073,
                                    "height": 796
                                },
                                "resolutions": [
                                    {
                                        "url": "https://preview.redd.it/75lbxfs9cjbg1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9f358ba05291034d93dc2f8849c6ff000337cc04",
                                        "width": 108,
                                        "height": 80
                                    },
                                    {
                                        "url": "https://preview.redd.it/75lbxfs9cjbg1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=091791cd524a18d8fd4f13334b997c1e49b16073",
                                        "width": 216,
                                        "height": 160
                                    },
                                    {
                                        "url": "https://preview.redd.it/75lbxfs9cjbg1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=105ef3db8418c38a1b7ec06eb9a5cfcea191f3fe",
                                        "width": 320,
                                        "height": 237
                                    },
                                    {
                                        "url": "https://preview.redd.it/75lbxfs9cjbg1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a5a4ed95fa567922956d4d143eef1fa892bfe221",
                                        "width": 640,
                                        "height": 474
                                    },
                                    {
                                        "url": "https://preview.redd.it/75lbxfs9cjbg1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=27aa8736a16d63b5aae9194d129d48b157961180",
                                        "width": 960,
                                        "height": 712
                                    }
                                ],
                                "variants": {},
                                "id": "PqGlrIUSJbBqqr8VlaF1id2WORSrB_FcrslWOlqQUfg"
                            }
                        ],
                        "enabled": true
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "3090d6a0-ab11-11f0-a7f1-526fbbfcd846",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "mod_note": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "num_reports": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#f40b0b",
                    "id": "1q4m68i",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "t4a8945",
                    "discussion_type": null,
                    "num_comments": 1,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q4m68i/codex_setup_linux_why_so_miserable/",
                    "stickied": false,
                    "url": "https://i.redd.it/75lbxfs9cjbg1.png",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767621017.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "We recently tested agentic CLI tools on 20 web development tasks to see how well they perform. Our comparison includes Kiro, Claude Code, Cline, Aider, Codex CLI, and Gemini CLI, evaluated on real development workflows. If you are curious where they genuinely help or fall short, you can find the full benchmark and methodology here: https://research.aimultiple.com/agentic-cli/",
                    "author_fullname": "t2_22lcyfdkrl",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Agentic CLI Tools Comparison",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 120,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1qaya19",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.4,
                    "author_flair_background_color": null,
                    "ups": 0,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": true,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Comparison",
                    "can_mod_post": false,
                    "score": 0,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/SeWM0BjRZHowhQHOPlONxbS3ThbrZ1wn-CHDVEClupo.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "image",
                    "content_categories": null,
                    "is_self": false,
                    "subreddit_type": "public",
                    "created": 1768232660.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "i.redd.it",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We recently tested agentic CLI tools on 20 web development tasks to see how well they perform. Our comparison includes Kiro, Claude Code, Cline, Aider, Codex CLI, and Gemini CLI, evaluated on real development workflows. If you are curious where they genuinely help or fall short, you can find the full benchmark and methodology here: &lt;a href=\"https://research.aimultiple.com/agentic-cli/\"&gt;https://research.aimultiple.com/agentic-cli/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "url_overridden_by_dest": "https://i.redd.it/16tlst6jvxcg1.jpeg",
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://preview.redd.it/16tlst6jvxcg1.jpeg?auto=webp&amp;s=a6cfee50f3e48383783395265156ac0a978d1805",
                                    "width": 1404,
                                    "height": 1204
                                },
                                "resolutions": [
                                    {
                                        "url": "https://preview.redd.it/16tlst6jvxcg1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=93ad7b71cd052cf501ce8046b2003389f934bdf9",
                                        "width": 108,
                                        "height": 92
                                    },
                                    {
                                        "url": "https://preview.redd.it/16tlst6jvxcg1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=aa7f0d6c73af9fba493ce3a8737eeb53b7a1836a",
                                        "width": 216,
                                        "height": 185
                                    },
                                    {
                                        "url": "https://preview.redd.it/16tlst6jvxcg1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5a7ac51ada30fa101fded89630b9d3476bd9a6f5",
                                        "width": 320,
                                        "height": 274
                                    },
                                    {
                                        "url": "https://preview.redd.it/16tlst6jvxcg1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4bef78f899cf54054e8ebd5759a04eeb38fa4f5",
                                        "width": 640,
                                        "height": 548
                                    },
                                    {
                                        "url": "https://preview.redd.it/16tlst6jvxcg1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=dec64e0121fd6648705dbcb83dbabf716537e753",
                                        "width": 960,
                                        "height": 823
                                    },
                                    {
                                        "url": "https://preview.redd.it/16tlst6jvxcg1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3537547ab15213bca40de6cb254841ea3b9150b2",
                                        "width": 1080,
                                        "height": 926
                                    }
                                ],
                                "variants": {},
                                "id": "6hWoDN8WF7XPuTCnvqD7wCylqRkvYNonYS6XXWlKQTU"
                            }
                        ],
                        "enabled": true
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "b81001d4-8c88-11f0-8523-42042a14a711",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "mod_note": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "num_reports": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#817e7e",
                    "id": "1qaya19",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "AIMultiple",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1qaya19/agentic_cli_tools_comparison/",
                    "stickied": false,
                    "url": "https://i.redd.it/16tlst6jvxcg1.jpeg",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1768232660.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Am I the only one that CODEX freezes and becomes grey in vscode after a while?  \nSo I lose all the credits of a long run sometimes (after &gt; 2hours).\n\nFound this issue on github, so I'm clearly not the only one : [https://github.com/openai/codex/issues/8197](https://github.com/openai/codex/issues/8197) \n\nAny plan to correct this?  \nWhat about our credits? Are they monitored and will they be restored? ",
                    "author_fullname": "t2_23tszurcpd",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Grey codex in vscode",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q24ofi",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.99,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 1,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Bug",
                    "can_mod_post": false,
                    "score": 1,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "self",
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767374758.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Am I the only one that CODEX freezes and becomes grey in vscode after a while?&lt;br/&gt;\nSo I lose all the credits of a long run sometimes (after &amp;gt; 2hours).&lt;/p&gt;\n\n&lt;p&gt;Found this issue on github, so I&amp;#39;m clearly not the only one : &lt;a href=\"https://github.com/openai/codex/issues/8197\"&gt;https://github.com/openai/codex/issues/8197&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Any plan to correct this?&lt;br/&gt;\nWhat about our credits? Are they monitored and will they be restored? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/JaMd3PtBmmRHu0d3xQhLhbOk2y97JnAQBOdXsvPzvys.png?auto=webp&amp;s=ac860f3710e55c0cee76e5e52604e8f348f90fbc",
                                    "width": 1200,
                                    "height": 600
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/JaMd3PtBmmRHu0d3xQhLhbOk2y97JnAQBOdXsvPzvys.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=847dbbe1e2c3bb8912c51df35a669a513e52abcc",
                                        "width": 108,
                                        "height": 54
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/JaMd3PtBmmRHu0d3xQhLhbOk2y97JnAQBOdXsvPzvys.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f690a1fa669cd86ebc30d23783eb7a2662403c2",
                                        "width": 216,
                                        "height": 108
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/JaMd3PtBmmRHu0d3xQhLhbOk2y97JnAQBOdXsvPzvys.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b62e3ab7d3fcdc849981ae12653c00d9c32cc9d4",
                                        "width": 320,
                                        "height": 160
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/JaMd3PtBmmRHu0d3xQhLhbOk2y97JnAQBOdXsvPzvys.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=190719eee7c61c519b4382c7bd8fd39e56bbdf38",
                                        "width": 640,
                                        "height": 320
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/JaMd3PtBmmRHu0d3xQhLhbOk2y97JnAQBOdXsvPzvys.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=09fc9199f08aafc5ef7e6c09d0def94ed202c17b",
                                        "width": 960,
                                        "height": 480
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/JaMd3PtBmmRHu0d3xQhLhbOk2y97JnAQBOdXsvPzvys.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a3cf5895876c40bb9de0c9bec50cf464840b6ceb",
                                        "width": 1080,
                                        "height": 540
                                    }
                                ],
                                "variants": {},
                                "id": "JaMd3PtBmmRHu0d3xQhLhbOk2y97JnAQBOdXsvPzvys"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "2a65ac36-b24d-11f0-b99f-ea9d881ff36e",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#b44b4b",
                    "id": "1q24ofi",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Strict-Photograph807",
                    "discussion_type": null,
                    "num_comments": 1,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q24ofi/grey_codex_in_vscode/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q24ofi/grey_codex_in_vscode/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767374758.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "I created my own agentic browser (Nexus) controlled by an embedded terminal that uses Codex CLI or Claude Code to control the browser. Works very well like Comet browser or ChatGPTAgent. #AI",
                    "author_fullname": "t2_93wr7yhf",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Nexus agentic browser",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 87,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q7qoj9",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 0.6,
                    "author_flair_background_color": null,
                    "ups": 1,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": true,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Showcase",
                    "can_mod_post": false,
                    "score": 1,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/LikLshVGPpdK4Z1iy2qZuiVd-oxVhTFLaiV1t04FYxA.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "image",
                    "content_categories": null,
                    "is_self": false,
                    "subreddit_type": "public",
                    "created": 1767912374.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "i.redd.it",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I created my own agentic browser (Nexus) controlled by an embedded terminal that uses Codex CLI or Claude Code to control the browser. Works very well like Comet browser or ChatGPTAgent. #AI&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "url_overridden_by_dest": "https://i.redd.it/ia7cyn55f7cg1.jpeg",
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://preview.redd.it/ia7cyn55f7cg1.jpeg?auto=webp&amp;s=061f56025345f9c9d4ef8cf8dfeeaae7d954f8fd",
                                    "width": 2048,
                                    "height": 1280
                                },
                                "resolutions": [
                                    {
                                        "url": "https://preview.redd.it/ia7cyn55f7cg1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ad1bb329bd05dbf937656f5ae16ca96a5fcc0499",
                                        "width": 108,
                                        "height": 67
                                    },
                                    {
                                        "url": "https://preview.redd.it/ia7cyn55f7cg1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=84faa40dbc4f39ad3f0901899381ad522e939e48",
                                        "width": 216,
                                        "height": 135
                                    },
                                    {
                                        "url": "https://preview.redd.it/ia7cyn55f7cg1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5461bbb35a6429cc564e372dd3dcd8ab9291228b",
                                        "width": 320,
                                        "height": 200
                                    },
                                    {
                                        "url": "https://preview.redd.it/ia7cyn55f7cg1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9f92526d0780922fd1645855ac45989c157bba28",
                                        "width": 640,
                                        "height": 400
                                    },
                                    {
                                        "url": "https://preview.redd.it/ia7cyn55f7cg1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e96e098483295f2209fb3b3bec7af36b7ee8c7c8",
                                        "width": 960,
                                        "height": 600
                                    },
                                    {
                                        "url": "https://preview.redd.it/ia7cyn55f7cg1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=84baffc9989143a28b26066e72192f21349b9879",
                                        "width": 1080,
                                        "height": 675
                                    }
                                ],
                                "variants": {},
                                "id": "RLSLw6YoF0E_EzKPfa4KGDZwfZ3R4u_Re2qHLJmJCrM"
                            }
                        ],
                        "enabled": true
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "e350908e-b24e-11f0-b239-62e50da6d05a",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "mod_note": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "num_reports": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#00ff2a",
                    "id": "1q7qoj9",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "Guilty_Car9874",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q7qoj9/nexus_agentic_browser/",
                    "stickied": false,
                    "url": "https://i.redd.it/ia7cyn55f7cg1.jpeg",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767912374.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "TLDR: I built a fast HTML / Tailwind editor for Google Stitch style workflows in 3 days using OpenAI Codex (about 16 hours of my time). Try it here: [https://stitchedit.io/](https://stitchedit.io/)  \n  \nI\u2019ve been replacing my old Figma to code workflow with a new dev workflow: Google Stitch AI for UI design, export the HTML / Tailwind, implement in codex, test / ship. Wow, is this new workflow fast!!!   \n  \nTwo things I want to highlight because they surprised me:\n\n1. **Google Stitch** [https://stitch.withgoogle.com/AI](https://stitch.withgoogle.com/AI) is genuinely good. It\u2019s the first UI generator that has felt usable for real iteration. Sure Claude and Gemini work but I love that stitch is UI centric. \n2. **OpenAI Codex** [https://openai.com/codex/](https://openai.com/codex/) is truly amazing. It built this entire tool in 3 days. I spent about 16 hours total reviewing, testing, and steering. I use Gemini, Claude and Codex each with $200 monthly plans for dev and all types of contract work but Codex currently really pushes the limit in terms of context value and time spent working through code.\n\nI\u2019m a dev with 20+ years of experience, and I could have built this the traditional way, but it would\u2019ve taken me a month+ of nights/weekends. Codex wrote all of it. I mostly reviewed, tested, and iterated on behavior / UI. AI is genuinely amazing here\u00a0and I think we all need to embrace it and adapt.\u00a0  \n  \n**What I was missing for my workflow**: Stitch doesn\u2019t currently let you do fast, tiny edits in-app (spacing, typography, layout nudges, swapping an icon, quick copy changes). You can re-prompt, but for small changes it\u2019s slower than it should be, and sometimes you end up re-prompting multiple times to get a simple tweak right.\n\nSo I built Stitch Edit. It\u2019s a lightweight editor focused on making practical edits to Stitch-style HTML/Tailwind output, instantly, without re-prompting. I\u2019m sure there are a million great HTML editors out there. I built this because I wanted something tuned to this specific Stitch / Tailwind workflow, and I wanted to see how fast / far AI could take it.\n\nWhat it does:\n\n* Rapid micro-edits without re-prompting\n   * Spacing, sizing, typography, layout, borders, radius, shadow, etc. with immediate preview\n* Fast theme and color workflows\n   * Background, text, border, accent updates across common components (buttons, inputs, cards, icons/SVG)\n   * Opacity tweaks and other small polish changes\n* Edit text content directly\n   * Update labels and copy in-place while iterating layout\n* Image and icon replacement\n   * Swap image sources and background images quickly\n   * Replace Material icons (and similar patterns) without digging through code\n* Copy and paste HTML elements between documents\n   * Move sections/components between docs fast for building screens from reusable chunks\n* Multi-document tabs\n   * Duplicate, rename, close docs for quick variations\n* Undo and redo\n* Export and share\n   * Copy HTML out and export the preview as a PNG for quick feedback\n\nIf you use Google Stitch AI or generate Tailwind/HTML and want to try the rapid tiny edits workflow, it\u2019s here: [https://stitchedit.io/](https://stitchedit.io/)\n\nI\u2019m sure there are bugs or use / edge cases I missed, but I wanted to get this out there and share it. I\u2019d love feedback and what features would make it a daily driver.",
                    "author_fullname": "t2_jpbt7",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "is_gallery": true,
                    "title": "Stitch Edit: Built in 3 days with Codex for Google Stitch workflows",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 53,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "media_metadata": {
                        "bdnmeochzdbg1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/png",
                            "p": [
                                {
                                    "y": 41,
                                    "x": 108,
                                    "u": "https://preview.redd.it/bdnmeochzdbg1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=196a01f1427755c4561ace3032eaf50561cc6096"
                                },
                                {
                                    "y": 82,
                                    "x": 216,
                                    "u": "https://preview.redd.it/bdnmeochzdbg1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=26bc4562b1c75384919367b343a9f2d5e54e12a5"
                                },
                                {
                                    "y": 122,
                                    "x": 320,
                                    "u": "https://preview.redd.it/bdnmeochzdbg1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b611fbee8dd588fd63fb45dc32fa18b36f063e9b"
                                },
                                {
                                    "y": 245,
                                    "x": 640,
                                    "u": "https://preview.redd.it/bdnmeochzdbg1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=47b1cda137f5bb22bf7c6be49610d72e1f013911"
                                },
                                {
                                    "y": 367,
                                    "x": 960,
                                    "u": "https://preview.redd.it/bdnmeochzdbg1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=848a77ccace78a499205909d2d3439c8f3c1bd2f"
                                },
                                {
                                    "y": 413,
                                    "x": 1080,
                                    "u": "https://preview.redd.it/bdnmeochzdbg1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4b6c8fd580f39935f9a3b95b17b5100c1e97f867"
                                }
                            ],
                            "s": {
                                "y": 1316,
                                "x": 3437,
                                "u": "https://preview.redd.it/bdnmeochzdbg1.png?width=3437&amp;format=png&amp;auto=webp&amp;s=cb464533bd4c24c99e7c16b215e2ae8f6af3d3fd"
                            },
                            "id": "bdnmeochzdbg1"
                        },
                        "f63gu94izdbg1": {
                            "status": "valid",
                            "e": "Image",
                            "m": "image/png",
                            "p": [
                                {
                                    "y": 41,
                                    "x": 108,
                                    "u": "https://preview.redd.it/f63gu94izdbg1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=69a038dd42a490280b677bfe717ede69c7d6f5a8"
                                },
                                {
                                    "y": 82,
                                    "x": 216,
                                    "u": "https://preview.redd.it/f63gu94izdbg1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c9cac4c3d005eed6bdcb646f1388008e338ce66b"
                                },
                                {
                                    "y": 122,
                                    "x": 320,
                                    "u": "https://preview.redd.it/f63gu94izdbg1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=027d5c26b8a8d1128058616224cb1998a84a43d0"
                                },
                                {
                                    "y": 244,
                                    "x": 640,
                                    "u": "https://preview.redd.it/f63gu94izdbg1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d9f282bb15e78e4a34b67fae3475ba663686ecda"
                                },
                                {
                                    "y": 367,
                                    "x": 960,
                                    "u": "https://preview.redd.it/f63gu94izdbg1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d03daee3c3bc72138be2d72ac38c66398530f629"
                                },
                                {
                                    "y": 413,
                                    "x": 1080,
                                    "u": "https://preview.redd.it/f63gu94izdbg1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d1fb6dd7bd82db29e058ba79cab367ab2301f2bb"
                                }
                            ],
                            "s": {
                                "y": 1316,
                                "x": 3439,
                                "u": "https://preview.redd.it/f63gu94izdbg1.png?width=3439&amp;format=png&amp;auto=webp&amp;s=6715623c718f9436f9f7b56d11e6b194ab2efb45"
                            },
                            "id": "f63gu94izdbg1"
                        }
                    },
                    "name": "t3_1q3zstb",
                    "quarantine": false,
                    "link_flair_text_color": "dark",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "ups": 6,
                    "domain": "old.reddit.com",
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "gallery_data": {
                        "items": [
                            {
                                "media_id": "bdnmeochzdbg1",
                                "id": 831946972
                            },
                            {
                                "media_id": "f63gu94izdbg1",
                                "id": 831946973
                            }
                        ]
                    },
                    "link_flair_text": "Showcase",
                    "can_mod_post": false,
                    "score": 6,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/tn48CtmxhA5OTNVKtslxvHSN1ydiIYvVS_Rsoqe1iPI.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": false,
                    "subreddit_type": "public",
                    "created": 1767556581.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "total_awards_received": 0,
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR: I built a fast HTML / Tailwind editor for Google Stitch style workflows in 3 days using OpenAI Codex (about 16 hours of my time). Try it here: &lt;a href=\"https://stitchedit.io/\"&gt;https://stitchedit.io/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been replacing my old Figma to code workflow with a new dev workflow: Google Stitch AI for UI design, export the HTML / Tailwind, implement in codex, test / ship. Wow, is this new workflow fast!!!   &lt;/p&gt;\n\n&lt;p&gt;Two things I want to highlight because they surprised me:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Google Stitch&lt;/strong&gt; &lt;a href=\"https://stitch.withgoogle.com/AI\"&gt;https://stitch.withgoogle.com/AI&lt;/a&gt; is genuinely good. It\u2019s the first UI generator that has felt usable for real iteration. Sure Claude and Gemini work but I love that stitch is UI centric. &lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;OpenAI Codex&lt;/strong&gt; &lt;a href=\"https://openai.com/codex/\"&gt;https://openai.com/codex/&lt;/a&gt; is truly amazing. It built this entire tool in 3 days. I spent about 16 hours total reviewing, testing, and steering. I use Gemini, Claude and Codex each with $200 monthly plans for dev and all types of contract work but Codex currently really pushes the limit in terms of context value and time spent working through code.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I\u2019m a dev with 20+ years of experience, and I could have built this the traditional way, but it would\u2019ve taken me a month+ of nights/weekends. Codex wrote all of it. I mostly reviewed, tested, and iterated on behavior / UI. AI is genuinely amazing here\u00a0and I think we all need to embrace it and adapt.\u00a0  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What I was missing for my workflow&lt;/strong&gt;: Stitch doesn\u2019t currently let you do fast, tiny edits in-app (spacing, typography, layout nudges, swapping an icon, quick copy changes). You can re-prompt, but for small changes it\u2019s slower than it should be, and sometimes you end up re-prompting multiple times to get a simple tweak right.&lt;/p&gt;\n\n&lt;p&gt;So I built Stitch Edit. It\u2019s a lightweight editor focused on making practical edits to Stitch-style HTML/Tailwind output, instantly, without re-prompting. I\u2019m sure there are a million great HTML editors out there. I built this because I wanted something tuned to this specific Stitch / Tailwind workflow, and I wanted to see how fast / far AI could take it.&lt;/p&gt;\n\n&lt;p&gt;What it does:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Rapid micro-edits without re-prompting\n\n&lt;ul&gt;\n&lt;li&gt;Spacing, sizing, typography, layout, borders, radius, shadow, etc. with immediate preview&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Fast theme and color workflows\n\n&lt;ul&gt;\n&lt;li&gt;Background, text, border, accent updates across common components (buttons, inputs, cards, icons/SVG)&lt;/li&gt;\n&lt;li&gt;Opacity tweaks and other small polish changes&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Edit text content directly\n\n&lt;ul&gt;\n&lt;li&gt;Update labels and copy in-place while iterating layout&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Image and icon replacement\n\n&lt;ul&gt;\n&lt;li&gt;Swap image sources and background images quickly&lt;/li&gt;\n&lt;li&gt;Replace Material icons (and similar patterns) without digging through code&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Copy and paste HTML elements between documents\n\n&lt;ul&gt;\n&lt;li&gt;Move sections/components between docs fast for building screens from reusable chunks&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Multi-document tabs\n\n&lt;ul&gt;\n&lt;li&gt;Duplicate, rename, close docs for quick variations&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Undo and redo&lt;/li&gt;\n&lt;li&gt;Export and share\n\n&lt;ul&gt;\n&lt;li&gt;Copy HTML out and export the preview as a PNG for quick feedback&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you use Google Stitch AI or generate Tailwind/HTML and want to try the rapid tiny edits workflow, it\u2019s here: &lt;a href=\"https://stitchedit.io/\"&gt;https://stitchedit.io/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I\u2019m sure there are bugs or use / edge cases I missed, but I wanted to get this out there and share it. I\u2019d love feedback and what features would make it a daily driver.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "url_overridden_by_dest": "https://www.reddit.com/gallery/1q3zstb",
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "e350908e-b24e-11f0-b239-62e50da6d05a",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "mod_note": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "num_reports": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#00ff2a",
                    "id": "1q3zstb",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "digitalml",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q3zstb/stitch_edit_built_in_3_days_with_codex_for_google/",
                    "stickied": false,
                    "url": "https://www.reddit.com/gallery/1q3zstb",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767556581.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "",
                    "author_fullname": "t2_1ehqw3cfln",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Interview with Tibo and Ed Bayes, Dec 18, 1h 09m",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 105,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1pq9uhd",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.75,
                    "author_flair_background_color": null,
                    "ups": 4,
                    "total_awards_received": 0,
                    "media_embed": {
                        "content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/tuLWIK1AVEM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Codex 5.2 Launch Revealed: How OpenAI Got Non-Engineers Shipping Real Code\"&gt;&lt;/iframe&gt;",
                        "width": 356,
                        "scrolling": false,
                        "height": 200
                    },
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": {
                        "type": "youtube.com",
                        "oembed": {
                            "provider_url": "https://www.youtube.com/",
                            "version": "1.0",
                            "title": "Codex 5.2 Launch Revealed: How OpenAI Got Non-Engineers Shipping Real Code",
                            "type": "video",
                            "thumbnail_width": 480,
                            "height": 200,
                            "width": 356,
                            "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/tuLWIK1AVEM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Codex 5.2 Launch Revealed: How OpenAI Got Non-Engineers Shipping Real Code\"&gt;&lt;/iframe&gt;",
                            "author_name": "AI News &amp; Strategy Daily | Nate B Jones",
                            "provider_name": "YouTube",
                            "thumbnail_url": "https://i.ytimg.com/vi/tuLWIK1AVEM/hqdefault.jpg",
                            "thumbnail_height": 360,
                            "author_url": "https://www.youtube.com/@NateBJones"
                        }
                    },
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {
                        "content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/tuLWIK1AVEM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Codex 5.2 Launch Revealed: How OpenAI Got Non-Engineers Shipping Real Code\"&gt;&lt;/iframe&gt;",
                        "width": 356,
                        "scrolling": false,
                        "media_domain_url": "https://www.redditmedia.com/mediaembed/1pq9uhd",
                        "height": 200
                    },
                    "link_flair_text": "Commentary",
                    "can_mod_post": false,
                    "score": 4,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://external-preview.redd.it/_6N5yz47PqN7LBGF7wpiJaj4gXIg9FJcpN_GnaWCYlY.jpeg?width=140&amp;height=105&amp;auto=webp&amp;s=4e38347b8ec27cecb00b8517886470f0e8097aed",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "rich:video",
                    "content_categories": null,
                    "is_self": false,
                    "subreddit_type": "public",
                    "created": 1766112257.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "youtube.com",
                    "allow_live_comments": false,
                    "selftext_html": null,
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "url_overridden_by_dest": "https://www.youtube.com/watch?v=tuLWIK1AVEM",
                    "view_count": null,
                    "archived": false,
                    "no_follow": false,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://external-preview.redd.it/_6N5yz47PqN7LBGF7wpiJaj4gXIg9FJcpN_GnaWCYlY.jpeg?auto=webp&amp;s=de791efd6536ab2015d3d9d714878114d23599c6",
                                    "width": 480,
                                    "height": 360
                                },
                                "resolutions": [
                                    {
                                        "url": "https://external-preview.redd.it/_6N5yz47PqN7LBGF7wpiJaj4gXIg9FJcpN_GnaWCYlY.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=78eb3999328e215fef56f3abedcac17e6d882736",
                                        "width": 108,
                                        "height": 81
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/_6N5yz47PqN7LBGF7wpiJaj4gXIg9FJcpN_GnaWCYlY.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0a7c067bdd7833eb5d6570589823f93f6f2ad6f0",
                                        "width": 216,
                                        "height": 162
                                    },
                                    {
                                        "url": "https://external-preview.redd.it/_6N5yz47PqN7LBGF7wpiJaj4gXIg9FJcpN_GnaWCYlY.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e0818965fd61ca45ffdb6cf3278c27bea81808b3",
                                        "width": 320,
                                        "height": 240
                                    }
                                ],
                                "variants": {},
                                "id": "_6N5yz47PqN7LBGF7wpiJaj4gXIg9FJcpN_GnaWCYlY"
                            }
                        ],
                        "enabled": false
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "5dc0bbc2-8d43-11f0-a897-a2f48743ec57",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "mod_note": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "num_reports": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#826e91",
                    "id": "1pq9uhd",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "MyUnbannableAccount",
                    "discussion_type": null,
                    "num_comments": 2,
                    "send_replies": false,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1pq9uhd/interview_with_tibo_and_ed_bayes_dec_18_1h_09m/",
                    "stickied": false,
                    "url": "https://www.youtube.com/watch?v=tuLWIK1AVEM",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766112257.0,
                    "num_crossposts": 0,
                    "media": {
                        "type": "youtube.com",
                        "oembed": {
                            "provider_url": "https://www.youtube.com/",
                            "version": "1.0",
                            "title": "Codex 5.2 Launch Revealed: How OpenAI Got Non-Engineers Shipping Real Code",
                            "type": "video",
                            "thumbnail_width": 480,
                            "height": 200,
                            "width": 356,
                            "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/tuLWIK1AVEM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Codex 5.2 Launch Revealed: How OpenAI Got Non-Engineers Shipping Real Code\"&gt;&lt;/iframe&gt;",
                            "author_name": "AI News &amp; Strategy Daily | Nate B Jones",
                            "provider_name": "YouTube",
                            "thumbnail_url": "https://i.ytimg.com/vi/tuLWIK1AVEM/hqdefault.jpg",
                            "thumbnail_height": 360,
                            "author_url": "https://www.youtube.com/@NateBJones"
                        }
                    },
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "**After Codex wiped files on my machine and caused OS-level damage**, I decided that should never be possible again.\n\nAs AI-assisted coding becomes more common, OpenAI has released its own sandboxing approach. I am not comfortable relying solely on vendor-controlled safeguards. When the same entity builds the tool and monitors its behavior, that creates obvious blind spots. It is effectively asking the fox to guard the hen house.\n\nSo, I built a Windows-focused sandbox and workflow designed to run Codex alongside normal development work without giving it the ability to damage the host system.\n\nIf there is interest, I am happy to share the repo and get feedback from others who are actively using Codex in their day-to-day work. This is currently Windows-only and aimed at developers who want stronger isolation than what is provided out of the box.",
                    "author_fullname": "t2_11zrd25z",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Built a Windows sandbox after Codex wiped files on my machine",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": 140,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1prtxxa",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.38,
                    "author_flair_background_color": null,
                    "ups": 0,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": 140,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": true,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Complaint",
                    "can_mod_post": false,
                    "score": 0,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "https://b.thumbs.redditmedia.com/xgj2vAUSzPeqmVCaFqwl_ljqxzHZM6GOUzFfTNQA1nU.jpg",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "post_hint": "image",
                    "content_categories": null,
                    "is_self": false,
                    "subreddit_type": "public",
                    "created": 1766279584.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "i.redd.it",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;After Codex wiped files on my machine and caused OS-level damage&lt;/strong&gt;, I decided that should never be possible again.&lt;/p&gt;\n\n&lt;p&gt;As AI-assisted coding becomes more common, OpenAI has released its own sandboxing approach. I am not comfortable relying solely on vendor-controlled safeguards. When the same entity builds the tool and monitors its behavior, that creates obvious blind spots. It is effectively asking the fox to guard the hen house.&lt;/p&gt;\n\n&lt;p&gt;So, I built a Windows-focused sandbox and workflow designed to run Codex alongside normal development work without giving it the ability to damage the host system.&lt;/p&gt;\n\n&lt;p&gt;If there is interest, I am happy to share the repo and get feedback from others who are actively using Codex in their day-to-day work. This is currently Windows-only and aimed at developers who want stronger isolation than what is provided out of the box.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "url_overridden_by_dest": "https://i.redd.it/tqh8d9sujg8g1.png",
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "preview": {
                        "images": [
                            {
                                "source": {
                                    "url": "https://preview.redd.it/tqh8d9sujg8g1.png?auto=webp&amp;s=05288795af42b8fe7be455a7d4640c282bc2c146",
                                    "width": 1024,
                                    "height": 1024
                                },
                                "resolutions": [
                                    {
                                        "url": "https://preview.redd.it/tqh8d9sujg8g1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=36da9b7332b53b0691870b8023338778196d3f87",
                                        "width": 108,
                                        "height": 108
                                    },
                                    {
                                        "url": "https://preview.redd.it/tqh8d9sujg8g1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=546efc476222400800900a5f1462563f8d6aac34",
                                        "width": 216,
                                        "height": 216
                                    },
                                    {
                                        "url": "https://preview.redd.it/tqh8d9sujg8g1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d506f83823a439991fb37956e3fe3546e460cd28",
                                        "width": 320,
                                        "height": 320
                                    },
                                    {
                                        "url": "https://preview.redd.it/tqh8d9sujg8g1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f7b697543a66d9b04253387881cc1872a70f2cc3",
                                        "width": 640,
                                        "height": 640
                                    },
                                    {
                                        "url": "https://preview.redd.it/tqh8d9sujg8g1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=94648c9f99f2f256e5566aa29674421c15329ad0",
                                        "width": 960,
                                        "height": 960
                                    }
                                ],
                                "variants": {},
                                "id": "6yn7f1Sj2piOa7Tvk3ueODCsfba5SiDgKIsbOIkmmkw"
                            }
                        ],
                        "enabled": true
                    },
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "3090d6a0-ab11-11f0-a7f1-526fbbfcd846",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "mod_note": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "num_reports": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#f40b0b",
                    "id": "1prtxxa",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "InvisibleWraith",
                    "discussion_type": null,
                    "num_comments": 2,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1prtxxa/built_a_windows_sandbox_after_codex_wiped_files/",
                    "stickied": false,
                    "url": "https://i.redd.it/tqh8d9sujg8g1.png",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766279584.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Perplexity suggests nobody's written what I'm about to write. It seems there's a weekly post to the tune of \"Anthropic \\[or OpenAI\\] promised me unlimited usage, now they seem to be reducing the limit without telling us!\" Yet, these consumer plans seem to be far cheaper than the equivalent in API cost so why not just charge people that?\n\nSo my sense is that\n\n* all of the labs need to make capacity commitments with the big clouds like Azure/AWS/Google to get the best possible pricing\n* API calls, which are on demand, must be delivered but are unpredictable\n* at times, the amount of excess capacity available is lower than others (and usage limits are adjusted accordingly) and when it is higher, OpenAI will gift consumers resets (i.e. during Christmas)\n\nBasically, consumer subscriptions are of the same priority as pre-emptible cloud instances on AWS or Google, which are around 5x cheaper. Same reason why batched requests are cheaper.\n\nI hope we stay in this equilibrium. I would hate for it to be inverted like Bigquery, where enterprises pay flex slots and consumers pay on-demand prices ($5). I'm sure there's lots of reasons AI pricing would be more favorable to consumers instead, such as the fact the API capabilities are constantly changing and thus hard to reserve, growth rates in hardware capacity, educating consumers through chaeper subscriptions, and not least of which the unreliability which makes corporates less likely to commit to reservations at scale.",
                    "author_fullname": "t2_24x4di2za9",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "a simple explanation for \"[lab] is reducing my usage on the $N plan\"",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1q1sc9e",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 0.25,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 0,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Commentary",
                    "can_mod_post": false,
                    "score": 0,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1767338774.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Perplexity suggests nobody&amp;#39;s written what I&amp;#39;m about to write. It seems there&amp;#39;s a weekly post to the tune of &amp;quot;Anthropic [or OpenAI] promised me unlimited usage, now they seem to be reducing the limit without telling us!&amp;quot; Yet, these consumer plans seem to be far cheaper than the equivalent in API cost so why not just charge people that?&lt;/p&gt;\n\n&lt;p&gt;So my sense is that&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;all of the labs need to make capacity commitments with the big clouds like Azure/AWS/Google to get the best possible pricing&lt;/li&gt;\n&lt;li&gt;API calls, which are on demand, must be delivered but are unpredictable&lt;/li&gt;\n&lt;li&gt;at times, the amount of excess capacity available is lower than others (and usage limits are adjusted accordingly) and when it is higher, OpenAI will gift consumers resets (i.e. during Christmas)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Basically, consumer subscriptions are of the same priority as pre-emptible cloud instances on AWS or Google, which are around 5x cheaper. Same reason why batched requests are cheaper.&lt;/p&gt;\n\n&lt;p&gt;I hope we stay in this equilibrium. I would hate for it to be inverted like Bigquery, where enterprises pay flex slots and consumers pay on-demand prices ($5). I&amp;#39;m sure there&amp;#39;s lots of reasons AI pricing would be more favorable to consumers instead, such as the fact the API capabilities are constantly changing and thus hard to reserve, growth rates in hardware capacity, educating consumers through chaeper subscriptions, and not least of which the unreliability which makes corporates less likely to commit to reservations at scale.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "5dc0bbc2-8d43-11f0-a897-a2f48743ec57",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#826e91",
                    "id": "1q1sc9e",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "banalyuppie",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1q1sc9e/a_simple_explanation_for_lab_is_reducing_my_usage/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1q1sc9e/a_simple_explanation_for_lab_is_reducing_my_usage/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1767338774.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            },
            {
                "kind": "t3",
                "data": {
                    "approved_at_utc": null,
                    "subreddit": "codex",
                    "selftext": "Disclaimer: I\u2019m new to Codex and IDEs. \n\nI\u2019m currently use ChatGPT Plus ($20/month) and I\u2019m generally happy with it. I\u2019d like to move beyond chat-based use and start building agent-style workflows that can plan steps, run commands, and work safely with local files.\n\nI want to start with simple tasks (for example, batch renaming files or organizing image folders) but scale up to more complex and reliable automations over time.\n\nWhat I\u2019m trying to understand:\n\n- If I\u2019m already paying for ChatGPT Plus, is OpenAI Codex (CLI or IDE-based) sufficient for this type of agent work, or do people typically rely on Claude Code for more advanced workflows?\n- Portability: if I structure projects using rules files, project memory documents (for example cloud.md-style), or defined \u201cskills,\u201d are these approaches portable between Codex and Claude Code, or do they effectively lock you into one ecosystem?\n- Cost and limits: I often hear that Claude Code becomes expensive at scale, and that the $20 Claude plan is quickly limiting for agent-style usage, with higher tiers being required. Is this generally true in real-world use?\n\nFor people who have experience with both, what setup would you recommend for someone who wants to start small but scale into more advanced agent workflows, while keeping tooling and subscriptions manageable?",
                    "author_fullname": "t2_ipbom",
                    "saved": false,
                    "mod_reason_title": null,
                    "gilded": 0,
                    "clicked": false,
                    "title": "Codex and/or Claude Code for running real AI agents on your own files?",
                    "link_flair_richtext": [],
                    "subreddit_name_prefixed": "r/codex",
                    "hidden": false,
                    "pwls": 6,
                    "link_flair_css_class": "",
                    "downs": 0,
                    "thumbnail_height": null,
                    "top_awarded_type": null,
                    "hide_score": false,
                    "name": "t3_1ppnra7",
                    "quarantine": false,
                    "link_flair_text_color": "light",
                    "upvote_ratio": 1.0,
                    "author_flair_background_color": null,
                    "subreddit_type": "public",
                    "ups": 1,
                    "total_awards_received": 0,
                    "media_embed": {},
                    "thumbnail_width": null,
                    "author_flair_template_id": null,
                    "is_original_content": false,
                    "user_reports": [],
                    "secure_media": null,
                    "is_reddit_media_domain": false,
                    "is_meta": false,
                    "category": null,
                    "secure_media_embed": {},
                    "link_flair_text": "Question",
                    "can_mod_post": false,
                    "score": 1,
                    "approved_by": null,
                    "is_created_from_ads_ui": false,
                    "author_premium": false,
                    "thumbnail": "self",
                    "edited": false,
                    "author_flair_css_class": null,
                    "author_flair_richtext": [],
                    "gildings": {},
                    "content_categories": null,
                    "is_self": true,
                    "mod_note": null,
                    "created": 1766054434.0,
                    "link_flair_type": "text",
                    "wls": 6,
                    "removed_by_category": null,
                    "banned_by": null,
                    "author_flair_type": "text",
                    "domain": "self.codex",
                    "allow_live_comments": false,
                    "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Disclaimer: I\u2019m new to Codex and IDEs. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently use ChatGPT Plus ($20/month) and I\u2019m generally happy with it. I\u2019d like to move beyond chat-based use and start building agent-style workflows that can plan steps, run commands, and work safely with local files.&lt;/p&gt;\n\n&lt;p&gt;I want to start with simple tasks (for example, batch renaming files or organizing image folders) but scale up to more complex and reliable automations over time.&lt;/p&gt;\n\n&lt;p&gt;What I\u2019m trying to understand:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;If I\u2019m already paying for ChatGPT Plus, is OpenAI Codex (CLI or IDE-based) sufficient for this type of agent work, or do people typically rely on Claude Code for more advanced workflows?&lt;/li&gt;\n&lt;li&gt;Portability: if I structure projects using rules files, project memory documents (for example cloud.md-style), or defined \u201cskills,\u201d are these approaches portable between Codex and Claude Code, or do they effectively lock you into one ecosystem?&lt;/li&gt;\n&lt;li&gt;Cost and limits: I often hear that Claude Code becomes expensive at scale, and that the $20 Claude plan is quickly limiting for agent-style usage, with higher tiers being required. Is this generally true in real-world use?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;For people who have experience with both, what setup would you recommend for someone who wants to start small but scale into more advanced agent workflows, while keeping tooling and subscriptions manageable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
                    "likes": null,
                    "suggested_sort": null,
                    "banned_at_utc": null,
                    "view_count": null,
                    "archived": false,
                    "no_follow": true,
                    "is_crosspostable": true,
                    "pinned": false,
                    "over_18": false,
                    "all_awardings": [],
                    "awarders": [],
                    "media_only": false,
                    "link_flair_template_id": "302c6282-b24c-11f0-a6c9-9eb8e1ecefd1",
                    "can_gild": false,
                    "spoiler": false,
                    "locked": false,
                    "author_flair_text": null,
                    "treatment_tags": [],
                    "visited": false,
                    "removed_by": null,
                    "num_reports": null,
                    "distinguished": null,
                    "subreddit_id": "t5_2t1qf",
                    "author_is_blocked": false,
                    "mod_reason_by": null,
                    "removal_reason": null,
                    "link_flair_background_color": "#c13e80",
                    "id": "1ppnra7",
                    "is_robot_indexable": true,
                    "report_reasons": null,
                    "author": "The-Road",
                    "discussion_type": null,
                    "num_comments": 0,
                    "send_replies": true,
                    "contest_mode": false,
                    "mod_reports": [],
                    "author_patreon_flair": false,
                    "author_flair_text_color": null,
                    "permalink": "/r/codex/comments/1ppnra7/codex_andor_claude_code_for_running_real_ai/",
                    "stickied": false,
                    "url": "https://old.reddit.com/r/codex/comments/1ppnra7/codex_andor_claude_code_for_running_real_ai/",
                    "subreddit_subscribers": 19413,
                    "created_utc": 1766054434.0,
                    "num_crossposts": 0,
                    "media": null,
                    "is_video": false
                }
            }
        ],
        "before": null
    }
}